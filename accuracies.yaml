audio-qa:
  audio:
    facebook/s2t-small-librispeech-asr: 80
    facebook/s2t-medium-librispeech-asr: 82
    facebook/s2t-large-librispeech-asr: 83
    facebook/wav2vec2-base-960h: 85
    facebook/wav2vec2-large-960h: 86
  nlp-qa:
    # F1 score, https://huggingface.co/deepset/roberta-base-squad2#performance
    # Training Dataset: SQuAD 2.0, https://huggingface.co/datasets/squad_v2
    # Testset: SQuAD 2.0, https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob/
    deepset/roberta-base-squad2: 82.9125  
    
    # F1 score, https://huggingface.co/deepset/xlm-roberta-large-squad2#performance
    # Training Dataset: SQuAD 2.0, https://huggingface.co/datasets/squad_v2
    # Testset: SQuAD 2.0, https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob/
    deepset/xlm-roberta-large-squad2: 83.7925  
    
    # F1 score, https://huggingface.co/distilbert-base-cased-distilled-squad#evaluation
    # Training Dataset: SQuAD 1.1, https://huggingface.co/datasets/squad
    # Testset: SQuAD 1.1
    # TODO
    distilbert-base-cased-distilled-squad: 87.1  

    # F1 score, https://huggingface.co/deepset/xlm-roberta-base-squad2#performance
    # Training Dataset: SQuAD 2.0, https://huggingface.co/datasets/squad_v2
    # Testset: SQuAD 2.0
    deepset/xlm-roberta-base-squad2: 77.141  
audio-sent:
  audio:
    facebook/s2t-small-librispeech-asr: 80
    facebook/s2t-medium-librispeech-asr: 82
    facebook/s2t-large-librispeech-asr: 83
    facebook/wav2vec2-base-960h: 85
    facebook/wav2vec2-large-960h: 86
  nlp-sent:
  # sentimment-analysis
    huggingface/distilbert-base-uncased-finetuned-mnli: nill  
    huggingface/prunebert-base-uncased-6-finepruned-w-distil-mnli: nill

    # URL: https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english
    # Training Datasets: https://huggingface.co/datasets/glue, https://huggingface.co/datasets/sst2
    distilbert-base-uncased-finetuned-sst-2-english: nill # Accuracy = 0.911 on glue, Accuracy = 0.989 on sst2 
    
    Souvikcmsa/BERT_sentiment_analysis: 0.799017824663514  # https://huggingface.co/Souvikcmsa/BERT_sentiment_analysis
    Souvikcmsa/SentimentAnalysisDistillBERT: 0.7962895598399418  # https://huggingface.co/Souvikcmsa/SentimentAnalysisDistillBERT
    Souvikcmsa/Roberta_Sentiment_Analysis: 0.8302828618968386  # https://huggingface.co/Souvikcmsa/Roberta_Sentiment_Analysis
mock:
  node-1:
    1: 100
    2: 100
  node-2:
    1: 100
    2: 100
nlp:

# language identification
  nlp-li:
    # Accuracy, https://huggingface.co/dinalzein/xlm-roberta-base-finetuned-language-identification
    # Training Dataset: https://huggingface.co/datasets/papluca/language-identification
    dinalzein/xlm-roberta-base-finetuned-language-identification: 0.9959
  # text translation
  nlp-trans:
    # chrF2 score, https://object.pouta.csc.fi/OPUS-MT-models/fr-en/opus-2020-02-26.eval.txt
    # Testset, Tatoeba.fr.en, https://object.pouta.csc.fi/OPUS-MT-models/fr-en/opus-2020-02-26.test.txt
    Helsinki-NLP/opus-mt-fr-en: 0.720

    # chrF2 score, https://object.pouta.csc.fi/Tatoeba-MT-models/fra-eng/opusTCv20210807+bt_transformer-big_2022-03-09.eval.txt
    # Testset: https://object.pouta.csc.fi/Tatoeba-MT-models/fra-eng/opusTCv20210807+bt_transformer-big_2022-03-09.test.txt
    # https://github.com/Helsinki-NLP/Tatoeba-Challenge
    Helsinki-NLP/opus-mt-tc-big-fr-en: 0.7409
  
  # text summerization
  nlp-sum:
    # ROUGE-L metric for sshleifer versions https://huggingface.co/sshleifer/distilbart-xsum-12-1#metrics-for-distilbart-models
    # Training Datasets: https://huggingface.co/datasets/cnn_dailymail, https://huggingface.co/datasets/xsum
    sshleifer/distilbart-cnn-12-6: 30.59
    sshleifer/distilbart-xsum-1-1: nill
    sshleifer/distill-pegasus-cnn-16-4: nill
    sshleifer/distill-pegasus-xsum-16-4: nill
    sshleifer/distilbart-xsum-12-3: 36.39
    sshleifer/distilbart-xsum-6-6: 35.73
    sshleifer/pegasus-cnn-ft-v2: nill
    sshleifer/distilbart-cnn-6-6: 29.70
    sshleifer/distilbart-xsum-12-6: 36.99
    sshleifer/distilbart-cnn-12-3: 30.00
    sshleifer/distilbart-xsum-12-1: 33.37
    sshleifer/distilbart-xsum-9-6: 36.61
    sshleifer/distill-pegasus-xsum-16-8: nill

    # ROUGE-L, https://huggingface.co/facebook/bart-large-cnn, https://paperswithcode.com/sota/summarization-on-cnn-dailymail
    # Training Dataset: https://huggingface.co/datasets/cnn_dailymail
    facebook/bart-large-cnn: 30.619  

    google/roberta2roberta_L-24_bbc: nill
    google/pegasus-cnn_dailymail: nill
    google/roberta2roberta_L-24_cnn_daily_mail: nill
    google/pegasus-large: nill
sum-qa:
  nlp-sum:
    # ROUGE-L metric for sshleifer versions https://huggingface.co/sshleifer/distilbart-xsum-12-1#metrics-for-distilbart-models
    # Training Datasets: https://huggingface.co/datasets/cnn_dailymail, https://huggingface.co/datasets/xsum
    sshleifer/distilbart-cnn-12-6: 30.59
    sshleifer/distilbart-xsum-1-1: nill
    sshleifer/distill-pegasus-cnn-16-4: nill
    sshleifer/distill-pegasus-xsum-16-4: nill
    sshleifer/distilbart-xsum-12-3: 36.39
    sshleifer/distilbart-xsum-6-6: 35.73
    sshleifer/pegasus-cnn-ft-v2: nill
    sshleifer/distilbart-cnn-6-6: 29.70
    sshleifer/distilbart-xsum-12-6: 36.99
    sshleifer/distilbart-cnn-12-3: 30.00
    sshleifer/distilbart-xsum-12-1: 33.37
    sshleifer/distilbart-xsum-9-6: 36.61
    sshleifer/distill-pegasus-xsum-16-8: nill

    # ROUGE-L, https://huggingface.co/facebook/bart-large-cnn, https://paperswithcode.com/sota/summarization-on-cnn-dailymail
    # Training Dataset: https://huggingface.co/datasets/cnn_dailymail
    facebook/bart-large-cnn: 30.619  
    
    google/roberta2roberta_L-24_bbc: nill
    google/pegasus-cnn_dailymail: nill
    google/roberta2roberta_L-24_cnn_daily_mail: nill
    google/pegasus-large: nill
  
  # question-answering
  nlp-qa:

    # F1 score, https://huggingface.co/deepset/roberta-base-squad2#performance
    # Training Dataset: SQuAD 2.0, https://huggingface.co/datasets/squad_v2
    # Testset: SQuAD 2.0, https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob/
    deepset/roberta-base-squad2: 82.9125  
    
    # F1 score, https://huggingface.co/deepset/xlm-roberta-large-squad2#performance
    # Training Dataset: SQuAD 2.0, https://huggingface.co/datasets/squad_v2
    # Testset: SQuAD 2.0, https://worksheets.codalab.org/rest/bundles/0x6b567e1cf2e041ec80d7098f031c5c9e/contents/blob/
    deepset/xlm-roberta-large-squad2: 83.7925  
    
    # F1 score, https://huggingface.co/distilbert-base-cased-distilled-squad#evaluation
    # Training Dataset: SQuAD 1.1, https://huggingface.co/datasets/squad
    # Testset: SQuAD 1.1
    distilbert-base-cased-distilled-squad: 87.1  

    # F1 score, https://huggingface.co/deepset/xlm-roberta-base-squad2#performance
    # Training Dataset: SQuAD 2.0, https://huggingface.co/datasets/squad_v2
    # Testset: SQuAD 2.0
    deepset/xlm-roberta-base-squad2: 77.141  
video:
  crop:
    # source https://github.com/ultralytics/yolov5
    yolov5n: 45.7
    yolov5s: 56.8
    yolov5m: 64.1
    yolov5l: 67.3
    yolov5x: 68.9
    # https://pytorch.org/vision/stable/models.html#table-of-all-available-classification-weights
  classification:
    resnet18: 69.75
    resnet34: 73.31
    resnet50: 76.13
    resnet101: 77.37
    resnet152: 78.31