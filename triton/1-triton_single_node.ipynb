{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single node triton server with load test\n",
    "1. Loading to and from minio workflow (multiple models)\n",
    "2. Getting models from [timm](https://timm.fast.ai/)\n",
    "3. Making the node\n",
    "4. Load and unload models operations\n",
    "5. Monitoring\n",
    "6. Naive load test\n",
    "7. TODO Add language models from Huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cc/miniconda3/envs/central/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "739"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(timm.list_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('sudo umount -l ~/my_mounting_point')\n",
    "os.system('cc-cloudfuse mount ~/my_mounting_point')\n",
    "\n",
    "data_folder_path = '/home/cc/my_mounting_point/datasets'\n",
    "dataset_folder_path = os.path.join(\n",
    "    data_folder_path, 'ILSVRC/Data/DET/test'\n",
    ")\n",
    "classes_file_path = os.path.join(\n",
    "    data_folder_path, 'imagenet_classes.txt'\n",
    ")\n",
    "\n",
    "image_names = os.listdir(dataset_folder_path)\n",
    "image_names.sort()\n",
    "with open(classes_file_path) as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "def image_loader(folder_path, image_name):\n",
    "    image = Image.open(\n",
    "        os.path.join(folder_path, image_name))\n",
    "    # if there was a need to filter out only color images\n",
    "    # if image.mode == 'RGB':\n",
    "    #     pass\n",
    "    return image\n",
    "num_loaded_images = 4\n",
    "images = {\n",
    "    image_name: image_loader(\n",
    "        dataset_folder_path, image_name) for image_name in image_names[\n",
    "            :num_loaded_images]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and transform model\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")])\n",
    "\n",
    "batch = torch.stack(list(map(lambda a: transform(a), list(images.values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and predict with the timm model\n",
    "model_name = 'resnet50'\n",
    "model = timm.create_model(model_name, pretrained=True)\n",
    "\n",
    "model.eval()\n",
    "torch_output = model(batch)\n",
    "torch_output = torch.nn.functional.softmax(torch_output, dim=1) * 100\n",
    "torch_output = torch_output.detach().numpy()\n",
    "torch_output = torch_output.argmax(axis=1)\n",
    "torch_class = np.array(classes)[torch_output]\n",
    "torch_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the onnx model\n",
    "import torch.onnx\n",
    "\n",
    "model_variant = 1\n",
    "model_dir = os.path.join(\n",
    "    'models',\n",
    "    model_name,\n",
    "    str(model_variant))\n",
    "model_path = os.path.join(model_dir, 'model.onnx')\n",
    "if 'models' not in os.listdir(\"./\"):\n",
    "    os.makedirs(model_dir)\n",
    "# Standard ImageNet input - 3 channels, 224x224,\n",
    "# values don't matter as we care about network structure.\n",
    "# But they can also be real inputs.\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "# Invoke export\n",
    "torch.onnx.export(\n",
    "    model, dummy_input,\n",
    "    model_path,\n",
    "    input_names = ['input'],\n",
    "    output_names = ['output'],\n",
    "    dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                  'output' : {0 : 'batch_size'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use onnx model\n",
    "import onnx\n",
    "import onnxruntime\n",
    "\n",
    "onnx_model = onnx.load(model_path)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\n",
    "    os.path.join(model_dir, \"model.onnx\"),\n",
    "    providers=['CPUExecutionProvider'])\n",
    "onnx_output = ort_session.run(None, {'input': batch.numpy()})\n",
    "onnx_output = torch.nn.functional.softmax(torch.tensor(onnx_output), dim=1)[0] * 100\n",
    "onnx_output = onnx_output.detach().numpy()\n",
    "onnx_output = onnx_output.argmax(axis=1)\n",
    "onnx_class = np.array(classes)[onnx_output]\n",
    "onnx_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/cc/infernece-pipeline-joint-optimization/triton/1-triton_single_node.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bchameleon/home/cc/infernece-pipeline-joint-optimization/triton/1-triton_single_node.ipynb#ch0000008vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m# TODO find out why slightly different\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bchameleon/home/cc/infernece-pipeline-joint-optimization/triton/1-triton_single_node.ipynb#ch0000008vscode-remote?line=2'>3</a>\u001b[0m \u001b[39massert\u001b[39;00m np\u001b[39m.\u001b[39mall(onnx_output \u001b[39m==\u001b[39m torch_output)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bchameleon/home/cc/infernece-pipeline-joint-optimization/triton/1-triton_single_node.ipynb#ch0000008vscode-remote?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(onnx_class)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO find out why slightly different\n",
    "\n",
    "assert np.all(onnx_output == torch_output)\n",
    "print(onnx_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying on Onnx Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting models/resnet50/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile models/resnet50/config.pbtxt\n",
    "name: \"resnet50\"\n",
    "platform: \"onnxruntime_onnx\"\n",
    "max_batch_size : 100\n",
    "input [\n",
    "  {\n",
    "    name: \"input\"\n",
    "    data_type: TYPE_FP32\n",
    "    format: FORMAT_NCHW\n",
    "    dims: [ 3, 224, 224 ]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"output\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 1000 ]\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION='22.05'\n",
    "os.system(f\"docker pull nvcr.io/nvidia/tritonserver:{VERSION}-py3\")\n",
    "# add --gpus=<number of gpus> on gpu machines\n",
    "# add -d to run at background and going to the next cell\n",
    "os.system(\"docker run --rm -d -p8000:8000 -p8001:8001 -p8002:8002\"\n",
    "          f\" -v {os.getcwd()}/models:/models \"\n",
    "          f\"nvcr.io/nvidia/tritonserver:{VERSION}-py3\"\n",
    "          \" tritonserver --model-repository=/models\")\n",
    "# print(\"docker run --rm -d -p8000:8000 -p8001:8001 -p8002:8002\"\n",
    "#       f\" -v {os.getcwd()}/models:/models \"\n",
    "#       f\"nvcr.io/nvidia/tritonserver:{VERSION}-py3\"\n",
    "#       \" tritonserver --strict-model-config=false --model-repository=/models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Client Examples\n",
    "\n",
    "[examples](https://github.com/triton-inference-server/client/tree/main/src/python/examples)\n",
    "\n",
    "[grpc](https://github.com/triton-inference-server/client/blob/main/src/python/library/tritonclient/grpc/__init__.py)\n",
    "\n",
    "[http](https://github.com/triton-inference-server/client/blob/main/src/python/library/tritonclient/http/__init__.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonclient.http as httpclient\n",
    "from tritonclient.utils import InferenceServerException\n",
    "\n",
    "try:\n",
    "    triton_client = httpclient.InferenceServerClient(\n",
    "        url='localhost:8000', verbose=True\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"context creation failed: \" + str(e))\n",
    "model_name = \"resnet50\"\n",
    "\n",
    "inputs = []\n",
    "inputs.append(\n",
    "    httpclient.InferInput(name=\"input\", shape=batch[0:4].shape, datatype=\"FP32\")\n",
    ")\n",
    "inputs[0].set_data_from_numpy(batch[0:4].numpy(), binary_data=False)\n",
    "\n",
    "outputs = []\n",
    "outputs.append(httpclient.InferRequestedOutput(name=\"output\"))\n",
    "\n",
    "result = triton_client.infer(model_name=model_name, inputs=inputs, outputs=outputs)\n",
    "triton_client.close()\n",
    "triton_output = result.as_numpy('output')\n",
    "triton_output = torch.nn.functional.softmax(\n",
    "    torch.tensor(triton_output), dim=1) * 100\n",
    "triton_output = triton_output.detach().numpy()\n",
    "triton_output = triton_output.argmax(axis=1)\n",
    "triton_class = np.array(classes)[triton_output]\n",
    "triton_class\n",
    "\n",
    "# stop triton server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonclient.grpc as grpcclient\n",
    "from tritonclient.utils import InferenceServerException\n",
    "\n",
    "try:\n",
    "    triton_client = grpcclient.InferenceServerClient(\n",
    "        url='localhost:8001', verbose=True\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"context creation failed: \" + str(e))\n",
    "model_name = \"resnet50\"\n",
    "\n",
    "inputs = []\n",
    "inputs.append(\n",
    "    grpcclient.InferInput(name=\"input\", shape=batch[0:4].shape, datatype=\"FP32\")\n",
    ")\n",
    "inputs[0].set_data_from_numpy(batch[0:4].numpy())\n",
    "\n",
    "outputs = []\n",
    "outputs.append(grpcclient.InferRequestedOutput(name=\"output\"))\n",
    "\n",
    "result = triton_client.infer(model_name=model_name, inputs=inputs, outputs=outputs)\n",
    "triton_client.close()\n",
    "triton_output = result.as_numpy('output')\n",
    "triton_output = torch.nn.functional.softmax(\n",
    "    torch.tensor(triton_output), dim=1) * 100\n",
    "triton_output = triton_output.detach().numpy()\n",
    "triton_output = triton_output.argmax(axis=1)\n",
    "triton_class = np.array(classes)[triton_output]\n",
    "triton_class\n",
    "\n",
    "# stop triton server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"resnet50\"\n",
      "platform: \"onnxruntime_onnx\"\n",
      "max_batch_size: 100\n",
      "  input [\n",
      "    {\n",
      "      name: \"input\"\n",
      "      data_type: TYPE_FP32\n",
      "      format: FORMAT_NCHW\n",
      "      dims: [ 3, 224, 224 ]\n",
      "    }\n",
      "  ]\n",
      "  output [\n",
      "    {\n",
      "      name: \"output\"\n",
      "      data_type: TYPE_FP32\n",
      "      dims: [ 1000 ]\n",
      "    }\n",
      "  ]\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def config_builder(name: str, platform: str, max_batch_size: int):\n",
    "  config = (f\"name: \\\"{name}\\\"\\n\"\n",
    "            f\"platform: \\\"{platform}\\\"\\n\"\n",
    "            f\"max_batch_size: {str(max_batch_size)}\")\n",
    "  common_config=\"\"\"\n",
    "  input [\n",
    "    {\n",
    "      name: \"input\"\n",
    "      data_type: TYPE_FP32\n",
    "      format: FORMAT_NCHW\n",
    "      dims: [ 3, 224, 224 ]\n",
    "    }\n",
    "  ]\n",
    "  output [\n",
    "    {\n",
    "      name: \"output\"\n",
    "      data_type: TYPE_FP32\n",
    "      dims: [ 1000 ]\n",
    "    }\n",
    "  ]\n",
    "  \"\"\"\n",
    "  return config + common_config\n",
    "\n",
    "print(config_builder('resnet50', 'onnxruntime_onnx', 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet34-43635321.pth\" to /home/cc/.cache/torch/hub/checkpoints/resnet34-43635321.pth\n",
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-rsb-weights/resnet101_a1h-36d3f2aa.pth\" to /home/cc/.cache/torch/hub/checkpoints/resnet101_a1h-36d3f2aa.pth\n"
     ]
    }
   ],
   "source": [
    "def generate_model_variants(model_name: str = 'resnet',\n",
    "    model_variants: list = ['18', '34', '101']):\n",
    "    # model name\n",
    "    timm_models = timm.list_models(model_name+'*', pretrained=True)\n",
    "    model_path = os.path.join(\n",
    "        'models',\n",
    "        model_name,\n",
    "    )\n",
    "    config_path = os.path.join(\n",
    "        model_path,\n",
    "        'config.pbtxt')\n",
    "    # if 'models' not in os.listdir(\"./\"):\n",
    "    os.makedirs(model_path)\n",
    "    config = config_builder(\n",
    "        name=model_name,\n",
    "        platform='onnxruntime_onnx',\n",
    "        max_batch_size=100)\n",
    "    with open(config_path, 'w') as f:\n",
    "        f.write(config)\n",
    "    for variant_id, model_variant in enumerate(model_variants):\n",
    "        model_full_name = model_name + model_variant\n",
    "        if not model_full_name in timm_models:\n",
    "            raise ValueError(\n",
    "                f\"Model {model_full_name} does not exist\"\n",
    "            )\n",
    "        model = timm.create_model(model_full_name, pretrained=True)\n",
    "        model.eval()\n",
    "        dummy_input = torch.randn(1, 3, 224, 224)\n",
    "        model_variant_dir = os.path.join(model_path, str(variant_id+1))\n",
    "        model_variant_path = os.path.join(model_variant_dir, 'model.onnx')\n",
    "        # if 'models' not in os.listdir(\"./\"):\n",
    "        os.makedirs(model_variant_dir)\n",
    "        torch.onnx.export(\n",
    "            model, dummy_input,\n",
    "            model_variant_path,\n",
    "            input_names = ['input'],\n",
    "            output_names = ['output'],\n",
    "            dynamic_axes={'input' : {0 : 'batch_size'},\n",
    "                          'output' : {0 : 'batch_size'}})\n",
    "\n",
    "        \n",
    "\n",
    "    # load them all on triton\n",
    "config_builder('resnet50', 'onnxruntime_onnx', 100)\n",
    "generate_model_variants(\n",
    "    model_name='resnet',\n",
    "    model_variants=['18', '34', '101'])\n",
    "# TODO\n",
    "# load and predict with the timm model\n",
    "# model_name = 'resnet50'\n",
    "# model = timm.create_model(model_name, pretrained=True)\n",
    "\n",
    "# # check if the model vairants are available\n",
    "# timm.list_models(\"resnet*\")\n",
    "\n",
    "# model.eval()\n",
    "# torch_output = model(batch)\n",
    "# torch_output = torch.nn.functional.softmax(torch_output, dim=1) * 100\n",
    "# torch_output = torch_output.detach().numpy()\n",
    "# torch_output = torch_output.argmax(axis=1)\n",
    "# torch_class = np.array(classes)[torch_output]\n",
    "# torch_class\n",
    "\n",
    "# TODO\n",
    "# save the onnx model\n",
    "# import torch.onnx\n",
    "\n",
    "# model_variant = 1\n",
    "model_dir = os.path.join(\n",
    "    'models',\n",
    "    model_name,\n",
    "    str(model_variant))\n",
    "model_path = os.path.join(model_dir, 'model.onnx')\n",
    "if 'models' not in os.listdir(\"./\"):\n",
    "    os.makedirs(model_dir)\n",
    "# # Standard ImageNet input - 3 channels, 224x224,\n",
    "# # values don't matter as we care about network structure.\n",
    "# # But they can also be real inputs.\n",
    "# dummy_input = torch.randn(1, 3, 224, 224)\n",
    "# # Invoke export\n",
    "# torch.onnx.export(\n",
    "#     model, dummy_input,\n",
    "#     model_path,\n",
    "#     input_names = ['input'],\n",
    "#     output_names = ['output'],\n",
    "#     dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "#                   'output' : {0 : 'batch_size'}})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send request to multi-models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Switching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model load and offload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timm.list_models(\"resnet*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seldon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add model switching etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('central')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2465c4f56298bc06dbdad3e7519856d346ec0e9edf6ba2c905f0af711583810e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
