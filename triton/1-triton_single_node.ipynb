{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### single node triton server with load test\n",
    "1. Loading to and from minio workflow (multiple models)\n",
    "2. Getting models from [timm](https://timm.fast.ai/)\n",
    "3. Making the node\n",
    "4. Load and unload models operations\n",
    "5. Monitoring\n",
    "6. Naive load test\n",
    "7. TODO Add language models from Huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cc/miniconda3/envs/central/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "739"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(timm.list_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('sudo umount -l ~/my_mounting_point')\n",
    "os.system('cc-cloudfuse mount ~/my_mounting_point')\n",
    "\n",
    "data_folder_path = '/home/cc/my_mounting_point/datasets'\n",
    "dataset_folder_path = os.path.join(\n",
    "    data_folder_path, 'ILSVRC/Data/DET/test'\n",
    ")\n",
    "classes_file_path = os.path.join(\n",
    "    data_folder_path, 'imagenet_classes.txt'\n",
    ")\n",
    "\n",
    "image_names = os.listdir(dataset_folder_path)\n",
    "image_names.sort()\n",
    "with open(classes_file_path) as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "def image_loader(folder_path, image_name):\n",
    "    image = Image.open(\n",
    "        os.path.join(folder_path, image_name))\n",
    "    # if there was a need to filter out only color images\n",
    "    # if image.mode == 'RGB':\n",
    "    #     pass\n",
    "    return image\n",
    "num_loaded_images = 4\n",
    "images = {\n",
    "    image_name: image_loader(\n",
    "        dataset_folder_path, image_name) for image_name in image_names[\n",
    "            :num_loaded_images]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and transform model\n",
    "from torchvision import transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")])\n",
    "\n",
    "batch = torch.stack(list(map(lambda a: transform(a), list(images.values()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and predict with the timm model\n",
    "model_name = 'resnet50'\n",
    "model = timm.create_model(model_name, pretrained=True)\n",
    "\n",
    "model.eval()\n",
    "torch_output = model(batch)\n",
    "torch_output = torch.nn.functional.softmax(torch_output, dim=1) * 100\n",
    "torch_output = torch_output.detach().numpy()\n",
    "torch_output = torch_output.argmax(axis=1)\n",
    "torch_class = np.array(classes)[torch_output]\n",
    "torch_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the onnx model\n",
    "import torch.onnx\n",
    "\n",
    "model_variant = 1\n",
    "model_dir = os.path.join(\n",
    "    'models',\n",
    "    model_name,\n",
    "    str(model_variant))\n",
    "model_path = os.path.join(model_dir, 'model.onnx')\n",
    "if 'models' not in os.listdir(\"./\"):\n",
    "    os.makedirs(model_dir)\n",
    "# Standard ImageNet input - 3 channels, 224x224,\n",
    "# values don't matter as we care about network structure.\n",
    "# But they can also be real inputs.\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "# Invoke export\n",
    "torch.onnx.export(\n",
    "    model, dummy_input,\n",
    "    model_path,\n",
    "    input_names = ['input'],\n",
    "    output_names = ['output'],\n",
    "    dynamic_axes={'input' : {0 : 'batch_size'},    # variable length axes\n",
    "                  'output' : {0 : 'batch_size'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use onnx model\n",
    "import onnx\n",
    "import onnxruntime\n",
    "\n",
    "onnx_model = onnx.load(model_path)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(\n",
    "    os.path.join(model_dir, \"model.onnx\"),\n",
    "    providers=['CPUExecutionProvider'])\n",
    "onnx_output = ort_session.run(None, {'input': batch.numpy()})\n",
    "onnx_output = torch.nn.functional.softmax(torch.tensor(onnx_output), dim=1)[0] * 100\n",
    "onnx_output = onnx_output.detach().numpy()\n",
    "onnx_output = onnx_output.argmax(axis=1)\n",
    "onnx_class = np.array(classes)[onnx_output]\n",
    "onnx_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/cc/infernece-pipeline-joint-optimization/triton/1-triton_single_node.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bchameleon/home/cc/infernece-pipeline-joint-optimization/triton/1-triton_single_node.ipynb#ch0000008vscode-remote?line=0'>1</a>\u001b[0m \u001b[39m# TODO find out why slightly different\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bchameleon/home/cc/infernece-pipeline-joint-optimization/triton/1-triton_single_node.ipynb#ch0000008vscode-remote?line=2'>3</a>\u001b[0m \u001b[39massert\u001b[39;00m np\u001b[39m.\u001b[39mall(onnx_output \u001b[39m==\u001b[39m torch_output)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bchameleon/home/cc/infernece-pipeline-joint-optimization/triton/1-triton_single_node.ipynb#ch0000008vscode-remote?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(onnx_class)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO find out why slightly different\n",
    "\n",
    "assert np.all(onnx_output == torch_output)\n",
    "print(onnx_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying on Onnx Docker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting models/resnet50/config.pbtxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile models/resnet50/config.pbtxt\n",
    "name: \"resnet50\"\n",
    "platform: \"onnxruntime_onnx\"\n",
    "max_batch_size : 100\n",
    "input [\n",
    "  {\n",
    "    name: \"input\"\n",
    "    data_type: TYPE_FP32\n",
    "    format: FORMAT_NCHW\n",
    "    dims: [ 3, 224, 224 ]\n",
    "  }\n",
    "]\n",
    "output [\n",
    "  {\n",
    "    name: \"output\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 1000 ]\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VERSION='22.05'\n",
    "os.system(f\"docker pull nvcr.io/nvidia/tritonserver:{VERSION}-py3\")\n",
    "# add --gpus=<number of gpus> on gpu machines\n",
    "# add -d to run at background and going to the next cell\n",
    "os.system(\"docker run --rm -d -p8000:8000 -p8001:8001 -p8002:8002\"\n",
    "          f\" -v {os.getcwd()}/models:/models \"\n",
    "          f\"nvcr.io/nvidia/tritonserver:{VERSION}-py3\"\n",
    "          \" tritonserver --model-repository=/models\")\n",
    "# print(\"docker run --rm -d -p8000:8000 -p8001:8001 -p8002:8002\"\n",
    "#       f\" -v {os.getcwd()}/models:/models \"\n",
    "#       f\"nvcr.io/nvidia/tritonserver:{VERSION}-py3\"\n",
    "#       \" tritonserver --strict-model-config=false --model-repository=/models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python Client Examples\n",
    "\n",
    "[examples](https://github.com/triton-inference-server/client/tree/main/src/python/examples)\n",
    "\n",
    "[grpc](https://github.com/triton-inference-server/client/blob/main/src/python/library/tritonclient/grpc/__init__.py)\n",
    "\n",
    "[http](https://github.com/triton-inference-server/client/blob/main/src/python/library/tritonclient/http/__init__.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonclient.http as httpclient\n",
    "from tritonclient.utils import InferenceServerException\n",
    "\n",
    "try:\n",
    "    triton_client = httpclient.InferenceServerClient(\n",
    "        url='localhost:8000', verbose=True\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"context creation failed: \" + str(e))\n",
    "model_name = \"resnet50\"\n",
    "\n",
    "inputs = []\n",
    "inputs.append(\n",
    "    httpclient.InferInput(name=\"input\", shape=batch[0:4].shape, datatype=\"FP32\")\n",
    ")\n",
    "inputs[0].set_data_from_numpy(batch[0:4].numpy(), binary_data=False)\n",
    "\n",
    "outputs = []\n",
    "outputs.append(httpclient.InferRequestedOutput(name=\"output\"))\n",
    "\n",
    "result = triton_client.infer(model_name=model_name, inputs=inputs, outputs=outputs)\n",
    "triton_client.close()\n",
    "triton_output = result.as_numpy('output')\n",
    "triton_output = torch.nn.functional.softmax(\n",
    "    torch.tensor(triton_output), dim=1) * 100\n",
    "triton_output = triton_output.detach().numpy()\n",
    "triton_output = triton_output.argmax(axis=1)\n",
    "triton_class = np.array(classes)[triton_output]\n",
    "triton_class\n",
    "\n",
    "# stop triton server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonclient.grpc as grpcclient\n",
    "from tritonclient.utils import InferenceServerException\n",
    "\n",
    "try:\n",
    "    triton_client = grpcclient.InferenceServerClient(\n",
    "        url='localhost:8001', verbose=True\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"context creation failed: \" + str(e))\n",
    "model_name = \"resnet50\"\n",
    "\n",
    "inputs = []\n",
    "inputs.append(\n",
    "    grpcclient.InferInput(name=\"input\", shape=batch[0:4].shape, datatype=\"FP32\")\n",
    ")\n",
    "inputs[0].set_data_from_numpy(batch[0:4].numpy())\n",
    "\n",
    "outputs = []\n",
    "outputs.append(grpcclient.InferRequestedOutput(name=\"output\"))\n",
    "\n",
    "result = triton_client.infer(model_name=model_name, inputs=inputs, outputs=outputs)\n",
    "triton_client.close()\n",
    "triton_output = result.as_numpy('output')\n",
    "triton_output = torch.nn.functional.softmax(\n",
    "    torch.tensor(triton_output), dim=1) * 100\n",
    "triton_output = triton_output.detach().numpy()\n",
    "triton_output = triton_output.argmax(axis=1)\n",
    "triton_class = np.array(classes)[triton_output]\n",
    "triton_class\n",
    "\n",
    "# stop triton server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Model/Model Switching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: \"resnet50\"\n",
      "platform: \"onnxruntime_onnx\"\n",
      "max_batch_size: 100\n",
      "  input [\n",
      "    {\n",
      "      name: \"input\"\n",
      "      data_type: TYPE_FP32\n",
      "      format: FORMAT_NCHW\n",
      "      dims: [ 3, 224, 224 ]\n",
      "    }\n",
      "  ]\n",
      "  output [\n",
      "    {\n",
      "      name: \"output\"\n",
      "      data_type: TYPE_FP32\n",
      "      dims: [ 1000 ]\n",
      "    }\n",
      "  ]\n",
      "  version_policy: { all { }}\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def config_builder(\n",
    "  name: str, platform: str, max_batch_size: int,\n",
    "  ):\n",
    "  config = (f\"name: \\\"{name}\\\"\\n\"\n",
    "            f\"platform: \\\"{platform}\\\"\\n\"\n",
    "            f\"max_batch_size: {str(max_batch_size)}\")\n",
    "  common_config=\"\"\"\n",
    "  input [\n",
    "    {\n",
    "      name: \"input\"\n",
    "      data_type: TYPE_FP32\n",
    "      format: FORMAT_NCHW\n",
    "      dims: [ 3, 224, 224 ]\n",
    "    }\n",
    "  ]\n",
    "  output [\n",
    "    {\n",
    "      name: \"output\"\n",
    "      data_type: TYPE_FP32\n",
    "      dims: [ 1000 ]\n",
    "    }\n",
    "  ]\n",
    "  version_policy: { all { }}\n",
    "  \"\"\"\n",
    "  return config + common_config\n",
    "\n",
    "print(config_builder('resnet50', 'onnxruntime_onnx', 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def generate_model_variants(model_name: str = 'resnet',\n",
    "    versions: list = ['18', '34', '101']):\n",
    "    # model name\n",
    "    timm_models = timm.list_models(model_name+'*', pretrained=True)\n",
    "    model_path = os.path.join(\n",
    "        'models',\n",
    "        model_name,\n",
    "    )\n",
    "    config_path = os.path.join(\n",
    "        model_path,\n",
    "        'config.pbtxt')\n",
    "    # if 'models' not in os.listdir(\"./\"):\n",
    "    os.makedirs(model_path)\n",
    "    config = config_builder(\n",
    "        name=model_name,\n",
    "        platform='onnxruntime_onnx',\n",
    "        max_batch_size=100)\n",
    "    with open(config_path, 'w') as f:\n",
    "        f.write(config)\n",
    "    for variant_id, model_variant in enumerate(versions):\n",
    "        model_full_name = model_name + model_variant\n",
    "        if not model_full_name in timm_models:\n",
    "            raise ValueError(\n",
    "                f\"Model {model_full_name} does not exist\"\n",
    "            )\n",
    "        model = timm.create_model(model_full_name, pretrained=True)\n",
    "        model.eval()\n",
    "        dummy_input = torch.randn(1, 3, 224, 224)\n",
    "        model_variant_dir = os.path.join(model_path, str(variant_id+1))\n",
    "        model_variant_path = os.path.join(model_variant_dir, 'model.onnx')\n",
    "        # if 'models' not in os.listdir(\"./\"):\n",
    "        os.makedirs(model_variant_dir)\n",
    "        torch.onnx.export(\n",
    "            model, dummy_input,\n",
    "            model_variant_path,\n",
    "            input_names = ['input'],\n",
    "            output_names = ['output'],\n",
    "            dynamic_axes={'input' : {0 : 'batch_size'},\n",
    "                          'output' : {0 : 'batch_size'}})\n",
    "\n",
    "def model_generator(\n",
    "    model_names: List[str],\n",
    "    versions: List[List[str]]):\n",
    "    assert len(model_names) == len(versions),\\\n",
    "        \"length modes list {} does not match versions list {}\".fromat(\n",
    "            len(model_names),\n",
    "            len(versions)\n",
    "        )\n",
    "    for model_name, version in zip(model_names, versions):\n",
    "        generate_model_variants(\n",
    "            model_name=model_name,\n",
    "            versions=version\n",
    "        )\n",
    "\n",
    "# read these from json/yamls build with a proper config builder\n",
    "model_generator(\n",
    "    model_names = ['resnet', 'xception'],\n",
    "    versions = [['18', '34', '101'], ['', '41', '65', '71']]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.05-py3: Pulling from nvidia/tritonserver\n",
      "Digest: sha256:a85daa2907f46e70b3782818a0331df62d9b4e0b1f15f1530b2a52c8c782d46d\n",
      "Status: Image is up to date for nvcr.io/nvidia/tritonserver:22.05-py3\n",
      "nvcr.io/nvidia/tritonserver:22.05-py3\n",
      "d22c74790ba886e0950cea3b9d64f0313911e0781db6313e8215c8f431899ce8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate models\n",
    "VERSION='22.05'\n",
    "os.system(f\"docker pull nvcr.io/nvidia/tritonserver:{VERSION}-py3\")\n",
    "# add --gpus=<number of gpus> on gpu machines\n",
    "# add -d to run at background and going to the next cell\n",
    "os.system(\"docker run --rm -d -p8000:8000 -p8001:8001 -p8002:8002\"\n",
    "          f\" -v {os.getcwd()}/models:/models \"\n",
    "          f\"nvcr.io/nvidia/tritonserver:{VERSION}-py3\"\n",
    "          \" tritonserver --model-repository=/models\")\n",
    "# print(\"docker run --rm -d -p8000:8000 -p8001:8001 -p8002:8002\"\n",
    "#       f\" -v {os.getcwd()}/models:/models \"\n",
    "#       f\"nvcr.io/nvidia/tritonserver:{VERSION}-py3\"\n",
    "#       \" tritonserver --strict-model-config=false --model-repository=/models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send request to multi-models\n",
    "import tritonclient.http as httpclient\n",
    "from tritonclient.utils import InferenceServerException\n",
    "\n",
    "\n",
    "model_version = \"1\"\n",
    "\n",
    "try:\n",
    "    triton_client = httpclient.InferenceServerClient(\n",
    "        url='localhost:8000', verbose=True\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"context creation failed: \" + str(e))\n",
    "model_name = \"resnet\"\n",
    "\n",
    "inputs = []\n",
    "inputs.append(\n",
    "    httpclient.InferInput(name=\"input\", shape=batch[0:4].shape, datatype=\"FP32\")\n",
    ")\n",
    "inputs[0].set_data_from_numpy(batch[0:4].numpy(), binary_data=False)\n",
    "\n",
    "outputs = []\n",
    "outputs.append(httpclient.InferRequestedOutput(name=\"output\"))\n",
    "\n",
    "result = triton_client.infer(\n",
    "    model_name=model_name,\n",
    "    model_version=model_version, # different form the older model\n",
    "    inputs=inputs, outputs=outputs)\n",
    "triton_client.close()\n",
    "# result.get_response()\n",
    "triton_output = result.as_numpy('output')\n",
    "triton_output = torch.nn.functional.softmax(\n",
    "    torch.tensor(triton_output), dim=1) * 100\n",
    "triton_output = triton_output.detach().numpy()\n",
    "triton_output = triton_output.argmax(axis=1)\n",
    "triton_class = np.array(classes)[triton_output]\n",
    "print(triton_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model load and offload/Model switching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST /v2/repository/index, headers None\n",
      "\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-type': 'application/json', 'content-length': '395'}>\n",
      "bytearray(b'[{\"name\":\"resnet\",\"version\":\"1\",\"state\":\"READY\"},{\"name\":\"resnet\",\"version\":\"2\",\"state\":\"READY\"},{\"name\":\"resnet\",\"version\":\"3\",\"state\":\"READY\"},{\"name\":\"resnet50\",\"version\":\"1\",\"state\":\"READY\"},{\"name\":\"xception\",\"version\":\"1\",\"state\":\"READY\"},{\"name\":\"xception\",\"version\":\"2\",\"state\":\"READY\"},{\"name\":\"xception\",\"version\":\"3\",\"state\":\"READY\"},{\"name\":\"xception\",\"version\":\"4\",\"state\":\"READY\"}]')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'name': 'resnet', 'version': '1', 'state': 'READY'},\n",
       " {'name': 'resnet', 'version': '2', 'state': 'READY'},\n",
       " {'name': 'resnet', 'version': '3', 'state': 'READY'},\n",
       " {'name': 'resnet50', 'version': '1', 'state': 'READY'},\n",
       " {'name': 'xception', 'version': '1', 'state': 'READY'},\n",
       " {'name': 'xception', 'version': '2', 'state': 'READY'},\n",
       " {'name': 'xception', 'version': '3', 'state': 'READY'},\n",
       " {'name': 'xception', 'version': '4', 'state': 'READY'}]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "import tritonclient.http as httpclient\n",
    "from tritonclient.utils import InferenceServerException\n",
    "\n",
    "\n",
    "try:\n",
    "    triton_client = httpclient.InferenceServerClient(\n",
    "        url='localhost:8000', verbose=True\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"context creation failed: \" + str(e))\n",
    "model_name = \"resnet\"\n",
    "\n",
    "\n",
    "print(20*'-' + 'active models' + 20*'-' + '\\n')\n",
    "print(triton_client.get_model_repository_index())\n",
    "\n",
    "print(20*'-' + f'unloading model: {model_name}' + 20*'-' + '\\n')\n",
    "print(triton_client.unload_model(model_name))\n",
    "\n",
    "\n",
    "# inputs = []\n",
    "# inputs.append(\n",
    "#     httpclient.InferInput(name=\"input\", shape=batch[0:4].shape, datatype=\"FP32\")\n",
    "# )\n",
    "# inputs[0].set_data_from_numpy(batch[0:4].numpy(), binary_data=False)\n",
    "\n",
    "# outputs = []\n",
    "# outputs.append(httpclient.InferRequestedOutput(name=\"output\"))\n",
    "\n",
    "# result = triton_client.infer(\n",
    "#     model_name=model_name,\n",
    "#     model_version=model_version, # different form the older model\n",
    "#     inputs=inputs, outputs=outputs)\n",
    "# triton_client.close()\n",
    "# # result.get_response()\n",
    "# triton_output = result.as_numpy('output')\n",
    "# triton_output = torch.nn.functional.softmax(\n",
    "#     torch.tensor(triton_output), dim=1) * 100\n",
    "# triton_output = triton_output.detach().numpy()\n",
    "# triton_output = triton_output.argmax(axis=1)\n",
    "# triton_class = np.array(classes)[triton_output]\n",
    "# print(triton_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POST /v2/repository/index, headers None\n",
      "\n",
      "<HTTPSocketPoolResponse status=200 headers={'content-type': 'application/json', 'content-length': '395'}>\n",
      "bytearray(b'[{\"name\":\"resnet\",\"version\":\"1\",\"state\":\"READY\"},{\"name\":\"resnet\",\"version\":\"2\",\"state\":\"READY\"},{\"name\":\"resnet\",\"version\":\"3\",\"state\":\"READY\"},{\"name\":\"resnet50\",\"version\":\"1\",\"state\":\"READY\"},{\"name\":\"xception\",\"version\":\"1\",\"state\":\"READY\"},{\"name\":\"xception\",\"version\":\"2\",\"state\":\"READY\"},{\"name\":\"xception\",\"version\":\"3\",\"state\":\"READY\"},{\"name\":\"xception\",\"version\":\"4\",\"state\":\"READY\"}]')\n",
      "[{'name': 'resnet', 'version': '1', 'state': 'READY'}, {'name': 'resnet', 'version': '2', 'state': 'READY'}, {'name': 'resnet', 'version': '3', 'state': 'READY'}, {'name': 'resnet50', 'version': '1', 'state': 'READY'}, {'name': 'xception', 'version': '1', 'state': 'READY'}, {'name': 'xception', 'version': '2', 'state': 'READY'}, {'name': 'xception', 'version': '3', 'state': 'READY'}, {'name': 'xception', 'version': '4', 'state': 'READY'}]\n"
     ]
    }
   ],
   "source": [
    "print(triton_client.get_model_repository_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seldon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adv_inception_v3',\n",
       " 'bat_resnext26ts',\n",
       " 'beit_base_patch16_224',\n",
       " 'beit_base_patch16_224_in22k',\n",
       " 'beit_base_patch16_384',\n",
       " 'beit_large_patch16_224',\n",
       " 'beit_large_patch16_224_in22k',\n",
       " 'beit_large_patch16_384',\n",
       " 'beit_large_patch16_512',\n",
       " 'botnet26t_256',\n",
       " 'cait_m36_384',\n",
       " 'cait_m48_448',\n",
       " 'cait_s24_224',\n",
       " 'cait_s24_384',\n",
       " 'cait_s36_384',\n",
       " 'cait_xs24_384',\n",
       " 'cait_xxs24_224',\n",
       " 'cait_xxs24_384',\n",
       " 'cait_xxs36_224',\n",
       " 'cait_xxs36_384',\n",
       " 'coat_lite_mini',\n",
       " 'coat_lite_small',\n",
       " 'coat_lite_tiny',\n",
       " 'coat_mini',\n",
       " 'coat_tiny',\n",
       " 'convit_base',\n",
       " 'convit_small',\n",
       " 'convit_tiny',\n",
       " 'convmixer_768_32',\n",
       " 'convmixer_1024_20_ks9_p14',\n",
       " 'convmixer_1536_20',\n",
       " 'convnext_base',\n",
       " 'convnext_base_384_in22ft1k',\n",
       " 'convnext_base_in22ft1k',\n",
       " 'convnext_base_in22k',\n",
       " 'convnext_large',\n",
       " 'convnext_large_384_in22ft1k',\n",
       " 'convnext_large_in22ft1k',\n",
       " 'convnext_large_in22k',\n",
       " 'convnext_small',\n",
       " 'convnext_tiny',\n",
       " 'convnext_xlarge_384_in22ft1k',\n",
       " 'convnext_xlarge_in22ft1k',\n",
       " 'convnext_xlarge_in22k',\n",
       " 'crossvit_9_240',\n",
       " 'crossvit_9_dagger_240',\n",
       " 'crossvit_15_240',\n",
       " 'crossvit_15_dagger_240',\n",
       " 'crossvit_15_dagger_408',\n",
       " 'crossvit_18_240',\n",
       " 'crossvit_18_dagger_240',\n",
       " 'crossvit_18_dagger_408',\n",
       " 'crossvit_base_240',\n",
       " 'crossvit_small_240',\n",
       " 'crossvit_tiny_240',\n",
       " 'cspdarknet53',\n",
       " 'cspresnet50',\n",
       " 'cspresnext50',\n",
       " 'deit_base_distilled_patch16_224',\n",
       " 'deit_base_distilled_patch16_384',\n",
       " 'deit_base_patch16_224',\n",
       " 'deit_base_patch16_384',\n",
       " 'deit_small_distilled_patch16_224',\n",
       " 'deit_small_patch16_224',\n",
       " 'deit_tiny_distilled_patch16_224',\n",
       " 'deit_tiny_patch16_224',\n",
       " 'densenet121',\n",
       " 'densenet161',\n",
       " 'densenet169',\n",
       " 'densenet201',\n",
       " 'densenetblur121d',\n",
       " 'dla34',\n",
       " 'dla46_c',\n",
       " 'dla46x_c',\n",
       " 'dla60',\n",
       " 'dla60_res2net',\n",
       " 'dla60_res2next',\n",
       " 'dla60x',\n",
       " 'dla60x_c',\n",
       " 'dla102',\n",
       " 'dla102x',\n",
       " 'dla102x2',\n",
       " 'dla169',\n",
       " 'dm_nfnet_f0',\n",
       " 'dm_nfnet_f1',\n",
       " 'dm_nfnet_f2',\n",
       " 'dm_nfnet_f3',\n",
       " 'dm_nfnet_f4',\n",
       " 'dm_nfnet_f5',\n",
       " 'dm_nfnet_f6',\n",
       " 'dpn68',\n",
       " 'dpn68b',\n",
       " 'dpn92',\n",
       " 'dpn98',\n",
       " 'dpn107',\n",
       " 'dpn131',\n",
       " 'eca_botnext26ts_256',\n",
       " 'eca_halonext26ts',\n",
       " 'eca_nfnet_l0',\n",
       " 'eca_nfnet_l1',\n",
       " 'eca_nfnet_l2',\n",
       " 'eca_resnet33ts',\n",
       " 'eca_resnext26ts',\n",
       " 'ecaresnet26t',\n",
       " 'ecaresnet50d',\n",
       " 'ecaresnet50d_pruned',\n",
       " 'ecaresnet50t',\n",
       " 'ecaresnet101d',\n",
       " 'ecaresnet101d_pruned',\n",
       " 'ecaresnet269d',\n",
       " 'ecaresnetlight',\n",
       " 'efficientnet_b0',\n",
       " 'efficientnet_b1',\n",
       " 'efficientnet_b1_pruned',\n",
       " 'efficientnet_b2',\n",
       " 'efficientnet_b2_pruned',\n",
       " 'efficientnet_b3',\n",
       " 'efficientnet_b3_pruned',\n",
       " 'efficientnet_b4',\n",
       " 'efficientnet_el',\n",
       " 'efficientnet_el_pruned',\n",
       " 'efficientnet_em',\n",
       " 'efficientnet_es',\n",
       " 'efficientnet_es_pruned',\n",
       " 'efficientnet_lite0',\n",
       " 'efficientnetv2_rw_m',\n",
       " 'efficientnetv2_rw_s',\n",
       " 'efficientnetv2_rw_t',\n",
       " 'ens_adv_inception_resnet_v2',\n",
       " 'ese_vovnet19b_dw',\n",
       " 'ese_vovnet39b',\n",
       " 'fbnetc_100',\n",
       " 'fbnetv3_b',\n",
       " 'fbnetv3_d',\n",
       " 'fbnetv3_g',\n",
       " 'gc_efficientnetv2_rw_t',\n",
       " 'gcresnet33ts',\n",
       " 'gcresnet50t',\n",
       " 'gcresnext26ts',\n",
       " 'gcresnext50ts',\n",
       " 'gernet_l',\n",
       " 'gernet_m',\n",
       " 'gernet_s',\n",
       " 'ghostnet_100',\n",
       " 'gluon_inception_v3',\n",
       " 'gluon_resnet18_v1b',\n",
       " 'gluon_resnet34_v1b',\n",
       " 'gluon_resnet50_v1b',\n",
       " 'gluon_resnet50_v1c',\n",
       " 'gluon_resnet50_v1d',\n",
       " 'gluon_resnet50_v1s',\n",
       " 'gluon_resnet101_v1b',\n",
       " 'gluon_resnet101_v1c',\n",
       " 'gluon_resnet101_v1d',\n",
       " 'gluon_resnet101_v1s',\n",
       " 'gluon_resnet152_v1b',\n",
       " 'gluon_resnet152_v1c',\n",
       " 'gluon_resnet152_v1d',\n",
       " 'gluon_resnet152_v1s',\n",
       " 'gluon_resnext50_32x4d',\n",
       " 'gluon_resnext101_32x4d',\n",
       " 'gluon_resnext101_64x4d',\n",
       " 'gluon_senet154',\n",
       " 'gluon_seresnext50_32x4d',\n",
       " 'gluon_seresnext101_32x4d',\n",
       " 'gluon_seresnext101_64x4d',\n",
       " 'gluon_xception65',\n",
       " 'gmixer_24_224',\n",
       " 'gmlp_s16_224',\n",
       " 'halo2botnet50ts_256',\n",
       " 'halonet26t',\n",
       " 'halonet50ts',\n",
       " 'haloregnetz_b',\n",
       " 'hardcorenas_a',\n",
       " 'hardcorenas_b',\n",
       " 'hardcorenas_c',\n",
       " 'hardcorenas_d',\n",
       " 'hardcorenas_e',\n",
       " 'hardcorenas_f',\n",
       " 'hrnet_w18',\n",
       " 'hrnet_w18_small',\n",
       " 'hrnet_w18_small_v2',\n",
       " 'hrnet_w30',\n",
       " 'hrnet_w32',\n",
       " 'hrnet_w40',\n",
       " 'hrnet_w44',\n",
       " 'hrnet_w48',\n",
       " 'hrnet_w64',\n",
       " 'ig_resnext101_32x8d',\n",
       " 'ig_resnext101_32x16d',\n",
       " 'ig_resnext101_32x32d',\n",
       " 'ig_resnext101_32x48d',\n",
       " 'inception_resnet_v2',\n",
       " 'inception_v3',\n",
       " 'inception_v4',\n",
       " 'jx_nest_base',\n",
       " 'jx_nest_small',\n",
       " 'jx_nest_tiny',\n",
       " 'lambda_resnet26rpt_256',\n",
       " 'lambda_resnet26t',\n",
       " 'lambda_resnet50ts',\n",
       " 'lamhalobotnet50ts_256',\n",
       " 'lcnet_050',\n",
       " 'lcnet_075',\n",
       " 'lcnet_100',\n",
       " 'legacy_senet154',\n",
       " 'legacy_seresnet18',\n",
       " 'legacy_seresnet34',\n",
       " 'legacy_seresnet50',\n",
       " 'legacy_seresnet101',\n",
       " 'legacy_seresnet152',\n",
       " 'legacy_seresnext26_32x4d',\n",
       " 'legacy_seresnext50_32x4d',\n",
       " 'legacy_seresnext101_32x4d',\n",
       " 'levit_128',\n",
       " 'levit_128s',\n",
       " 'levit_192',\n",
       " 'levit_256',\n",
       " 'levit_384',\n",
       " 'mixer_b16_224',\n",
       " 'mixer_b16_224_in21k',\n",
       " 'mixer_b16_224_miil',\n",
       " 'mixer_b16_224_miil_in21k',\n",
       " 'mixer_l16_224',\n",
       " 'mixer_l16_224_in21k',\n",
       " 'mixnet_l',\n",
       " 'mixnet_m',\n",
       " 'mixnet_s',\n",
       " 'mixnet_xl',\n",
       " 'mnasnet_100',\n",
       " 'mnasnet_small',\n",
       " 'mobilenetv2_050',\n",
       " 'mobilenetv2_100',\n",
       " 'mobilenetv2_110d',\n",
       " 'mobilenetv2_120d',\n",
       " 'mobilenetv2_140',\n",
       " 'mobilenetv3_large_100',\n",
       " 'mobilenetv3_large_100_miil',\n",
       " 'mobilenetv3_large_100_miil_in21k',\n",
       " 'mobilenetv3_rw',\n",
       " 'nasnetalarge',\n",
       " 'nf_regnet_b1',\n",
       " 'nf_resnet50',\n",
       " 'nfnet_l0',\n",
       " 'pit_b_224',\n",
       " 'pit_b_distilled_224',\n",
       " 'pit_s_224',\n",
       " 'pit_s_distilled_224',\n",
       " 'pit_ti_224',\n",
       " 'pit_ti_distilled_224',\n",
       " 'pit_xs_224',\n",
       " 'pit_xs_distilled_224',\n",
       " 'pnasnet5large',\n",
       " 'regnetx_002',\n",
       " 'regnetx_004',\n",
       " 'regnetx_006',\n",
       " 'regnetx_008',\n",
       " 'regnetx_016',\n",
       " 'regnetx_032',\n",
       " 'regnetx_040',\n",
       " 'regnetx_064',\n",
       " 'regnetx_080',\n",
       " 'regnetx_120',\n",
       " 'regnetx_160',\n",
       " 'regnetx_320',\n",
       " 'regnety_002',\n",
       " 'regnety_004',\n",
       " 'regnety_006',\n",
       " 'regnety_008',\n",
       " 'regnety_016',\n",
       " 'regnety_032',\n",
       " 'regnety_040',\n",
       " 'regnety_064',\n",
       " 'regnety_080',\n",
       " 'regnety_120',\n",
       " 'regnety_160',\n",
       " 'regnety_320',\n",
       " 'regnetz_b16',\n",
       " 'regnetz_c16',\n",
       " 'regnetz_d8',\n",
       " 'regnetz_d32',\n",
       " 'regnetz_e8',\n",
       " 'repvgg_a2',\n",
       " 'repvgg_b0',\n",
       " 'repvgg_b1',\n",
       " 'repvgg_b1g4',\n",
       " 'repvgg_b2',\n",
       " 'repvgg_b2g4',\n",
       " 'repvgg_b3',\n",
       " 'repvgg_b3g4',\n",
       " 'res2net50_14w_8s',\n",
       " 'res2net50_26w_4s',\n",
       " 'res2net50_26w_6s',\n",
       " 'res2net50_26w_8s',\n",
       " 'res2net50_48w_2s',\n",
       " 'res2net101_26w_4s',\n",
       " 'res2next50',\n",
       " 'resmlp_12_224',\n",
       " 'resmlp_12_224_dino',\n",
       " 'resmlp_12_distilled_224',\n",
       " 'resmlp_24_224',\n",
       " 'resmlp_24_224_dino',\n",
       " 'resmlp_24_distilled_224',\n",
       " 'resmlp_36_224',\n",
       " 'resmlp_36_distilled_224',\n",
       " 'resmlp_big_24_224',\n",
       " 'resmlp_big_24_224_in22ft1k',\n",
       " 'resmlp_big_24_distilled_224',\n",
       " 'resnest14d',\n",
       " 'resnest26d',\n",
       " 'resnest50d',\n",
       " 'resnest50d_1s4x24d',\n",
       " 'resnest50d_4s2x40d',\n",
       " 'resnest101e',\n",
       " 'resnest200e',\n",
       " 'resnest269e',\n",
       " 'resnet18',\n",
       " 'resnet18d',\n",
       " 'resnet26',\n",
       " 'resnet26d',\n",
       " 'resnet26t',\n",
       " 'resnet32ts',\n",
       " 'resnet33ts',\n",
       " 'resnet34',\n",
       " 'resnet34d',\n",
       " 'resnet50',\n",
       " 'resnet50_gn',\n",
       " 'resnet50d',\n",
       " 'resnet51q',\n",
       " 'resnet61q',\n",
       " 'resnet101',\n",
       " 'resnet101d',\n",
       " 'resnet152',\n",
       " 'resnet152d',\n",
       " 'resnet200d',\n",
       " 'resnetblur50',\n",
       " 'resnetrs50',\n",
       " 'resnetrs101',\n",
       " 'resnetrs152',\n",
       " 'resnetrs200',\n",
       " 'resnetrs270',\n",
       " 'resnetrs350',\n",
       " 'resnetrs420',\n",
       " 'resnetv2_50',\n",
       " 'resnetv2_50x1_bit_distilled',\n",
       " 'resnetv2_50x1_bitm',\n",
       " 'resnetv2_50x1_bitm_in21k',\n",
       " 'resnetv2_50x3_bitm',\n",
       " 'resnetv2_50x3_bitm_in21k',\n",
       " 'resnetv2_101',\n",
       " 'resnetv2_101x1_bitm',\n",
       " 'resnetv2_101x1_bitm_in21k',\n",
       " 'resnetv2_101x3_bitm',\n",
       " 'resnetv2_101x3_bitm_in21k',\n",
       " 'resnetv2_152x2_bit_teacher',\n",
       " 'resnetv2_152x2_bit_teacher_384',\n",
       " 'resnetv2_152x2_bitm',\n",
       " 'resnetv2_152x2_bitm_in21k',\n",
       " 'resnetv2_152x4_bitm',\n",
       " 'resnetv2_152x4_bitm_in21k',\n",
       " 'resnext26ts',\n",
       " 'resnext50_32x4d',\n",
       " 'resnext50d_32x4d',\n",
       " 'resnext101_32x8d',\n",
       " 'rexnet_100',\n",
       " 'rexnet_130',\n",
       " 'rexnet_150',\n",
       " 'rexnet_200',\n",
       " 'sebotnet33ts_256',\n",
       " 'sehalonet33ts',\n",
       " 'selecsls42b',\n",
       " 'selecsls60',\n",
       " 'selecsls60b',\n",
       " 'semnasnet_075',\n",
       " 'semnasnet_100',\n",
       " 'seresnet33ts',\n",
       " 'seresnet50',\n",
       " 'seresnet152d',\n",
       " 'seresnext26d_32x4d',\n",
       " 'seresnext26t_32x4d',\n",
       " 'seresnext26ts',\n",
       " 'seresnext50_32x4d',\n",
       " 'skresnet18',\n",
       " 'skresnet34',\n",
       " 'skresnext50_32x4d',\n",
       " 'spnasnet_100',\n",
       " 'ssl_resnet18',\n",
       " 'ssl_resnet50',\n",
       " 'ssl_resnext50_32x4d',\n",
       " 'ssl_resnext101_32x4d',\n",
       " 'ssl_resnext101_32x8d',\n",
       " 'ssl_resnext101_32x16d',\n",
       " 'swin_base_patch4_window7_224',\n",
       " 'swin_base_patch4_window7_224_in22k',\n",
       " 'swin_base_patch4_window12_384',\n",
       " 'swin_base_patch4_window12_384_in22k',\n",
       " 'swin_large_patch4_window7_224',\n",
       " 'swin_large_patch4_window7_224_in22k',\n",
       " 'swin_large_patch4_window12_384',\n",
       " 'swin_large_patch4_window12_384_in22k',\n",
       " 'swin_small_patch4_window7_224',\n",
       " 'swin_tiny_patch4_window7_224',\n",
       " 'swsl_resnet18',\n",
       " 'swsl_resnet50',\n",
       " 'swsl_resnext50_32x4d',\n",
       " 'swsl_resnext101_32x4d',\n",
       " 'swsl_resnext101_32x8d',\n",
       " 'swsl_resnext101_32x16d',\n",
       " 'tf_efficientnet_b0',\n",
       " 'tf_efficientnet_b0_ap',\n",
       " 'tf_efficientnet_b0_ns',\n",
       " 'tf_efficientnet_b1',\n",
       " 'tf_efficientnet_b1_ap',\n",
       " 'tf_efficientnet_b1_ns',\n",
       " 'tf_efficientnet_b2',\n",
       " 'tf_efficientnet_b2_ap',\n",
       " 'tf_efficientnet_b2_ns',\n",
       " 'tf_efficientnet_b3',\n",
       " 'tf_efficientnet_b3_ap',\n",
       " 'tf_efficientnet_b3_ns',\n",
       " 'tf_efficientnet_b4',\n",
       " 'tf_efficientnet_b4_ap',\n",
       " 'tf_efficientnet_b4_ns',\n",
       " 'tf_efficientnet_b5',\n",
       " 'tf_efficientnet_b5_ap',\n",
       " 'tf_efficientnet_b5_ns',\n",
       " 'tf_efficientnet_b6',\n",
       " 'tf_efficientnet_b6_ap',\n",
       " 'tf_efficientnet_b6_ns',\n",
       " 'tf_efficientnet_b7',\n",
       " 'tf_efficientnet_b7_ap',\n",
       " 'tf_efficientnet_b7_ns',\n",
       " 'tf_efficientnet_b8',\n",
       " 'tf_efficientnet_b8_ap',\n",
       " 'tf_efficientnet_cc_b0_4e',\n",
       " 'tf_efficientnet_cc_b0_8e',\n",
       " 'tf_efficientnet_cc_b1_8e',\n",
       " 'tf_efficientnet_el',\n",
       " 'tf_efficientnet_em',\n",
       " 'tf_efficientnet_es',\n",
       " 'tf_efficientnet_l2_ns',\n",
       " 'tf_efficientnet_l2_ns_475',\n",
       " 'tf_efficientnet_lite0',\n",
       " 'tf_efficientnet_lite1',\n",
       " 'tf_efficientnet_lite2',\n",
       " 'tf_efficientnet_lite3',\n",
       " 'tf_efficientnet_lite4',\n",
       " 'tf_efficientnetv2_b0',\n",
       " 'tf_efficientnetv2_b1',\n",
       " 'tf_efficientnetv2_b2',\n",
       " 'tf_efficientnetv2_b3',\n",
       " 'tf_efficientnetv2_l',\n",
       " 'tf_efficientnetv2_l_in21ft1k',\n",
       " 'tf_efficientnetv2_l_in21k',\n",
       " 'tf_efficientnetv2_m',\n",
       " 'tf_efficientnetv2_m_in21ft1k',\n",
       " 'tf_efficientnetv2_m_in21k',\n",
       " 'tf_efficientnetv2_s',\n",
       " 'tf_efficientnetv2_s_in21ft1k',\n",
       " 'tf_efficientnetv2_s_in21k',\n",
       " 'tf_efficientnetv2_xl_in21ft1k',\n",
       " 'tf_efficientnetv2_xl_in21k',\n",
       " 'tf_inception_v3',\n",
       " 'tf_mixnet_l',\n",
       " 'tf_mixnet_m',\n",
       " 'tf_mixnet_s',\n",
       " 'tf_mobilenetv3_large_075',\n",
       " 'tf_mobilenetv3_large_100',\n",
       " 'tf_mobilenetv3_large_minimal_100',\n",
       " 'tf_mobilenetv3_small_075',\n",
       " 'tf_mobilenetv3_small_100',\n",
       " 'tf_mobilenetv3_small_minimal_100',\n",
       " 'tinynet_a',\n",
       " 'tinynet_b',\n",
       " 'tinynet_c',\n",
       " 'tinynet_d',\n",
       " 'tinynet_e',\n",
       " 'tnt_s_patch16_224',\n",
       " 'tresnet_l',\n",
       " 'tresnet_l_448',\n",
       " 'tresnet_m',\n",
       " 'tresnet_m_448',\n",
       " 'tresnet_m_miil_in21k',\n",
       " 'tresnet_xl',\n",
       " 'tresnet_xl_448',\n",
       " 'tv_densenet121',\n",
       " 'tv_resnet34',\n",
       " 'tv_resnet50',\n",
       " 'tv_resnet101',\n",
       " 'tv_resnet152',\n",
       " 'tv_resnext50_32x4d',\n",
       " 'twins_pcpvt_base',\n",
       " 'twins_pcpvt_large',\n",
       " 'twins_pcpvt_small',\n",
       " 'twins_svt_base',\n",
       " 'twins_svt_large',\n",
       " 'twins_svt_small',\n",
       " 'vgg11',\n",
       " 'vgg11_bn',\n",
       " 'vgg13',\n",
       " 'vgg13_bn',\n",
       " 'vgg16',\n",
       " 'vgg16_bn',\n",
       " 'vgg19',\n",
       " 'vgg19_bn',\n",
       " 'visformer_small',\n",
       " 'vit_base_patch8_224',\n",
       " 'vit_base_patch8_224_in21k',\n",
       " 'vit_base_patch16_224',\n",
       " 'vit_base_patch16_224_in21k',\n",
       " 'vit_base_patch16_224_miil',\n",
       " 'vit_base_patch16_224_miil_in21k',\n",
       " 'vit_base_patch16_384',\n",
       " 'vit_base_patch16_sam_224',\n",
       " 'vit_base_patch32_224',\n",
       " 'vit_base_patch32_224_in21k',\n",
       " 'vit_base_patch32_384',\n",
       " 'vit_base_patch32_sam_224',\n",
       " 'vit_base_r50_s16_224_in21k',\n",
       " 'vit_base_r50_s16_384',\n",
       " 'vit_huge_patch14_224_in21k',\n",
       " 'vit_large_patch16_224',\n",
       " 'vit_large_patch16_224_in21k',\n",
       " 'vit_large_patch16_384',\n",
       " 'vit_large_patch32_224_in21k',\n",
       " 'vit_large_patch32_384',\n",
       " 'vit_large_r50_s32_224',\n",
       " 'vit_large_r50_s32_224_in21k',\n",
       " 'vit_large_r50_s32_384',\n",
       " 'vit_small_patch16_224',\n",
       " 'vit_small_patch16_224_in21k',\n",
       " 'vit_small_patch16_384',\n",
       " 'vit_small_patch32_224',\n",
       " 'vit_small_patch32_224_in21k',\n",
       " 'vit_small_patch32_384',\n",
       " 'vit_small_r26_s32_224',\n",
       " 'vit_small_r26_s32_224_in21k',\n",
       " 'vit_small_r26_s32_384',\n",
       " 'vit_tiny_patch16_224',\n",
       " 'vit_tiny_patch16_224_in21k',\n",
       " 'vit_tiny_patch16_384',\n",
       " 'vit_tiny_r_s16_p8_224',\n",
       " 'vit_tiny_r_s16_p8_224_in21k',\n",
       " 'vit_tiny_r_s16_p8_384',\n",
       " 'wide_resnet50_2',\n",
       " 'wide_resnet101_2',\n",
       " 'xception',\n",
       " 'xception41',\n",
       " 'xception65',\n",
       " 'xception71',\n",
       " 'xcit_large_24_p8_224',\n",
       " 'xcit_large_24_p8_224_dist',\n",
       " 'xcit_large_24_p8_384_dist',\n",
       " 'xcit_large_24_p16_224',\n",
       " 'xcit_large_24_p16_224_dist',\n",
       " 'xcit_large_24_p16_384_dist',\n",
       " 'xcit_medium_24_p8_224',\n",
       " 'xcit_medium_24_p8_224_dist',\n",
       " 'xcit_medium_24_p8_384_dist',\n",
       " 'xcit_medium_24_p16_224',\n",
       " 'xcit_medium_24_p16_224_dist',\n",
       " 'xcit_medium_24_p16_384_dist',\n",
       " 'xcit_nano_12_p8_224',\n",
       " 'xcit_nano_12_p8_224_dist',\n",
       " 'xcit_nano_12_p8_384_dist',\n",
       " 'xcit_nano_12_p16_224',\n",
       " 'xcit_nano_12_p16_224_dist',\n",
       " 'xcit_nano_12_p16_384_dist',\n",
       " 'xcit_small_12_p8_224',\n",
       " 'xcit_small_12_p8_224_dist',\n",
       " 'xcit_small_12_p8_384_dist',\n",
       " 'xcit_small_12_p16_224',\n",
       " 'xcit_small_12_p16_224_dist',\n",
       " 'xcit_small_12_p16_384_dist',\n",
       " 'xcit_small_24_p8_224',\n",
       " 'xcit_small_24_p8_224_dist',\n",
       " 'xcit_small_24_p8_384_dist',\n",
       " 'xcit_small_24_p16_224',\n",
       " 'xcit_small_24_p16_224_dist',\n",
       " 'xcit_small_24_p16_384_dist',\n",
       " 'xcit_tiny_12_p8_224',\n",
       " 'xcit_tiny_12_p8_224_dist',\n",
       " 'xcit_tiny_12_p8_384_dist',\n",
       " 'xcit_tiny_12_p16_224',\n",
       " 'xcit_tiny_12_p16_224_dist',\n",
       " 'xcit_tiny_12_p16_384_dist',\n",
       " 'xcit_tiny_24_p8_224',\n",
       " 'xcit_tiny_24_p8_224_dist',\n",
       " 'xcit_tiny_24_p8_384_dist',\n",
       " 'xcit_tiny_24_p16_224',\n",
       " 'xcit_tiny_24_p16_224_dist',\n",
       " 'xcit_tiny_24_p16_384_dist']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy models to the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('central')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2465c4f56298bc06dbdad3e7519856d346ec0e9edf6ba2c905f0af711583810e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
