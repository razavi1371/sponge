{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pprint import PrettyPrinter\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "\n",
    "pp = PrettyPrinter(indent=4)\n",
    "from barazmoon.twitter import twitter_workload_generator\n",
    "\n",
    "# get an absolute path to the directory that contains parent files\n",
    "__file__ = globals()[\"_dh\"][0]\n",
    "project_dir = __file__ = globals()[\"_dh\"][0]\n",
    "sys.path.append(os.path.normpath(os.path.join(project_dir, \"..\", \"..\", \"..\")))\n",
    "\n",
    "from experiments.utils.constants import FINAL_RESULTS_PATH, FIGURES_PATH\n",
    "from experiments.utils.parser import AdaptationParser\n",
    "import experiments.utils.drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaserieses = [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
    "serieses = [1, 2, 3, 21, 22, 23, 41, 42, 43, 61, 62, 63, 81, 82, 83]\n",
    "\n",
    "series_meta = {\n",
    "    \"resource-priorotize\": {\n",
    "        \"video\": 1,\n",
    "        \"audio-qa\": 21,\n",
    "        \"audio-sent\": 41,\n",
    "        \"sum-qa\": 61,\n",
    "        \"nlp\": 81,\n",
    "    },\n",
    "    \"balance\": {\"video\": 2, \"audio-qa\": 22, \"audio-sent\": 42, \"sum-qa\": 62, \"nlp\": 82},\n",
    "    \"accuracy-priorotize\": {\n",
    "        \"video\": 3,\n",
    "        \"audio-qa\": 23,\n",
    "        \"audio-sent\": 43,\n",
    "        \"sum-qa\": 63,\n",
    "        \"nlp\": 83,\n",
    "    },\n",
    "}\n",
    "\n",
    "series_paths = {\n",
    "    series: os.path.join(\n",
    "        FINAL_RESULTS_PATH, \"metaseries\", str(metaseries), \"series\", str(series)\n",
    "    )\n",
    "    for series, metaseries in zip(serieses, metaserieses)\n",
    "}\n",
    "\n",
    "loaders = {\n",
    "    series: AdaptationParser(\n",
    "        series_path=series_path, model_name=\"nlp\", type_of=\"router_pipeline\"\n",
    "    )\n",
    "    for series, series_path in series_paths.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/1',\n",
       " 2: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/2',\n",
       " 3: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/3',\n",
       " 21: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/21',\n",
       " 22: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/22',\n",
       " 23: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/23',\n",
       " 41: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/41',\n",
       " 42: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/42',\n",
       " 43: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/43',\n",
       " 61: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/61',\n",
       " 62: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/62',\n",
       " 63: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/63',\n",
       " 81: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/81',\n",
       " 82: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/82',\n",
       " 83: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/83'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: <experiments.utils.parser.AdaptationParser at 0x7efd684020d0>,\n",
       " 2: <experiments.utils.parser.AdaptationParser at 0x7efe343d8c10>,\n",
       " 3: <experiments.utils.parser.AdaptationParser at 0x7efe343d8d60>,\n",
       " 21: <experiments.utils.parser.AdaptationParser at 0x7efd68468dc0>,\n",
       " 22: <experiments.utils.parser.AdaptationParser at 0x7efe343cff10>,\n",
       " 23: <experiments.utils.parser.AdaptationParser at 0x7efe3409dc70>,\n",
       " 41: <experiments.utils.parser.AdaptationParser at 0x7efd6840a490>,\n",
       " 42: <experiments.utils.parser.AdaptationParser at 0x7efd68157250>,\n",
       " 43: <experiments.utils.parser.AdaptationParser at 0x7efd6814c0a0>,\n",
       " 61: <experiments.utils.parser.AdaptationParser at 0x7efe343df190>,\n",
       " 62: <experiments.utils.parser.AdaptationParser at 0x7efe343ca610>,\n",
       " 63: <experiments.utils.parser.AdaptationParser at 0x7efe343ca460>,\n",
       " 81: <experiments.utils.parser.AdaptationParser at 0x7efe343ca760>,\n",
       " 82: <experiments.utils.parser.AdaptationParser at 0x7efe343d8bb0>,\n",
       " 83: <experiments.utils.parser.AdaptationParser at 0x7efe343d8d30>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "series: 1 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 2,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 8,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.125,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 10,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': ['yolov5n', 'resnet18'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['yolo', 'resnet-human'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'image',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'yolov5n',\n",
      "                     'node_name': 'yolo',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'resnet18',\n",
      "                     'node_name': 'resnet-human',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'video',\n",
      "    'pipeline_name': 'video',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [71, 72],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 1,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['crop', 'classification'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 4,\n",
      "    'throughput_margin': 0,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 2 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 2,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 8,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 1,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 10,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': ['yolov5n', 'resnet18'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['yolo', 'resnet-human'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'image',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'yolov5n',\n",
      "                     'node_name': 'yolo',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'resnet18',\n",
      "                     'node_name': 'resnet-human',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'video',\n",
      "    'pipeline_name': 'video',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [71, 72],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 2,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['crop', 'classification'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 4,\n",
      "    'throughput_margin': 0,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 3 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 0.125,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 8,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 2,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 10,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': ['yolov5n', 'resnet18'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['yolo', 'resnet-human'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'image',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'yolov5n',\n",
      "                     'node_name': 'yolo',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'resnet18',\n",
      "                     'node_name': 'resnet-human',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'video',\n",
      "    'pipeline_name': 'video',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [71, 72],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 3,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['crop', 'classification'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 4,\n",
      "    'throughput_margin': 0,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 21 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.125,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib - redo of '\n",
      "                'metaseries bursty on chameleon to check latencies',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-qa',\n",
      "    'pipeline_name': 'audio-qa',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [85, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 21,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-qa'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 22 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib - redo of '\n",
      "                'metaseries bursty on chameleon to check latencies',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-qa',\n",
      "    'pipeline_name': 'audio-qa',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [85, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 22,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-qa'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 23 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 0.125,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 10,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib - redo of '\n",
      "                'metaseries bursty on chameleon to check latencies',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-qa',\n",
      "    'pipeline_name': 'audio-qa',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [85, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 23,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-qa'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 41 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.125,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'distilbert-base-uncased-finetuned-sst-2-english'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-sent'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'distilbert-base-uncased-finetuned-sst-2-english',\n",
      "                     'node_name': 'nlp-sent',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-sent',\n",
      "    'pipeline_name': 'audio-sent',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [87, 88],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 41,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-sent'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 42 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'distilbert-base-uncased-finetuned-sst-2-english'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-sent'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'distilbert-base-uncased-finetuned-sst-2-english',\n",
      "                     'node_name': 'nlp-sent',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-sent',\n",
      "    'pipeline_name': 'audio-sent',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [87, 88],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 42,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-sent'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 43 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 0.125,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 10,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'distilbert-base-uncased-finetuned-sst-2-english'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 16,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-sent'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'distilbert-base-uncased-finetuned-sst-2-english',\n",
      "                     'node_name': 'nlp-sent',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-sent',\n",
      "    'pipeline_name': 'audio-sent',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [87, 88],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 43,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-sent'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 61 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.125,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 5,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'sshleifer-distilbart-xsum-1-1',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'sshleifer-distilbart-xsum-1-1',\n",
      "                     'node_name': 'nlp-sum',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'sum-qa',\n",
      "    'pipeline_name': 'sum-qa',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 10,\n",
      "    'profiling_series': [97, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 61,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 5,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 62 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 5,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'sshleifer-distilbart-xsum-1-1',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'sshleifer-distilbart-xsum-1-1',\n",
      "                     'node_name': 'nlp-sum',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'sum-qa',\n",
      "    'pipeline_name': 'sum-qa',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 10,\n",
      "    'profiling_series': [97, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 62,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 5,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 63 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 0.125,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 10,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 5,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'sshleifer-distilbart-xsum-1-1',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'sshleifer-distilbart-xsum-1-1',\n",
      "                     'node_name': 'nlp-sum',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'sum-qa',\n",
      "    'pipeline_name': 'sum-qa',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 10,\n",
      "    'profiling_series': [97, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 63,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 5,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 81 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.125,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 5,\n",
      "    'drop_limit': 20,\n",
      "    'from_storage': [False, False, False],\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'dinalzein-xlm-roberta-base-finetuned-language-identification',\n",
      "                                'Helsinki-NLP-opus-mt-fr-en',\n",
      "                                'sshleifer-distilbart-xsum-1-1'],\n",
      "    'initial_batch': [1, 1, 1],\n",
      "    'initial_cpu_allocation': [1, 2, 2],\n",
      "    'initial_replica': [1, 1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': True,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['nlp-li', 'nlp-trans', 'nlp-sum'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'dinalzein-xlm-roberta-base-finetuned-language-identification',\n",
      "                     'node_name': 'nlp-li',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'Helsinki-NLP-opus-mt-fr-en',\n",
      "                     'node_name': 'nlp-trans',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'sshleifer-distilbart-xsum-1-1',\n",
      "                     'node_name': 'nlp-sum',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 3,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'nlp',\n",
      "    'pipeline_name': 'nlp',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': [20, 10, 10],\n",
      "    'profiling_series': [98, 99, 97],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 81,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['nlp-li', 'nlp-trans', 'nlp-sum'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 4,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 82 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 5,\n",
      "    'drop_limit': 20,\n",
      "    'from_storage': [False, False, False],\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'dinalzein-xlm-roberta-base-finetuned-language-identification',\n",
      "                                'Helsinki-NLP-opus-mt-fr-en',\n",
      "                                'sshleifer-distilbart-xsum-1-1'],\n",
      "    'initial_batch': [1, 1, 1],\n",
      "    'initial_cpu_allocation': [1, 2, 2],\n",
      "    'initial_replica': [1, 1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': True,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['nlp-li', 'nlp-trans', 'nlp-sum'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'dinalzein-xlm-roberta-base-finetuned-language-identification',\n",
      "                     'node_name': 'nlp-li',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'Helsinki-NLP-opus-mt-fr-en',\n",
      "                     'node_name': 'nlp-trans',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'sshleifer-distilbart-xsum-1-1',\n",
      "                     'node_name': 'nlp-sum',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 3,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'nlp',\n",
      "    'pipeline_name': 'nlp',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': [20, 10, 10],\n",
      "    'profiling_series': [98, 99, 97],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 82,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['nlp-li', 'nlp-trans', 'nlp-sum'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 4,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 83 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 0.125,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 10,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 5,\n",
      "    'drop_limit': 20,\n",
      "    'from_storage': [False, False, False],\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'dinalzein-xlm-roberta-base-finetuned-language-identification',\n",
      "                                'Helsinki-NLP-opus-mt-fr-en',\n",
      "                                'sshleifer-distilbart-xsum-1-1'],\n",
      "    'initial_batch': [1, 1, 1],\n",
      "    'initial_cpu_allocation': [1, 2, 2],\n",
      "    'initial_replica': [1, 1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': True,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['nlp-li', 'nlp-trans', 'nlp-sum'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'dinalzein-xlm-roberta-base-finetuned-language-identification',\n",
      "                     'node_name': 'nlp-li',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'Helsinki-NLP-opus-mt-fr-en',\n",
      "                     'node_name': 'nlp-trans',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'sshleifer-distilbart-xsum-1-1',\n",
      "                     'node_name': 'nlp-sum',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 3,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'nlp',\n",
      "    'pipeline_name': 'nlp',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': [20, 10, 10],\n",
      "    'profiling_series': [98, 99, 97],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 83,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['nlp-li', 'nlp-trans', 'nlp-sum'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 4,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n"
     ]
    }
   ],
   "source": [
    "accuracy_methods = {}\n",
    "adaptation_intervals = {}\n",
    "simulation_modes = {}\n",
    "configs = {}\n",
    "for series, loader in loaders.items():\n",
    "    configs_exp = loader.load_configs()\n",
    "    print(f\"series: {series} config:\\n\")\n",
    "    config = configs_exp[\"0.yaml\"]\n",
    "    pp.pprint(config)\n",
    "    configs[series] = config\n",
    "    accuracy_methods[series] = config[\"accuracy_method\"]\n",
    "    adaptation_intervals[series] = config[\"adaptation_interval\"]\n",
    "    simulation_modes[series] = config[\"simulation_mode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the sent workload\n",
    "sent_loads = {}\n",
    "for series, config in configs.items():\n",
    "    workload_type = config[\"workload_type\"]\n",
    "    workload_config = config[\"workload_config\"][0]\n",
    "    start = workload_config[\"start\"]\n",
    "    end = workload_config[\"end\"]\n",
    "    damping_factor = workload_config[\"damping_factor\"]\n",
    "    sent_loads[series] = twitter_workload_generator(\n",
    "        days=f\"{start}-{end}\", damping_factor=damping_factor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: True,\n",
       " 2: True,\n",
       " 3: True,\n",
       " 21: True,\n",
       " 22: True,\n",
       " 23: True,\n",
       " 41: True,\n",
       " 42: True,\n",
       " 43: True,\n",
       " 61: True,\n",
       " 62: True,\n",
       " 63: True,\n",
       " 81: True,\n",
       " 82: True,\n",
       " 83: True}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# key_config_df = loader.loader.key_config_mapper()\n",
    "# display(key_config_df)\n",
    "# key_config_df.columns\n",
    "results_all = []\n",
    "simulation_modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptation_logs = dict(\n",
    "    map(lambda l: (l[0], l[1].load_adaptation_log()), loaders.items())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_changes = {}\n",
    "for series in serieses:\n",
    "    series_changes[series] = loaders[series].series_changes(\n",
    "        adaptation_log=adaptation_logs[series]\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replica Changes\n",
    "1. Total\n",
    "2. Per node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "replica_changes = {}\n",
    "for series, series_dict in series_changes.items():\n",
    "    # print(50 * \"-\" + f\" {series} \" + 50 * \"-\")\n",
    "    replica_changes[series] = {}\n",
    "    nodes = []\n",
    "    for node_name, metrics in series_changes[series][\"nodes\"].items():\n",
    "        replica_changes[series][node_name] = metrics[\"replicas\"]\n",
    "        nodes.append(node_name)\n",
    "    # replica_changes['total'] = []\n",
    "    replica_changes[series][\"total\"] = [\n",
    "        sum(x) for x in zip(*replica_changes[series].values())\n",
    "    ]\n",
    "    # draw_temporal(replica_changes[series], adaptation_intervals[series])\n",
    "replica_changes_total = {\n",
    "    key: {\"total\": value[\"total\"]} for key, value in replica_changes.items()\n",
    "}\n",
    "ylabel = \"replicas\"\n",
    "# draw_temporal(\n",
    "#     replica_changes_total, adaptation_intervals, ylabel=ylabel, multiple_experiments=True\n",
    "# )\n",
    "# draw_cumulative(replica_changes_total, multiple_experiments=True, ylabel=ylabel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per Container Core changes\n",
    "1. Total\n",
    "2. Per Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_changes = {}\n",
    "for series in serieses:\n",
    "    # print(50 * \"-\" + f\" {series} \" + 50 * \"-\")\n",
    "    core_changes[series] = {}\n",
    "    nodes = []\n",
    "    for node_name, metrics in series_changes[series][\"nodes\"].items():\n",
    "        core_changes[series][node_name] = metrics[\"cpu\"]\n",
    "        nodes.append(node_name)\n",
    "    core_changes[series][\"total\"] = [\n",
    "        sum(x) for x in zip(*core_changes[series].values())\n",
    "    ]\n",
    "    # draw_temporal(core_changes[series])\n",
    "ylabel = \"core changes\"\n",
    "# draw_temporal(\n",
    "#     core_changes, adaptation_intervals, multiple_experiments=True, ylabel=ylabel\n",
    "# )\n",
    "core_changes_total = {\n",
    "    key: {\"total\": value[\"total\"]} for key, value in core_changes.items()\n",
    "}\n",
    "# draw_cumulative(\n",
    "#     core_changes_total, multiple_experiments=True, ylabel=ylabel, series_names=series_names\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total core changes\n",
    "replica * cores for each stage\n",
    "1. Total\n",
    "2. Per Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_core_changes = {}\n",
    "for series in serieses:\n",
    "    # print(50 * \"-\" + f\" {series} \" + 50 * \"-\")\n",
    "    total_core_changes[series] = {}\n",
    "    for key in replica_changes[series].keys():\n",
    "        if key != \"total\":\n",
    "            total_core_changes[series][key] = [\n",
    "                x * y\n",
    "                for x, y in zip(replica_changes[series][key], core_changes[series][key])\n",
    "            ]\n",
    "    total = np.zeros(len(list(total_core_changes[series].values())[0]))\n",
    "    for key, series_value in total_core_changes[series].items():\n",
    "        total += np.array(series_value)\n",
    "    total_core_changes[series][\"total\"] = total.tolist()\n",
    "    # draw_temporal(total_core_changes[series])\n",
    "legend = \"Priority\"\n",
    "xlabel = \"Pipelines\"\n",
    "ylabel = \"Total Core\"\n",
    "# draw_temporal(\n",
    "#     total_core_changes, adaptation_intervals, multiple_experiments=True, ylabel=ylabel\n",
    "# )\n",
    "\n",
    "for exp, value in total_core_changes.items():\n",
    "    value[\"total\"] = (np.array(value[\"total\"]) / len(value[\"total\"])).tolist()\n",
    "\n",
    "total_core_changes_total = {\n",
    "    key: value[\"total\"] for key, value in total_core_changes.items()\n",
    "}\n",
    "# draw_cumulative(\n",
    "#     total_core_changes_total,\n",
    "#     multiple_experiments=True,\n",
    "#     ylabel=ylabel,\n",
    "#     series_names=series_names,\n",
    "# )\n",
    "# draw_cumulative_with_grouping(\n",
    "#     dict_to_draw=total_core_changes_total,\n",
    "#     series_meta=series_meta,\n",
    "#     ylabel=ylabel,\n",
    "#     xlabel=xlabel,\n",
    "#     legend=legend,\n",
    "#     filename=f\"{FIGURES_PATH}/priority-cost\",\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_changes = {}\n",
    "for series in serieses:\n",
    "    accuracy_changes[series] = {}\n",
    "    # print(50 * \"-\" + f\" {series} \" + 50 * \"-\")\n",
    "    nodes = []\n",
    "    for node_name, metrics in series_changes[series][\"nodes\"].items():\n",
    "        accuracy_changes[series][node_name] = metrics[\"accuracy\"]\n",
    "        nodes.append(node_name)\n",
    "    # replica_changes['total'] = []\n",
    "    if accuracy_methods[series] == \"sum\":\n",
    "        accuracy_changes[series][\"e2e\"] = [\n",
    "            sum(x) for x in zip(*accuracy_changes[series].values())\n",
    "        ]\n",
    "    # draw_temporal(accuracy_changes[series])\n",
    "ylabel = \"Accuracy\"\n",
    "\n",
    "accuracy_changes_total = {key: value[\"e2e\"] for key, value in accuracy_changes.items()}\n",
    "\n",
    "# make it average\n",
    "for exp, value in accuracy_changes_total.items():\n",
    "    accuracy_changes_total[exp] = (np.array(value) / len(value)).tolist()\n",
    "\n",
    "# draw_cumulative_with_grouping(\n",
    "#     dict_to_draw=accuracy_changes_total,\n",
    "#     series_meta=series_meta,\n",
    "#     ylabel=ylabel,\n",
    "#     xlabel=xlabel,\n",
    "#     legend=legend,\n",
    "#     filename=f\"{FIGURES_PATH}/priority-accuracy\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cc/infernece-pipeline-joint-optimization/experiments/utils/drawing.py:549: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels(group_names)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(experiments.utils.drawing)\n",
    "\n",
    "data = {\n",
    "    \"Cost (cores)\": total_core_changes_total,\n",
    "    \"Accuracy\": accuracy_changes_total\n",
    "}\n",
    "\n",
    "\n",
    "experiments.utils.drawing.draw_cumulative_with_grouping(\n",
    "    data,\n",
    "    series_meta=series_meta,\n",
    "    xlabel=xlabel,\n",
    "    filename=f\"{FIGURES_PATH}/objective-preferences\",\n",
    "    colors = [\"#253494\", \"#41b6c4\", \"#2c7fb8\"],\n",
    "    bar_width = 0.2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "central",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2465c4f56298bc06dbdad3e7519856d346ec0e9edf6ba2c905f0af711583810e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
