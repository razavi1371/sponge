{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video pipeline with Yolo + Resnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pprint import PrettyPrinter\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "\n",
    "pp = PrettyPrinter(indent=4)\n",
    "from barazmoon.twitter import twitter_workload_generator\n",
    "\n",
    "# get an absolute path to the directory that contains parent files\n",
    "__file__ = globals()[\"_dh\"][0]\n",
    "project_dir = __file__ = globals()[\"_dh\"][0]\n",
    "sys.path.append(os.path.normpath(os.path.join(project_dir, \"..\", \"..\", \"..\")))\n",
    "\n",
    "from experiments.utils.constants import FINAL_RESULTS_PATH\n",
    "from experiments.utils.parser import AdaptationParser\n",
    "from experiments.utils.drawing import draw_cumulative_with_grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaserieses = [15 ,15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]\n",
    "serieses = [1, 2, 21, 22, 41, 42, 61, 62]\n",
    "\n",
    "series_meta = {\n",
    "    \"lstm\": {\"video\": 1, \"audio-qa\": 21, \"audio-sent\": 41, \"sum-qa\": 61},\n",
    "    \"reactive\": {\"video\": 2, \"audio-qa\": 22, \"audio-sent\": 42, \"sum-qa\": 62}\n",
    "}\n",
    "# groups = {\n",
    "#     \"video\": [1, 2],\n",
    "#     \"audio-qa\": [21, 22],\n",
    "#     \"audio-sent\": [41, 42],\n",
    "#     \"sum-qa\": [61, 62]\n",
    "# }\n",
    "\n",
    "# series_names = {\n",
    "#     1: \"lstm\",\n",
    "#     2: \"reactive\",\n",
    "#     21: \"lstm\",\n",
    "#     22: \"reactive\",\n",
    "#     41: \"lstm\",\n",
    "#     42: \"reactive\",\n",
    "#     61: \"lstm\",\n",
    "#     62: \"reactive\",\n",
    "# }\n",
    "\n",
    "# categories = ['lstm', 'reactive']\n",
    "\n",
    "series_paths = {\n",
    "series: os.path.join(FINAL_RESULTS_PATH, \"metaseries\", str(metaseries), \"series\", str(series))\n",
    "    for series, metaseries in zip(serieses, metaserieses)\n",
    "}\n",
    "\n",
    "loaders = {\n",
    "series: AdaptationParser(\n",
    "        series_path=series_path, model_name=\"video\", type_of=\"router_pipeline\"\n",
    "    )\n",
    "    for series, series_path in series_paths.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/15/series/1',\n",
       " 2: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/15/series/2',\n",
       " 21: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/15/series/21',\n",
       " 22: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/15/series/22',\n",
       " 41: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/15/series/41',\n",
       " 42: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/15/series/42',\n",
       " 61: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/15/series/61',\n",
       " 62: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/15/series/62'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: <experiments.utils.parser.AdaptationParser at 0x7f692cadcfa0>,\n",
       " 2: <experiments.utils.parser.AdaptationParser at 0x7f69d4229bb0>,\n",
       " 21: <experiments.utils.parser.AdaptationParser at 0x7f69d4229d30>,\n",
       " 22: <experiments.utils.parser.AdaptationParser at 0x7f692cadcee0>,\n",
       " 41: <experiments.utils.parser.AdaptationParser at 0x7f69d4256ee0>,\n",
       " 42: <experiments.utils.parser.AdaptationParser at 0x7f69d423f040>,\n",
       " 61: <experiments.utils.parser.AdaptationParser at 0x7f69d4245640>,\n",
       " 62: <experiments.utils.parser.AdaptationParser at 0x7f69d4245610>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "series: 1 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 2,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 8,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 1,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 10,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': ['yolov5n', 'resnet18'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 7,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['yolo', 'resnet-human'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'image',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'yolov5n',\n",
      "                     'node_name': 'yolo',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'resnet18',\n",
      "                     'node_name': 'resnet-human',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'video',\n",
      "    'pipeline_name': 'video',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [71, 72],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 1,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['crop', 'classification'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 4,\n",
      "    'throughput_margin': 0,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 2 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 2,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'reactive',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 8,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 1,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 10,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': ['yolov5n', 'resnet18'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 15,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['yolo', 'resnet-human'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'image',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'yolov5n',\n",
      "                     'node_name': 'yolo',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'resnet18',\n",
      "                     'node_name': 'resnet-human',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'video',\n",
      "    'pipeline_name': 'video',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'reactive',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [71, 72],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 2,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['crop', 'classification'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 4,\n",
      "    'throughput_margin': 0,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 21 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib - redo of '\n",
      "                'metaseries bursty on chameleon to check latencies',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-qa',\n",
      "    'pipeline_name': 'audio-qa',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [85, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 28,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-qa'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 22 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'reactive',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib - redo of '\n",
      "                'metaseries bursty on chameleon to check latencies',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-qa',\n",
      "    'pipeline_name': 'audio-qa',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'reactive',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [85, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 36,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-qa'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 41 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'distilbert-base-uncased-finetuned-sst-2-english'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 14,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-sent'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'distilbert-base-uncased-finetuned-sst-2-english',\n",
      "                     'node_name': 'nlp-sent',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-sent',\n",
      "    'pipeline_name': 'audio-sent',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [87, 88],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 41,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-sent'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 42 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'reactive',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'distilbert-base-uncased-finetuned-sst-2-english'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 15,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-sent'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'distilbert-base-uncased-finetuned-sst-2-english',\n",
      "                     'node_name': 'nlp-sent',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-sent',\n",
      "    'pipeline_name': 'audio-sent',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'reactive',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [87, 88],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 42,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-sent'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 61 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 5,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'sshleifer-distilbart-xsum-1-1',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 15,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'sshleifer-distilbart-xsum-1-1',\n",
      "                     'node_name': 'nlp-sum',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'sum-qa',\n",
      "    'pipeline_name': 'sum-qa',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 10,\n",
      "    'profiling_series': [97, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 70,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 5,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 62 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'reactive',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 5,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'sshleifer-distilbart-xsum-1-1',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 15,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'sshleifer-distilbart-xsum-1-1',\n",
      "                     'node_name': 'nlp-sum',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'sum-qa',\n",
      "    'pipeline_name': 'sum-qa',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'reactive',\n",
      "    'profiling_load': 10,\n",
      "    'profiling_series': [97, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 65,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 5,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n"
     ]
    }
   ],
   "source": [
    "accuracy_methods = {}\n",
    "adaptation_intervals = {}\n",
    "simulation_modes = {}\n",
    "configs = {}\n",
    "for series, loader in loaders.items():\n",
    "    configs_exp = loader.load_configs()\n",
    "    print(f\"series: {series} config:\\n\")\n",
    "    config = configs_exp[\"0.yaml\"]\n",
    "    pp.pprint(config)\n",
    "    configs[series] = config\n",
    "    accuracy_methods[series] = config[\"accuracy_method\"]\n",
    "    adaptation_intervals[series] = config[\"adaptation_interval\"]\n",
    "    simulation_modes[series] = config[\"simulation_mode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the sent workload\n",
    "sent_loads = {}\n",
    "for series, config in configs.items():\n",
    "    workload_type = config[\"workload_type\"]\n",
    "    workload_config = config[\"workload_config\"][0]\n",
    "    start = workload_config[\"start\"]\n",
    "    end = workload_config[\"end\"]\n",
    "    damping_factor = workload_config[\"damping_factor\"]\n",
    "    sent_loads[series] = twitter_workload_generator(\n",
    "        days=f\"{start}-{end}\", damping_factor=damping_factor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: False,\n",
       " 2: False,\n",
       " 21: False,\n",
       " 22: False,\n",
       " 41: False,\n",
       " 42: False,\n",
       " 61: False,\n",
       " 62: False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# key_config_df = loader.loader.key_config_mapper()\n",
    "# display(key_config_df)\n",
    "# key_config_df.columns\n",
    "results_all = []\n",
    "simulation_modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptation_logs = dict(\n",
    "    map(lambda l: (l[0], l[1].load_adaptation_log()), loaders.items())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_changes = {}\n",
    "for series in serieses:\n",
    "    series_changes[series] = loaders[series].series_changes(\n",
    "        adaptation_log=adaptation_logs[series]\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total core changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "replica_changes = {}\n",
    "for series, series_dict in series_changes.items():\n",
    "    # print(50 * \"-\" + f\" {series} \" + 50 * \"-\")\n",
    "    replica_changes[series] = {}\n",
    "    nodes = []\n",
    "    for node_name, metrics in series_changes[series][\"nodes\"].items():\n",
    "        replica_changes[series][node_name] = metrics[\"replicas\"]\n",
    "        nodes.append(node_name)\n",
    "    replica_changes[series][\"total\"] = [\n",
    "        sum(x) for x in zip(*replica_changes[series].values())\n",
    "    ]\n",
    "\n",
    "# -----------------------------\n",
    "core_changes = {}\n",
    "for series in serieses:\n",
    "    # print(50 * \"-\" + f\" {series} \" + 50 * \"-\")\n",
    "    core_changes[series] = {}\n",
    "    nodes = []\n",
    "    for node_name, metrics in series_changes[series][\"nodes\"].items():\n",
    "        core_changes[series][node_name] = metrics[\"cpu\"]\n",
    "        nodes.append(node_name)\n",
    "    core_changes[series][\"total\"] = [\n",
    "        sum(x) for x in zip(*core_changes[series].values())\n",
    "    ]\n",
    "\n",
    "# -----------------------------\n",
    "\n",
    "total_core_changes = {}\n",
    "for series in serieses:\n",
    "    # print(50 * \"-\" + f\" {series} \" + 50 * \"-\")\n",
    "    total_core_changes[series] = {}\n",
    "    for key in replica_changes[series].keys():\n",
    "        if key != \"total\":\n",
    "            total_core_changes[series][key] = [\n",
    "                x * y\n",
    "                for x, y in zip(replica_changes[series][key], core_changes[series][key])\n",
    "            ]\n",
    "    total = np.zeros(len(list(total_core_changes[series].values())[0]))\n",
    "    for key, series_value in total_core_changes[series].items():\n",
    "        total += np.array(series_value)\n",
    "    total_core_changes[series][\"total\"] = total.tolist()\n",
    "    # draw_temporal(total_core_changes[series])\n",
    "ylabel = \"Total Core\"\n",
    "\n",
    "for exp, value in total_core_changes.items():\n",
    "    value['total'] = (np.array(value['total']) / len(value['total'])).tolist()\n",
    "total_core_changes_total = {key: {'total': value['total']} for key, value in total_core_changes.items()}\n",
    "\n",
    "# draw_cumulative_with_grouping(\n",
    "#     total_core_changes_total,\n",
    "#     multiple_experiments=True,\n",
    "#     ylabel=ylabel,\n",
    "#     series_names=series_names,\n",
    "#     groups=groups\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Latencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeout_per_second = {}\n",
    "per_second_results = {}\n",
    "for series in serieses:\n",
    "    if not simulation_modes[series]:\n",
    "        timeout_per_second[series], per_second_results[series] = loaders[\n",
    "            series\n",
    "        ].per_second_result_processing()\n",
    "    else:\n",
    "        timeout_per_second[series], per_second_results[series] = None, None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not all(simulation_modes.values()):\n",
    "    metric = \"p99\"  # [min, max, p99]\n",
    "    metrics_all = {}\n",
    "    for series in serieses:\n",
    "        # print(50 * \"-\" + f\" {series} \" + 50 * \"-\")\n",
    "        if not simulation_modes[series]:\n",
    "            metric_columns = list(\n",
    "                filter(lambda col: metric in col, per_second_results[series].columns)\n",
    "            )\n",
    "            metrics_all[series] = per_second_results[series][metric_columns]\n",
    "            # metrics_all[series][f\"{metric}_e2e\"] = metrics_all[series].sum(axis=1).to_list()\n",
    "            metrics_all[series] = metrics_all[series].to_dict(orient=\"list\")\n",
    "            # draw_temporal(metrics_all[series])\n",
    "    ylabel = \"Second\"\n",
    "    # draw_temporal(metrics_all, multiple_experiments=True, ylabel=ylabel)\n",
    "    # draw_cumulative(metrics_all, multiple_experiments=True, ylabel=ylabel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## timeouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 out of 14437\n",
      "368 out of 14437\n",
      "93 out of 14437\n",
      "683 out of 14437\n",
      "50 out of 14437\n",
      "139 out of 14437\n",
      "803 out of 14437\n",
      "1647 out of 14437\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/cc/miniconda3/envs/central/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_3732028/2101044186.py\", line 14, in <module>\n",
      "    draw_cumulative_with_grouping(\n",
      "  File \"/home/cc/infernece-pipeline-joint-optimization/experiments/utils/drawing.py\", line 525, in draw_cumulative_with_grouping\n",
      "    # Set the positions of the bars on the x-axis\n",
      "AttributeError: 'float' object has no attribute 'keys'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/cc/miniconda3/envs/central/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/cc/miniconda3/envs/central/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1396, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/cc/miniconda3/envs/central/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1287, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/cc/miniconda3/envs/central/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1140, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/cc/miniconda3/envs/central/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1030, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "  File \"/home/cc/miniconda3/envs/central/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1098, in get_records\n",
      "    mod = inspect.getmodule(cf.tb_frame)\n",
      "  File \"/home/cc/miniconda3/envs/central/lib/python3.9/inspect.py\", line 752, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/cc/miniconda3/envs/central/lib/python3.9/inspect.py\", line 721, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/cc/miniconda3/envs/central/lib/python3.9/inspect.py\", line 700, in getsourcefile\n",
      "    if any(filename.endswith(s) for s in all_bytecode_suffixes):\n",
      "  File \"/home/cc/miniconda3/envs/central/lib/python3.9/inspect.py\", line 700, in <genexpr>\n",
      "    if any(filename.endswith(s) for s in all_bytecode_suffixes):\n",
      "AttributeError: 'PosixPath' object has no attribute 'endswith'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "if not all(simulation_modes.values()):\n",
    "    ylabel = \"% SLA Violations\"\n",
    "    xlabel = \"Experiments\"\n",
    "    timeout_dics = {}\n",
    "    for series in serieses:\n",
    "        # print(50 * \"-\" + f\" {series} \" + 50 * \"-\")\n",
    "        if not simulation_modes[series]:\n",
    "            timeout_dics[series] = (np.array(timeout_per_second[series]) / sum(sent_loads[series])).tolist()\n",
    "            # draw_temporal(timeout_dics[series])\n",
    "            print(f\"{sum(timeout_per_second[series])} out of {sum(sent_loads[series])}\")\n",
    "    # draw_temporal(timeout_dics, multiple_experiments=True, ylabel=ylabel)\n",
    "    draw_cumulative_with_grouping(\n",
    "        dict_to_draw=timeout_dics,\n",
    "        series_meta=series_meta,\n",
    "        ylabel=ylabel,\n",
    "        xlabel=xlabel,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "central",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2465c4f56298bc06dbdad3e7519856d346ec0e9edf6ba2c905f0af711583810e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
