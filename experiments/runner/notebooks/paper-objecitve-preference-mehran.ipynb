{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pprint import PrettyPrinter\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "\n",
    "pp = PrettyPrinter(indent=4)\n",
    "from barazmoon.twitter import twitter_workload_generator\n",
    "\n",
    "# get an absolute path to the directory that contains parent files\n",
    "__file__ = globals()[\"_dh\"][0]\n",
    "project_dir = __file__ = globals()[\"_dh\"][0]\n",
    "sys.path.append(os.path.normpath(os.path.join(project_dir, \"..\", \"..\", \"..\")))\n",
    "\n",
    "from experiments.utils.constants import FINAL_RESULTS_PATH, FIGURES_PATH\n",
    "from experiments.utils.parser import AdaptationParser\n",
    "import experiments.utils.drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaserieses = [16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16, 16]\n",
    "serieses = [1, 2, 3, 21, 22, 23, 41, 42, 43, 61, 62, 63, 81, 82, 83]\n",
    "\n",
    "series_meta = {\n",
    "    \"resource-priorotize\": {\n",
    "        \"video\": 1,\n",
    "        \"audio-qa\": 21,\n",
    "        \"audio-sent\": 41,\n",
    "        \"sum-qa\": 61,\n",
    "        \"nlp\": 81,\n",
    "    },\n",
    "    \"balance\": {\"video\": 2, \"audio-qa\": 22, \"audio-sent\": 42, \"sum-qa\": 62, \"nlp\": 82},\n",
    "    \"accuracy-priorotize\": {\n",
    "        \"video\": 3,\n",
    "        \"audio-qa\": 23,\n",
    "        \"audio-sent\": 43,\n",
    "        \"sum-qa\": 63,\n",
    "        \"nlp\": 83,\n",
    "    },\n",
    "}\n",
    "\n",
    "series_paths = {\n",
    "    series: os.path.join(\n",
    "        FINAL_RESULTS_PATH, \"metaseries\", str(metaseries), \"series\", str(series)\n",
    "    )\n",
    "    for series, metaseries in zip(serieses, metaserieses)\n",
    "}\n",
    "\n",
    "loaders = {\n",
    "    series: AdaptationParser(\n",
    "        series_path=series_path, model_name=\"nlp\", type_of=\"router_pipeline\"\n",
    "    )\n",
    "    for series, series_path in series_paths.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/1',\n",
       " 2: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/2',\n",
       " 3: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/3',\n",
       " 21: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/21',\n",
       " 22: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/22',\n",
       " 23: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/23',\n",
       " 41: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/41',\n",
       " 42: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/42',\n",
       " 43: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/43',\n",
       " 61: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/61',\n",
       " 62: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/62',\n",
       " 63: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/63',\n",
       " 81: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/81',\n",
       " 82: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/82',\n",
       " 83: '/home/cc/infernece-pipeline-joint-optimization/data/results/final/metaseries/16/series/83'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: <experiments.utils.parser.AdaptationParser at 0x7fbec6e9c910>,\n",
       " 2: <experiments.utils.parser.AdaptationParser at 0x7fbec6e9c9d0>,\n",
       " 3: <experiments.utils.parser.AdaptationParser at 0x7fbec6efdd90>,\n",
       " 21: <experiments.utils.parser.AdaptationParser at 0x7fbed4d11910>,\n",
       " 22: <experiments.utils.parser.AdaptationParser at 0x7fbf985e2cd0>,\n",
       " 23: <experiments.utils.parser.AdaptationParser at 0x7fbf9868f580>,\n",
       " 41: <experiments.utils.parser.AdaptationParser at 0x7fbf9868f6d0>,\n",
       " 42: <experiments.utils.parser.AdaptationParser at 0x7fbf98668670>,\n",
       " 43: <experiments.utils.parser.AdaptationParser at 0x7fbec6be0700>,\n",
       " 61: <experiments.utils.parser.AdaptationParser at 0x7fbf9e2cd0d0>,\n",
       " 62: <experiments.utils.parser.AdaptationParser at 0x7fbf98676c40>,\n",
       " 63: <experiments.utils.parser.AdaptationParser at 0x7fbf986763d0>,\n",
       " 81: <experiments.utils.parser.AdaptationParser at 0x7fbf98676220>,\n",
       " 82: <experiments.utils.parser.AdaptationParser at 0x7fbf98650940>,\n",
       " 83: <experiments.utils.parser.AdaptationParser at 0x7fbec6be1970>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "series: 1 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 2,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 8,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.125,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 10,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': ['yolov5n', 'resnet18'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['yolo', 'resnet-human'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'image',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'yolov5n',\n",
      "                     'node_name': 'yolo',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'resnet18',\n",
      "                     'node_name': 'resnet-human',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'video',\n",
      "    'pipeline_name': 'video',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [71, 72],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 1,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['crop', 'classification'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 4,\n",
      "    'throughput_margin': 0,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 2 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 2,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 8,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 1,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 10,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': ['yolov5n', 'resnet18'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['yolo', 'resnet-human'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'image',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'yolov5n',\n",
      "                     'node_name': 'yolo',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'resnet18',\n",
      "                     'node_name': 'resnet-human',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'video',\n",
      "    'pipeline_name': 'video',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [71, 72],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 2,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['crop', 'classification'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 4,\n",
      "    'throughput_margin': 0,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 3 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 0.125,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 8,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 2,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 10,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': ['yolov5n', 'resnet18'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['yolo', 'resnet-human'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'image',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'yolov5n',\n",
      "                     'node_name': 'yolo',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'resnet18',\n",
      "                     'node_name': 'resnet-human',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'video',\n",
      "    'pipeline_name': 'video',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [71, 72],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 3,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['crop', 'classification'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 4,\n",
      "    'throughput_margin': 0,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 21 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.125,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib - redo of '\n",
      "                'metaseries bursty on chameleon to check latencies',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-qa',\n",
      "    'pipeline_name': 'audio-qa',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [85, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 21,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-qa'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 22 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib - redo of '\n",
      "                'metaseries bursty on chameleon to check latencies',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-qa',\n",
      "    'pipeline_name': 'audio-qa',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [85, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 22,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-qa'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 23 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 0.125,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 10,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib - redo of '\n",
      "                'metaseries bursty on chameleon to check latencies',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-qa',\n",
      "    'pipeline_name': 'audio-qa',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [85, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 23,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-qa'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 41 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.125,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'distilbert-base-uncased-finetuned-sst-2-english'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-sent'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'distilbert-base-uncased-finetuned-sst-2-english',\n",
      "                     'node_name': 'nlp-sent',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-sent',\n",
      "    'pipeline_name': 'audio-sent',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [87, 88],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 41,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-sent'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 42 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'distilbert-base-uncased-finetuned-sst-2-english'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-sent'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'distilbert-base-uncased-finetuned-sst-2-english',\n",
      "                     'node_name': 'nlp-sent',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-sent',\n",
      "    'pipeline_name': 'audio-sent',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [87, 88],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 42,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-sent'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 43 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 0.125,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 10,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'distilbert-base-uncased-finetuned-sst-2-english'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 16,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-sent'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'distilbert-base-uncased-finetuned-sst-2-english',\n",
      "                     'node_name': 'nlp-sent',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-sent',\n",
      "    'pipeline_name': 'audio-sent',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [87, 88],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 43,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-sent'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 61 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.125,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 5,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'sshleifer-distilbart-xsum-1-1',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'sshleifer-distilbart-xsum-1-1',\n",
      "                     'node_name': 'nlp-sum',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'sum-qa',\n",
      "    'pipeline_name': 'sum-qa',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 10,\n",
      "    'profiling_series': [97, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 61,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 5,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 62 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 5,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'sshleifer-distilbart-xsum-1-1',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'sshleifer-distilbart-xsum-1-1',\n",
      "                     'node_name': 'nlp-sum',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'sum-qa',\n",
      "    'pipeline_name': 'sum-qa',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 10,\n",
      "    'profiling_series': [97, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 62,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 5,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 63 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 0.125,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 10,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 5,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'sshleifer-distilbart-xsum-1-1',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'sshleifer-distilbart-xsum-1-1',\n",
      "                     'node_name': 'nlp-sum',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'sum-qa',\n",
      "    'pipeline_name': 'sum-qa',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 10,\n",
      "    'profiling_series': [97, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 63,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 5,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 81 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.125,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 5,\n",
      "    'drop_limit': 20,\n",
      "    'from_storage': [False, False, False],\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'dinalzein-xlm-roberta-base-finetuned-language-identification',\n",
      "                                'Helsinki-NLP-opus-mt-fr-en',\n",
      "                                'sshleifer-distilbart-xsum-1-1'],\n",
      "    'initial_batch': [1, 1, 1],\n",
      "    'initial_cpu_allocation': [1, 2, 2],\n",
      "    'initial_replica': [1, 1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': True,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['nlp-li', 'nlp-trans', 'nlp-sum'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'dinalzein-xlm-roberta-base-finetuned-language-identification',\n",
      "                     'node_name': 'nlp-li',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'Helsinki-NLP-opus-mt-fr-en',\n",
      "                     'node_name': 'nlp-trans',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'sshleifer-distilbart-xsum-1-1',\n",
      "                     'node_name': 'nlp-sum',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 3,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'nlp',\n",
      "    'pipeline_name': 'nlp',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': [20, 10, 10],\n",
      "    'profiling_series': [98, 99, 97],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 81,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['nlp-li', 'nlp-trans', 'nlp-sum'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 4,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 82 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 5,\n",
      "    'drop_limit': 20,\n",
      "    'from_storage': [False, False, False],\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'dinalzein-xlm-roberta-base-finetuned-language-identification',\n",
      "                                'Helsinki-NLP-opus-mt-fr-en',\n",
      "                                'sshleifer-distilbart-xsum-1-1'],\n",
      "    'initial_batch': [1, 1, 1],\n",
      "    'initial_cpu_allocation': [1, 2, 2],\n",
      "    'initial_replica': [1, 1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': True,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['nlp-li', 'nlp-trans', 'nlp-sum'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'dinalzein-xlm-roberta-base-finetuned-language-identification',\n",
      "                     'node_name': 'nlp-li',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'Helsinki-NLP-opus-mt-fr-en',\n",
      "                     'node_name': 'nlp-trans',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'sshleifer-distilbart-xsum-1-1',\n",
      "                     'node_name': 'nlp-sum',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 3,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'nlp',\n",
      "    'pipeline_name': 'nlp',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': [20, 10, 10],\n",
      "    'profiling_series': [98, 99, 97],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 82,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['nlp-li', 'nlp-trans', 'nlp-sum'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 4,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 83 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 0.125,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 10,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 5,\n",
      "    'drop_limit': 20,\n",
      "    'from_storage': [False, False, False],\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'dinalzein-xlm-roberta-base-finetuned-language-identification',\n",
      "                                'Helsinki-NLP-opus-mt-fr-en',\n",
      "                                'sshleifer-distilbart-xsum-1-1'],\n",
      "    'initial_batch': [1, 1, 1],\n",
      "    'initial_cpu_allocation': [1, 2, 2],\n",
      "    'initial_replica': [1, 1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': True,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['nlp-li', 'nlp-trans', 'nlp-sum'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'dinalzein-xlm-roberta-base-finetuned-language-identification',\n",
      "                     'node_name': 'nlp-li',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'Helsinki-NLP-opus-mt-fr-en',\n",
      "                     'node_name': 'nlp-trans',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'sshleifer-distilbart-xsum-1-1',\n",
      "                     'node_name': 'nlp-sum',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 3,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'nlp',\n",
      "    'pipeline_name': 'nlp',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': [20, 10, 10],\n",
      "    'profiling_series': [98, 99, 97],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 83,\n",
      "    'simulation_mode': True,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['nlp-li', 'nlp-trans', 'nlp-sum'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 4,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n"
     ]
    }
   ],
   "source": [
    "accuracy_methods = {}\n",
    "adaptation_intervals = {}\n",
    "simulation_modes = {}\n",
    "configs = {}\n",
    "for series, loader in loaders.items():\n",
    "    configs_exp = loader.load_configs()\n",
    "    print(f\"series: {series} config:\\n\")\n",
    "    config = configs_exp[\"0.yaml\"]\n",
    "    pp.pprint(config)\n",
    "    configs[series] = config\n",
    "    accuracy_methods[series] = config[\"accuracy_method\"]\n",
    "    adaptation_intervals[series] = config[\"adaptation_interval\"]\n",
    "    simulation_modes[series] = config[\"simulation_mode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the sent workload\n",
    "sent_loads = {}\n",
    "for series, config in configs.items():\n",
    "    workload_type = config[\"workload_type\"]\n",
    "    workload_config = config[\"workload_config\"][0]\n",
    "    start = workload_config[\"start\"]\n",
    "    end = workload_config[\"end\"]\n",
    "    damping_factor = workload_config[\"damping_factor\"]\n",
    "    sent_loads[series] = twitter_workload_generator(\n",
    "        days=f\"{start}-{end}\", damping_factor=damping_factor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: True,\n",
       " 2: True,\n",
       " 3: True,\n",
       " 21: True,\n",
       " 22: True,\n",
       " 23: True,\n",
       " 41: True,\n",
       " 42: True,\n",
       " 43: True,\n",
       " 61: True,\n",
       " 62: True,\n",
       " 63: True,\n",
       " 81: True,\n",
       " 82: True,\n",
       " 83: True}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# key_config_df = loader.loader.key_config_mapper()\n",
    "# display(key_config_df)\n",
    "# key_config_df.columns\n",
    "results_all = []\n",
    "simulation_modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptation_logs = dict(\n",
    "    map(lambda l: (l[0], l[1].load_adaptation_log()), loaders.items())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_changes = {}\n",
    "for series in serieses:\n",
    "    series_changes[series] = loaders[series].series_changes(\n",
    "        adaptation_log=adaptation_logs[series]\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replica Changes\n",
    "1. Total\n",
    "2. Per node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "replica_changes = {}\n",
    "for series, series_dict in series_changes.items():\n",
    "    # print(50 * \"-\" + f\" {series} \" + 50 * \"-\")\n",
    "    replica_changes[series] = {}\n",
    "    nodes = []\n",
    "    for node_name, metrics in series_changes[series][\"nodes\"].items():\n",
    "        replica_changes[series][node_name] = metrics[\"replicas\"]\n",
    "        nodes.append(node_name)\n",
    "    # replica_changes['total'] = []\n",
    "    replica_changes[series][\"total\"] = [\n",
    "        sum(x) for x in zip(*replica_changes[series].values())\n",
    "    ]\n",
    "    # draw_temporal(replica_changes[series], adaptation_intervals[series])\n",
    "replica_changes_total = {\n",
    "    key: {\"total\": value[\"total\"]} for key, value in replica_changes.items()\n",
    "}\n",
    "ylabel = \"replicas\"\n",
    "# draw_temporal(\n",
    "#     replica_changes_total, adaptation_intervals, ylabel=ylabel, multiple_experiments=True\n",
    "# )\n",
    "# draw_cumulative(replica_changes_total, multiple_experiments=True, ylabel=ylabel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per Container Core changes\n",
    "1. Total\n",
    "2. Per Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_changes = {}\n",
    "for series in serieses:\n",
    "    # print(50 * \"-\" + f\" {series} \" + 50 * \"-\")\n",
    "    core_changes[series] = {}\n",
    "    nodes = []\n",
    "    for node_name, metrics in series_changes[series][\"nodes\"].items():\n",
    "        core_changes[series][node_name] = metrics[\"cpu\"]\n",
    "        nodes.append(node_name)\n",
    "    core_changes[series][\"total\"] = [\n",
    "        sum(x) for x in zip(*core_changes[series].values())\n",
    "    ]\n",
    "    # draw_temporal(core_changes[series])\n",
    "ylabel = \"core changes\"\n",
    "# draw_temporal(\n",
    "#     core_changes, adaptation_intervals, multiple_experiments=True, ylabel=ylabel\n",
    "# )\n",
    "core_changes_total = {\n",
    "    key: {\"total\": value[\"total\"]} for key, value in core_changes.items()\n",
    "}\n",
    "# draw_cumulative(\n",
    "#     core_changes_total, multiple_experiments=True, ylabel=ylabel, series_names=series_names\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total core changes\n",
    "replica * cores for each stage\n",
    "1. Total\n",
    "2. Per Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_core_changes = {}\n",
    "for series in serieses:\n",
    "    # print(50 * \"-\" + f\" {series} \" + 50 * \"-\")\n",
    "    total_core_changes[series] = {}\n",
    "    for key in replica_changes[series].keys():\n",
    "        if key != \"total\":\n",
    "            total_core_changes[series][key] = [\n",
    "                x * y\n",
    "                for x, y in zip(replica_changes[series][key], core_changes[series][key])\n",
    "            ]\n",
    "    total = np.zeros(len(list(total_core_changes[series].values())[0]))\n",
    "    for key, series_value in total_core_changes[series].items():\n",
    "        total += np.array(series_value)\n",
    "    total_core_changes[series][\"total\"] = total.tolist()\n",
    "    # draw_temporal(total_core_changes[series])\n",
    "legend = \"Priority\"\n",
    "xlabel = \"Pipelines\"\n",
    "ylabel = \"Total Core\"\n",
    "# draw_temporal(\n",
    "#     total_core_changes, adaptation_intervals, multiple_experiments=True, ylabel=ylabel\n",
    "# )\n",
    "\n",
    "for exp, value in total_core_changes.items():\n",
    "    value[\"total\"] = (np.array(value[\"total\"]) / len(value[\"total\"])).tolist()\n",
    "\n",
    "total_core_changes_total = {\n",
    "    key: value[\"total\"] for key, value in total_core_changes.items()\n",
    "}\n",
    "# draw_cumulative(\n",
    "#     total_core_changes_total,\n",
    "#     multiple_experiments=True,\n",
    "#     ylabel=ylabel,\n",
    "#     series_names=series_names,\n",
    "# )\n",
    "# draw_cumulative_with_grouping(\n",
    "#     dict_to_draw=total_core_changes_total,\n",
    "#     series_meta=series_meta,\n",
    "#     ylabel=ylabel,\n",
    "#     xlabel=xlabel,\n",
    "#     legend=legend,\n",
    "#     filename=f\"{FIGURES_PATH}/priority-cost\",\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_changes = {}\n",
    "for series in serieses:\n",
    "    accuracy_changes[series] = {}\n",
    "    # print(50 * \"-\" + f\" {series} \" + 50 * \"-\")\n",
    "    nodes = []\n",
    "    for node_name, metrics in series_changes[series][\"nodes\"].items():\n",
    "        accuracy_changes[series][node_name] = metrics[\"accuracy\"]\n",
    "        nodes.append(node_name)\n",
    "    # replica_changes['total'] = []\n",
    "    if accuracy_methods[series] == \"sum\":\n",
    "        accuracy_changes[series][\"e2e\"] = [\n",
    "            sum(x) for x in zip(*accuracy_changes[series].values())\n",
    "        ]\n",
    "    # draw_temporal(accuracy_changes[series])\n",
    "ylabel = \"Accuracy\"\n",
    "\n",
    "accuracy_changes_total = {key: value[\"e2e\"] for key, value in accuracy_changes.items()}\n",
    "\n",
    "# make it average\n",
    "for exp, value in accuracy_changes_total.items():\n",
    "    accuracy_changes_total[exp] = (np.array(value) / len(value)).tolist()\n",
    "\n",
    "# draw_cumulative_with_grouping(\n",
    "#     dict_to_draw=accuracy_changes_total,\n",
    "#     series_meta=series_meta,\n",
    "#     ylabel=ylabel,\n",
    "#     xlabel=xlabel,\n",
    "#     legend=legend,\n",
    "#     filename=f\"{FIGURES_PATH}/priority-accuracy\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cost (cores)': {1: 8.26050420168066, 2: 2.865546218487394, 3: 2.764705882352941, 21: 47.91596638655459, 22: 17.579831932773075, 23: 13.243697478991582, 41: 28.32773109243693, 42: 17.126050420168035, 43: 11.74789915966386, 61: 41.94117647058822, 62: 16.840336134453757, 63: 8.915966386554619, 81: 109.47058823529434, 82: 56.94117647058822, 83: 48.59663865546229}, 'Accuracy': {1: 1.3949579831932746, 2: 0.40336134453781475, 3: 0.35294117647058804, 21: 1.8025210084033576, 22: 1.302521008403359, 23: 0.999999999999999, 41: 1.499999999999997, 42: 1.302521008403359, 43: 0.999999999999999, 61: 1.926050420168063, 62: 1.4873949579831898, 63: 0.999999999999999, 81: 2.6134453781512557, 82: 1.6285714285714255, 83: 0.999999999999999}}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(experiments.utils.drawing)\n",
    "\n",
    "data = {\n",
    "    \"Cost (cores)\": total_core_changes_total,\n",
    "    \"Accuracy\": accuracy_changes_total\n",
    "}\n",
    "\n",
    "\n",
    "experiments.utils.drawing.draw_cumulative_with_grouping(\n",
    "    data,\n",
    "    series_meta=series_meta,\n",
    "    xlabel=xlabel,\n",
    "    filename=f\"{FIGURES_PATH}/objective-preferences\",\n",
    "    colors = [\"#2c7fb8\", \"#41b6c4\", \"#253494\"],\n",
    "    bar_width = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "central",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2465c4f56298bc06dbdad3e7519856d346ec0e9edf6ba2c905f0af711583810e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
