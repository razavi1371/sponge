{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video pipeline with Yolo + Resnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pprint import PrettyPrinter\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "\n",
    "pp = PrettyPrinter(indent=4)\n",
    "from barazmoon.twitter import twitter_workload_generator\n",
    "\n",
    "# get an absolute path to the directory that contains parent files\n",
    "__file__ = globals()[\"_dh\"][0]\n",
    "project_dir = __file__ = globals()[\"_dh\"][0]\n",
    "sys.path.append(os.path.normpath(os.path.join(project_dir, \"..\", \"..\", \"..\")))\n",
    "\n",
    "from experiments.utils.constants import FINAL_RESULTS_PATH, FIGURES_PATH\n",
    "from experiments.utils.parser import AdaptationParser\n",
    "import experiments.utils.drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaserieses = [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]\n",
    "serieses = [1, 2, 3, 21, 22, 23, 41, 42, 43, 61, 62, 63, 81, 82, 83]\n",
    "\n",
    "series_meta = {\n",
    "    \"lstm\": {\"video\": 1, \"audio-qa\": 21, \"audio-sent\": 41, \"sum-qa\": 61, \"nlp\": 81},\n",
    "    \"reactive\": {\"video\": 2, \"audio-qa\": 22, \"audio-sent\": 42, \"sum-qa\": 62, \"nlp\": 82},\n",
    "    \"baseline\": {\"video\": 3, \"audio-qa\": 23, \"audio-sent\": 43, \"sum-qa\": 63, \"nlp\": 83},\n",
    "}\n",
    "\n",
    "\n",
    "series_paths = {\n",
    "    series: os.path.join(\n",
    "        FINAL_RESULTS_PATH, \"metaseries\", str(metaseries), \"series\", str(series)\n",
    "    )\n",
    "    for series, metaseries in zip(serieses, metaserieses)\n",
    "}\n",
    "\n",
    "loaders = {\n",
    "    series: AdaptationParser(\n",
    "        series_path=series_path, model_name=\"video\", type_of=\"router_pipeline\"\n",
    "    )\n",
    "    for series, series_path in series_paths.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '/home/cc/ipa-private/data/results/final/metaseries/15/series/1',\n",
       " 2: '/home/cc/ipa-private/data/results/final/metaseries/15/series/2',\n",
       " 3: '/home/cc/ipa-private/data/results/final/metaseries/15/series/3',\n",
       " 21: '/home/cc/ipa-private/data/results/final/metaseries/15/series/21',\n",
       " 22: '/home/cc/ipa-private/data/results/final/metaseries/15/series/22',\n",
       " 23: '/home/cc/ipa-private/data/results/final/metaseries/15/series/23',\n",
       " 41: '/home/cc/ipa-private/data/results/final/metaseries/15/series/41',\n",
       " 42: '/home/cc/ipa-private/data/results/final/metaseries/15/series/42',\n",
       " 43: '/home/cc/ipa-private/data/results/final/metaseries/15/series/43',\n",
       " 61: '/home/cc/ipa-private/data/results/final/metaseries/15/series/61',\n",
       " 62: '/home/cc/ipa-private/data/results/final/metaseries/15/series/62',\n",
       " 63: '/home/cc/ipa-private/data/results/final/metaseries/15/series/63',\n",
       " 81: '/home/cc/ipa-private/data/results/final/metaseries/15/series/81',\n",
       " 82: '/home/cc/ipa-private/data/results/final/metaseries/15/series/82',\n",
       " 83: '/home/cc/ipa-private/data/results/final/metaseries/15/series/83'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: <experiments.utils.parser.AdaptationParser at 0x7fd36f8592b0>,\n",
       " 2: <experiments.utils.parser.AdaptationParser at 0x7fd4404eef40>,\n",
       " 3: <experiments.utils.parser.AdaptationParser at 0x7fd44049f1f0>,\n",
       " 21: <experiments.utils.parser.AdaptationParser at 0x7fd4404e3c40>,\n",
       " 22: <experiments.utils.parser.AdaptationParser at 0x7fd4404f3f10>,\n",
       " 23: <experiments.utils.parser.AdaptationParser at 0x7fd4404f3f40>,\n",
       " 41: <experiments.utils.parser.AdaptationParser at 0x7fd4404e7e80>,\n",
       " 42: <experiments.utils.parser.AdaptationParser at 0x7fd440373eb0>,\n",
       " 43: <experiments.utils.parser.AdaptationParser at 0x7fd36f859fd0>,\n",
       " 61: <experiments.utils.parser.AdaptationParser at 0x7fd36f8578e0>,\n",
       " 62: <experiments.utils.parser.AdaptationParser at 0x7fd4403736a0>,\n",
       " 63: <experiments.utils.parser.AdaptationParser at 0x7fd440373400>,\n",
       " 81: <experiments.utils.parser.AdaptationParser at 0x7fd36f8544f0>,\n",
       " 82: <experiments.utils.parser.AdaptationParser at 0x7fd36f87b6d0>,\n",
       " 83: <experiments.utils.parser.AdaptationParser at 0x7fd36f857460>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "series: 1 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 2,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 8,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 1,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 10,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': ['yolov5n', 'resnet18'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 7,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['yolo', 'resnet-human'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'image',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'yolov5n',\n",
      "                     'node_name': 'yolo',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'resnet18',\n",
      "                     'node_name': 'resnet-human',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'video',\n",
      "    'pipeline_name': 'video',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [71, 72],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 1,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['crop', 'classification'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 4,\n",
      "    'throughput_margin': 0,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 2 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 2,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'reactive',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 8,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 1,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 10,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': ['yolov5n', 'resnet18'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 15,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['yolo', 'resnet-human'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'image',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'yolov5n',\n",
      "                     'node_name': 'yolo',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'resnet18',\n",
      "                     'node_name': 'resnet-human',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'video',\n",
      "    'pipeline_name': 'video',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'reactive',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [71, 72],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 2,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['crop', 'classification'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 4,\n",
      "    'throughput_margin': 0,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 3 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 2,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'reactive',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 8,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 1,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 10,\n",
      "    'from_storage': [True, True],\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': ['yolov5n', 'resnet18'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'lowest_model_accuracy': 0,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 47,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['yolo', 'resnet-human'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'image',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'yolov5n',\n",
      "                     'node_name': 'yolo',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'resnet18',\n",
      "                     'node_name': 'resnet-human',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'video',\n",
      "    'pipeline_name': 'video',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'reactive',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [71, 72],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 3,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['crop', 'classification'],\n",
      "    'teleport_interval': 20,\n",
      "    'teleport_mode': True,\n",
      "    'threshold': 4,\n",
      "    'throughput_margin': 0,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 21 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'from_storage': [True, True],\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'lowest_model_accuracy': 0,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib - redo of '\n",
      "                'metaseries bursty on chameleon to check latencies',\n",
      "    'metaseries': 46,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-qa',\n",
      "    'pipeline_name': 'audio-qa',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [85, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 21,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-qa'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 22 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'reactive',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib - redo of '\n",
      "                'metaseries bursty on chameleon to check latencies',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-qa',\n",
      "    'pipeline_name': 'audio-qa',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'reactive',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [85, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 36,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-qa'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 23 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'reactive',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'from_storage': [True, True],\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'lowest_model_accuracy': 0,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib - redo of '\n",
      "                'metaseries bursty on chameleon to check latencies',\n",
      "    'metaseries': 47,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-qa',\n",
      "    'pipeline_name': 'audio-qa',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'reactive',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [85, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 23,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-qa'],\n",
      "    'teleport_interval': 20,\n",
      "    'teleport_mode': True,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 41 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'distilbert-base-uncased-finetuned-sst-2-english'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 14,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-sent'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'distilbert-base-uncased-finetuned-sst-2-english',\n",
      "                     'node_name': 'nlp-sent',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-sent',\n",
      "    'pipeline_name': 'audio-sent',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [87, 88],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 41,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-sent'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 42 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'reactive',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'distilbert-base-uncased-finetuned-sst-2-english'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 15,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-sent'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'distilbert-base-uncased-finetuned-sst-2-english',\n",
      "                     'node_name': 'nlp-sent',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-sent',\n",
      "    'pipeline_name': 'audio-sent',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'reactive',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [87, 88],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 42,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-sent'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 43 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'reactive',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'from_storage': [True, True],\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'distilbert-base-uncased-finetuned-sst-2-english'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'lowest_model_accuracy': 0,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 49,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-sent'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'distilbert-base-uncased-finetuned-sst-2-english',\n",
      "                     'node_name': 'nlp-sent',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-sent',\n",
      "    'pipeline_name': 'audio-sent',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'reactive',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [87, 88],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 43,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-sent'],\n",
      "    'teleport_interval': 20,\n",
      "    'teleport_mode': True,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 61 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 5,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'sshleifer-distilbart-xsum-1-1',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 15,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'sshleifer-distilbart-xsum-1-1',\n",
      "                     'node_name': 'nlp-sum',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'sum-qa',\n",
      "    'pipeline_name': 'sum-qa',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 10,\n",
      "    'profiling_series': [97, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 70,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 5,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 62 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'reactive',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 5,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'sshleifer-distilbart-xsum-1-1',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 15,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'sshleifer-distilbart-xsum-1-1',\n",
      "                     'node_name': 'nlp-sum',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'sum-qa',\n",
      "    'pipeline_name': 'sum-qa',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'reactive',\n",
      "    'profiling_load': 10,\n",
      "    'profiling_series': [97, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 65,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 5,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 63 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'reactive',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 5,\n",
      "    'from_storage': [True, True],\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'sshleifer-distilbart-xsum-1-1',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'lowest_model_accuracy': 0,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 47,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'sshleifer-distilbart-xsum-1-1',\n",
      "                     'node_name': 'nlp-sum',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'sum-qa',\n",
      "    'pipeline_name': 'sum-qa',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'reactive',\n",
      "    'profiling_load': 10,\n",
      "    'profiling_series': [97, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 63,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'teleport_interval': 20,\n",
      "    'teleport_mode': True,\n",
      "    'threshold': 5,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 81 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 5,\n",
      "    'drop_limit': 20,\n",
      "    'from_storage': [False, False, False],\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'dinalzein-xlm-roberta-base-finetuned-language-identification',\n",
      "                                'Helsinki-NLP-opus-mt-fr-en',\n",
      "                                'sshleifer-distilbart-xsum-1-1'],\n",
      "    'initial_batch': [1, 1, 1],\n",
      "    'initial_cpu_allocation': [1, 2, 2],\n",
      "    'initial_replica': [1, 1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': True,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 15,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['nlp-li', 'nlp-trans', 'nlp-sum'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'dinalzein-xlm-roberta-base-finetuned-language-identification',\n",
      "                     'node_name': 'nlp-li',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'Helsinki-NLP-opus-mt-fr-en',\n",
      "                     'node_name': 'nlp-trans',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'sshleifer-distilbart-xsum-1-1',\n",
      "                     'node_name': 'nlp-sum',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 3,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'nlp',\n",
      "    'pipeline_name': 'nlp',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': [20, 10, 10],\n",
      "    'profiling_series': [98, 99, 97],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 83,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['nlp-li', 'nlp-trans', 'nlp-sum'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 4,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 82 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'reactive',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 5,\n",
      "    'drop_limit': 20,\n",
      "    'from_storage': [False, False, False],\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'dinalzein-xlm-roberta-base-finetuned-language-identification',\n",
      "                                'Helsinki-NLP-opus-mt-fr-en',\n",
      "                                'sshleifer-distilbart-xsum-1-1'],\n",
      "    'initial_batch': [1, 1, 1],\n",
      "    'initial_cpu_allocation': [1, 2, 2],\n",
      "    'initial_replica': [1, 1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': True,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 15,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['nlp-li', 'nlp-trans', 'nlp-sum'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'dinalzein-xlm-roberta-base-finetuned-language-identification',\n",
      "                     'node_name': 'nlp-li',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'Helsinki-NLP-opus-mt-fr-en',\n",
      "                     'node_name': 'nlp-trans',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'sshleifer-distilbart-xsum-1-1',\n",
      "                     'node_name': 'nlp-sum',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 3,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'nlp',\n",
      "    'pipeline_name': 'nlp',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'reactive',\n",
      "    'profiling_load': [20, 10, 10],\n",
      "    'profiling_series': [98, 99, 97],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 99,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['nlp-li', 'nlp-trans', 'nlp-sum'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 4,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 83 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 5,\n",
      "    'drop_limit': 20,\n",
      "    'from_storage': [False, False, False],\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'dinalzein-xlm-roberta-base-finetuned-language-identification',\n",
      "                                'Helsinki-NLP-opus-mt-fr-en',\n",
      "                                'sshleifer-distilbart-xsum-1-1'],\n",
      "    'initial_batch': [1, 1, 1],\n",
      "    'initial_cpu_allocation': [1, 2, 2],\n",
      "    'initial_replica': [1, 1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'lowest_model_accuracy': 0,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 71,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['nlp-li', 'nlp-trans', 'nlp-sum'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'dinalzein-xlm-roberta-base-finetuned-language-identification',\n",
      "                     'node_name': 'nlp-li',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'Helsinki-NLP-opus-mt-fr-en',\n",
      "                     'node_name': 'nlp-trans',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'sshleifer-distilbart-xsum-1-1',\n",
      "                     'node_name': 'nlp-sum',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 3,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'nlp',\n",
      "    'pipeline_name': 'nlp',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': [20, 10, 10],\n",
      "    'profiling_series': [98, 99, 97],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 81,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['nlp-li', 'nlp-trans', 'nlp-sum'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 4,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n"
     ]
    }
   ],
   "source": [
    "accuracy_methods = {}\n",
    "adaptation_intervals = {}\n",
    "simulation_modes = {}\n",
    "configs = {}\n",
    "for series, loader in loaders.items():\n",
    "    configs_exp = loader.load_configs()\n",
    "    print(f\"series: {series} config:\\n\")\n",
    "    config = configs_exp[\"0.yaml\"]\n",
    "    pp.pprint(config)\n",
    "    configs[series] = config\n",
    "    accuracy_methods[series] = config[\"accuracy_method\"]\n",
    "    adaptation_intervals[series] = config[\"adaptation_interval\"]\n",
    "    simulation_modes[series] = config[\"simulation_mode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the sent workload\n",
    "sent_loads = {}\n",
    "for series, config in configs.items():\n",
    "    workload_type = config[\"workload_type\"]\n",
    "    workload_config = config[\"workload_config\"][0]\n",
    "    start = workload_config[\"start\"]\n",
    "    end = workload_config[\"end\"]\n",
    "    damping_factor = workload_config[\"damping_factor\"]\n",
    "    sent_loads[series] = twitter_workload_generator(\n",
    "        days=f\"{start}-{end}\", damping_factor=damping_factor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: False,\n",
       " 2: False,\n",
       " 3: False,\n",
       " 21: False,\n",
       " 22: False,\n",
       " 23: False,\n",
       " 41: False,\n",
       " 42: False,\n",
       " 43: False,\n",
       " 61: False,\n",
       " 62: False,\n",
       " 63: False,\n",
       " 81: False,\n",
       " 82: False,\n",
       " 83: False}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# key_config_df = loader.loader.key_config_mapper()\n",
    "# display(key_config_df)\n",
    "# key_config_df.columns\n",
    "results_all = []\n",
    "simulation_modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptation_logs = dict(\n",
    "    map(lambda l: (l[0], l[1].load_adaptation_log()), loaders.items())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_changes = {}\n",
    "for series in serieses:\n",
    "    series_changes[series] = loaders[series].series_changes(\n",
    "        adaptation_log=adaptation_logs[series]\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total core changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "replica_changes = {}\n",
    "for series, series_dict in series_changes.items():\n",
    "    # print(50 * \"-\" + f\" {series} \" + 50 * \"-\")\n",
    "    replica_changes[series] = {}\n",
    "    nodes = []\n",
    "    for node_name, metrics in series_changes[series][\"nodes\"].items():\n",
    "        replica_changes[series][node_name] = metrics[\"replicas\"]\n",
    "        nodes.append(node_name)\n",
    "    replica_changes[series][\"total\"] = [\n",
    "        sum(x) for x in zip(*replica_changes[series].values())\n",
    "    ]\n",
    "\n",
    "# -----------------------------\n",
    "core_changes = {}\n",
    "for series in serieses:\n",
    "    # print(50 * \"-\" + f\" {series} \" + 50 * \"-\")\n",
    "    core_changes[series] = {}\n",
    "    nodes = []\n",
    "    for node_name, metrics in series_changes[series][\"nodes\"].items():\n",
    "        core_changes[series][node_name] = metrics[\"cpu\"]\n",
    "        nodes.append(node_name)\n",
    "    core_changes[series][\"total\"] = [\n",
    "        sum(x) for x in zip(*core_changes[series].values())\n",
    "    ]\n",
    "\n",
    "# -----------------------------\n",
    "\n",
    "total_core_changes = {}\n",
    "for series in serieses:\n",
    "    # print(50 * \"-\" + f\" {series} \" + 50 * \"-\")\n",
    "    total_core_changes[series] = {}\n",
    "    for key in replica_changes[series].keys():\n",
    "        if key != \"total\":\n",
    "            total_core_changes[series][key] = [\n",
    "                x * y\n",
    "                for x, y in zip(replica_changes[series][key], core_changes[series][key])\n",
    "            ]\n",
    "    total = np.zeros(len(list(total_core_changes[series].values())[0]))\n",
    "    for key, series_value in total_core_changes[series].items():\n",
    "        total += np.array(series_value)\n",
    "    total_core_changes[series][\"total\"] = total.tolist()\n",
    "    # draw_temporal(total_core_changes[series])\n",
    "ylabel = \"Total Core\"\n",
    "xlabel = \"Pipelines\"\n",
    "legend = \"Predictor\"\n",
    "\n",
    "for exp, value in total_core_changes.items():\n",
    "    value[\"total\"] = (np.array(value[\"total\"]) / len(value[\"total\"])).tolist()\n",
    "total_core_changes_total = {\n",
    "    key: value[\"total\"] for key, value in total_core_changes.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'experiments.utils.drawing' from '/home/cc/ipa-private/experiments/utils/drawing.py'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(experiments.utils.drawing)\n",
    "\n",
    "# experiments.utils.drawing.draw_cumulative_with_grouping(\n",
    "#     dict_to_draw=total_core_changes_total,\n",
    "#     series_meta=series_meta,\n",
    "#     ylabel=ylabel,\n",
    "#     xlabel=xlabel,\n",
    "#     legend=legend,\n",
    "#     filename=f\"{FIGURES_PATH}/predictor-abelation-resources\",\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Latencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeout_per_second = {}\n",
    "per_second_results = {}\n",
    "for series in serieses:\n",
    "    if not simulation_modes[series]:\n",
    "        timeout_per_second[series], per_second_results[series] = loaders[\n",
    "            series\n",
    "        ].per_second_result_processing()\n",
    "    else:\n",
    "        timeout_per_second[series], per_second_results[series] = None, None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not all(simulation_modes.values()):\n",
    "    metric = \"p99\"  # [min, max, p99]\n",
    "    metrics_all = {}\n",
    "    for series in serieses:\n",
    "        # print(50 * \"-\" + f\" {series} \" + 50 * \"-\")\n",
    "        if not simulation_modes[series]:\n",
    "            metric_columns = list(\n",
    "                filter(lambda col: metric in col, per_second_results[series].columns)\n",
    "            )\n",
    "            metrics_all[series] = per_second_results[series][metric_columns]\n",
    "            # metrics_all[series][f\"{metric}_e2e\"] = metrics_all[series].sum(axis=1).to_list()\n",
    "            metrics_all[series] = metrics_all[series].to_dict(orient=\"list\")\n",
    "            # draw_temporal(metrics_all[series])\n",
    "    ylabel = \"Second\"\n",
    "    # draw_temporal(metrics_all, multiple_experiments=True, ylabel=ylabel)\n",
    "    # draw_cumulative(metrics_all, multiple_experiments=True, ylabel=ylabel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## timeouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 out of 14437\n",
      "368 out of 14437\n",
      "43 out of 14437\n",
      "132 out of 14437\n",
      "683 out of 14437\n",
      "131 out of 14437\n",
      "50 out of 14437\n",
      "139 out of 14437\n",
      "40 out of 14437\n",
      "803 out of 14437\n",
      "1647 out of 14437\n",
      "365 out of 14437\n",
      "257 out of 14437\n",
      "463 out of 14437\n",
      "87 out of 14437\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "legend = \"Predictor\"\n",
    "ylabel = \"% SLA Violations\"\n",
    "xlabel = \"Pipelines\"\n",
    "\n",
    "timeout_dics = {}\n",
    "for series in serieses:\n",
    "    # print(50 * \"-\" + f\" {series} \" + 50 * \"-\")\n",
    "    if not simulation_modes[series]:\n",
    "        timeout_dics[series] = (\n",
    "            np.array(timeout_per_second[series]) / sum(sent_loads[series]) * 100\n",
    "        ).tolist()\n",
    "        # draw_temporal(timeout_dics[series])\n",
    "        print(f\"{sum(timeout_per_second[series])} out of {sum(sent_loads[series])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cc/ipa-private/experiments/utils/drawing.py:559: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(group_names)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(experiments.utils.drawing)\n",
    "\n",
    "data = {\"Cost (cores)\": total_core_changes_total, \"SLA violations (%)\": timeout_dics}\n",
    "\n",
    "bbox_to_anchor = (0.7, 2.55)\n",
    "\n",
    "experiments.utils.drawing.draw_cumulative_with_grouping(\n",
    "    data,\n",
    "    series_meta=series_meta,\n",
    "    xlabel=xlabel,\n",
    "    filename=f\"{FIGURES_PATH}/predictor-abelation-sla\",\n",
    "    colors=[\"#2c7fb8\", \"#41b6c4\", \"#253494\"],\n",
    "    bbox_to_anchor=bbox_to_anchor,\n",
    "    bar_width=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "central",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2465c4f56298bc06dbdad3e7519856d346ec0e9edf6ba2c905f0af711583810e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
