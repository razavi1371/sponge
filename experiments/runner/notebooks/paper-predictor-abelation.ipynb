{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video pipeline with Yolo + Resnet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pprint import PrettyPrinter\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List\n",
    "import numpy as np\n",
    "\n",
    "pp = PrettyPrinter(indent=4)\n",
    "from barazmoon.twitter import twitter_workload_generator\n",
    "\n",
    "# get an absolute path to the directory that contains parent files\n",
    "__file__ = globals()[\"_dh\"][0]\n",
    "project_dir = __file__ = globals()[\"_dh\"][0]\n",
    "sys.path.append(os.path.normpath(os.path.join(project_dir, \"..\", \"..\", \"..\")))\n",
    "\n",
    "from experiments.utils.constants import FINAL_RESULTS_PATH, FIGURES_PATH\n",
    "from experiments.utils.parser import AdaptationParser\n",
    "import experiments.utils.drawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaserieses = [15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15, 15]\n",
    "serieses = [1, 2, 3, 21, 22, 23, 41, 42, 43, 61, 62, 63, 81, 82, 83]\n",
    "\n",
    "series_meta = {\n",
    "    \"lstm\": {\"video\": 1, \"audio-qa\": 21, \"audio-sent\": 41, \"sum-qa\": 61, \"nlp\": 81},\n",
    "    \"reactive\": {\"video\": 2, \"audio-qa\": 22, \"audio-sent\": 42, \"sum-qa\": 62, \"nlp\": 82},\n",
    "    \"baseline\": {\"video\": 3, \"audio-qa\": 23, \"audio-sent\": 43, \"sum-qa\": 63, \"nlp\": 83},\n",
    "}\n",
    "\n",
    "\n",
    "series_paths = {\n",
    "    series: os.path.join(\n",
    "        FINAL_RESULTS_PATH, \"metaseries\", str(metaseries), \"series\", str(series)\n",
    "    )\n",
    "    for series, metaseries in zip(serieses, metaserieses)\n",
    "}\n",
    "\n",
    "loaders = {\n",
    "    series: AdaptationParser(\n",
    "        series_path=series_path, model_name=\"video\", type_of=\"router_pipeline\"\n",
    "    )\n",
    "    for series, series_path in series_paths.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '/home/cc/ipa-private/data/results/final/metaseries/15/series/1',\n",
       " 2: '/home/cc/ipa-private/data/results/final/metaseries/15/series/2',\n",
       " 3: '/home/cc/ipa-private/data/results/final/metaseries/15/series/3',\n",
       " 21: '/home/cc/ipa-private/data/results/final/metaseries/15/series/21',\n",
       " 22: '/home/cc/ipa-private/data/results/final/metaseries/15/series/22',\n",
       " 23: '/home/cc/ipa-private/data/results/final/metaseries/15/series/23',\n",
       " 41: '/home/cc/ipa-private/data/results/final/metaseries/15/series/41',\n",
       " 42: '/home/cc/ipa-private/data/results/final/metaseries/15/series/42',\n",
       " 43: '/home/cc/ipa-private/data/results/final/metaseries/15/series/43',\n",
       " 61: '/home/cc/ipa-private/data/results/final/metaseries/15/series/61',\n",
       " 62: '/home/cc/ipa-private/data/results/final/metaseries/15/series/62',\n",
       " 63: '/home/cc/ipa-private/data/results/final/metaseries/15/series/63',\n",
       " 81: '/home/cc/ipa-private/data/results/final/metaseries/15/series/81',\n",
       " 82: '/home/cc/ipa-private/data/results/final/metaseries/15/series/82',\n",
       " 83: '/home/cc/ipa-private/data/results/final/metaseries/15/series/83'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: <experiments.utils.parser.AdaptationParser at 0x7f821beeee20>,\n",
       " 2: <experiments.utils.parser.AdaptationParser at 0x7f821beeec10>,\n",
       " 3: <experiments.utils.parser.AdaptationParser at 0x7f821beee580>,\n",
       " 21: <experiments.utils.parser.AdaptationParser at 0x7f82f0cfffd0>,\n",
       " 22: <experiments.utils.parser.AdaptationParser at 0x7f821bf751c0>,\n",
       " 23: <experiments.utils.parser.AdaptationParser at 0x7f821bfa1220>,\n",
       " 41: <experiments.utils.parser.AdaptationParser at 0x7f822008db80>,\n",
       " 42: <experiments.utils.parser.AdaptationParser at 0x7f8220081610>,\n",
       " 43: <experiments.utils.parser.AdaptationParser at 0x7f821bf69040>,\n",
       " 61: <experiments.utils.parser.AdaptationParser at 0x7f821bfc2850>,\n",
       " 62: <experiments.utils.parser.AdaptationParser at 0x7f821bf7a100>,\n",
       " 63: <experiments.utils.parser.AdaptationParser at 0x7f82200ffd60>,\n",
       " 81: <experiments.utils.parser.AdaptationParser at 0x7f821bf94040>,\n",
       " 82: <experiments.utils.parser.AdaptationParser at 0x7f82200ca280>,\n",
       " 83: <experiments.utils.parser.AdaptationParser at 0x7f821bfdb730>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "series: 1 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 2,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 8,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 1,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 10,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': ['yolov5n', 'resnet18'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 7,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['yolo', 'resnet-human'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'image',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'yolov5n',\n",
      "                     'node_name': 'yolo',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'resnet18',\n",
      "                     'node_name': 'resnet-human',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'video',\n",
      "    'pipeline_name': 'video',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [71, 72],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 1,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['crop', 'classification'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 4,\n",
      "    'throughput_margin': 0,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 2 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 2,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'reactive',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 8,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 1,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 10,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': ['yolov5n', 'resnet18'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 15,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['yolo', 'resnet-human'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'image',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'yolov5n',\n",
      "                     'node_name': 'yolo',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'resnet18',\n",
      "                     'node_name': 'resnet-human',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'video',\n",
      "    'pipeline_name': 'video',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'reactive',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [71, 72],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 2,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['crop', 'classification'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 4,\n",
      "    'throughput_margin': 0,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 3 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 2,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'reactive',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 8,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 1,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 10,\n",
      "    'from_storage': [True, True],\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': ['yolov5n', 'resnet18'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'lowest_model_accuracy': 0,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 47,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['yolo', 'resnet-human'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'image',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'yolov5n',\n",
      "                     'node_name': 'yolo',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'resnet18',\n",
      "                     'node_name': 'resnet-human',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'video',\n",
      "    'pipeline_name': 'video',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'reactive',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [71, 72],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 3,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['crop', 'classification'],\n",
      "    'teleport_interval': 20,\n",
      "    'teleport_mode': True,\n",
      "    'threshold': 4,\n",
      "    'throughput_margin': 0,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 21 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'from_storage': [True, True],\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'lowest_model_accuracy': 0,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib - redo of '\n",
      "                'metaseries bursty on chameleon to check latencies',\n",
      "    'metaseries': 46,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-qa',\n",
      "    'pipeline_name': 'audio-qa',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [85, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 21,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-qa'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 22 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'reactive',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib - redo of '\n",
      "                'metaseries bursty on chameleon to check latencies',\n",
      "    'metaseries': 18,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-qa',\n",
      "    'pipeline_name': 'audio-qa',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'reactive',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [85, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 36,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-qa'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 23 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'reactive',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'from_storage': [True, True],\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'lowest_model_accuracy': 0,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib - redo of '\n",
      "                'metaseries bursty on chameleon to check latencies',\n",
      "    'metaseries': 47,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-qa',\n",
      "    'pipeline_name': 'audio-qa',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'reactive',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [85, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 23,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-qa'],\n",
      "    'teleport_interval': 20,\n",
      "    'teleport_mode': True,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 41 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'distilbert-base-uncased-finetuned-sst-2-english'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 14,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-sent'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'distilbert-base-uncased-finetuned-sst-2-english',\n",
      "                     'node_name': 'nlp-sent',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-sent',\n",
      "    'pipeline_name': 'audio-sent',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [87, 88],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 41,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-sent'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 42 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'reactive',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'distilbert-base-uncased-finetuned-sst-2-english'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 15,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-sent'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'distilbert-base-uncased-finetuned-sst-2-english',\n",
      "                     'node_name': 'nlp-sent',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-sent',\n",
      "    'pipeline_name': 'audio-sent',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'reactive',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [87, 88],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 42,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-sent'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 43 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'reactive',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 20,\n",
      "    'from_storage': [True, True],\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'facebook-s2t-small-librispeech-asr',\n",
      "                                'distilbert-base-uncased-finetuned-sst-2-english'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 100,\n",
      "    'logs_enabled': False,\n",
      "    'lowest_model_accuracy': 0,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 49,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['audio', 'nlp-sent'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'audio',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'facebook-s2t-small-librispeech-asr',\n",
      "                     'node_name': 'audio',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'distilbert-base-uncased-finetuned-sst-2-english',\n",
      "                     'node_name': 'nlp-sent',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'audio-sent',\n",
      "    'pipeline_name': 'audio-sent',\n",
      "    'predictor_margin': 20,\n",
      "    'predictor_type': 'reactive',\n",
      "    'profiling_load': 20,\n",
      "    'profiling_series': [87, 88],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 43,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['audio', 'nlp-sent'],\n",
      "    'teleport_interval': 20,\n",
      "    'teleport_mode': True,\n",
      "    'threshold': 1,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 61 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 5,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'sshleifer-distilbart-xsum-1-1',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 15,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'sshleifer-distilbart-xsum-1-1',\n",
      "                     'node_name': 'nlp-sum',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'sum-qa',\n",
      "    'pipeline_name': 'sum-qa',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': 10,\n",
      "    'profiling_series': [97, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 70,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 5,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 62 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'reactive',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 5,\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'sshleifer-distilbart-xsum-1-1',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 15,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'sshleifer-distilbart-xsum-1-1',\n",
      "                     'node_name': 'nlp-sum',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'sum-qa',\n",
      "    'pipeline_name': 'sum-qa',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'reactive',\n",
      "    'profiling_load': 10,\n",
      "    'profiling_series': [97, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 65,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 5,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 63 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'reactive',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 30,\n",
      "    'drop_limit': 5,\n",
      "    'from_storage': [True, True],\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'sshleifer-distilbart-xsum-1-1',\n",
      "                                'deepset-roberta-base-squad2'],\n",
      "    'initial_batch': [1, 1],\n",
      "    'initial_cpu_allocation': [1, 1],\n",
      "    'initial_replica': [1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'lowest_model_accuracy': 0,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 47,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'sshleifer-distilbart-xsum-1-1',\n",
      "                     'node_name': 'nlp-sum',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'deepset-roberta-base-squad2',\n",
      "                     'node_name': 'nlp-qa',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 2,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'sum-qa',\n",
      "    'pipeline_name': 'sum-qa',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'reactive',\n",
      "    'profiling_load': 10,\n",
      "    'profiling_series': [97, 86],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 63,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['nlp-sum', 'nlp-qa'],\n",
      "    'teleport_interval': 20,\n",
      "    'teleport_mode': True,\n",
      "    'threshold': 5,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 81 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 5,\n",
      "    'drop_limit': 20,\n",
      "    'from_storage': [False, False, False],\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'dinalzein-xlm-roberta-base-finetuned-language-identification',\n",
      "                                'Helsinki-NLP-opus-mt-fr-en',\n",
      "                                'sshleifer-distilbart-xsum-1-1'],\n",
      "    'initial_batch': [1, 1, 1],\n",
      "    'initial_cpu_allocation': [1, 2, 2],\n",
      "    'initial_replica': [1, 1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': True,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 15,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['nlp-li', 'nlp-trans', 'nlp-sum'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'dinalzein-xlm-roberta-base-finetuned-language-identification',\n",
      "                     'node_name': 'nlp-li',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'Helsinki-NLP-opus-mt-fr-en',\n",
      "                     'node_name': 'nlp-trans',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'sshleifer-distilbart-xsum-1-1',\n",
      "                     'node_name': 'nlp-sum',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 3,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'nlp',\n",
      "    'pipeline_name': 'nlp',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': [20, 10, 10],\n",
      "    'profiling_series': [98, 99, 97],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 83,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['nlp-li', 'nlp-trans', 'nlp-sum'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 4,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 82 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'reactive',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 5,\n",
      "    'drop_limit': 20,\n",
      "    'from_storage': [False, False, False],\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'dinalzein-xlm-roberta-base-finetuned-language-identification',\n",
      "                                'Helsinki-NLP-opus-mt-fr-en',\n",
      "                                'sshleifer-distilbart-xsum-1-1'],\n",
      "    'initial_batch': [1, 1, 1],\n",
      "    'initial_cpu_allocation': [1, 2, 2],\n",
      "    'initial_replica': [1, 1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': True,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 15,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['nlp-li', 'nlp-trans', 'nlp-sum'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'dinalzein-xlm-roberta-base-finetuned-language-identification',\n",
      "                     'node_name': 'nlp-li',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'Helsinki-NLP-opus-mt-fr-en',\n",
      "                     'node_name': 'nlp-trans',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'sshleifer-distilbart-xsum-1-1',\n",
      "                     'node_name': 'nlp-sum',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 3,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'nlp',\n",
      "    'pipeline_name': 'nlp',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'reactive',\n",
      "    'profiling_load': [20, 10, 10],\n",
      "    'profiling_series': [98, 99, 97],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 99,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['nlp-li', 'nlp-trans', 'nlp-sum'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 4,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n",
      "series: 83 config:\n",
      "\n",
      "{   'accuracy_method': 'sum',\n",
      "    'adaptation_interval': 10,\n",
      "    'allocation_mode': 'base',\n",
      "    'alpha': 10,\n",
      "    'backup_predictor_duration': 2,\n",
      "    'backup_predictor_type': 'max',\n",
      "    'baseline_mode': None,\n",
      "    'batching_cap': 1,\n",
      "    'benchmark_duration': 1,\n",
      "    'beta': 0.5,\n",
      "    'central_queue': True,\n",
      "    'debug_mode': False,\n",
      "    'distrpution_time': 5,\n",
      "    'drop_limit': 20,\n",
      "    'from_storage': [False, False, False],\n",
      "    'gamma': 1e-06,\n",
      "    'initial_active_model': [   'dinalzein-xlm-roberta-base-finetuned-language-identification',\n",
      "                                'Helsinki-NLP-opus-mt-fr-en',\n",
      "                                'sshleifer-distilbart-xsum-1-1'],\n",
      "    'initial_batch': [1, 1, 1],\n",
      "    'initial_cpu_allocation': [1, 2, 2],\n",
      "    'initial_replica': [1, 1, 1],\n",
      "    'latency_margin': 0,\n",
      "    'logs_enabled': False,\n",
      "    'lowest_model_accuracy': 0,\n",
      "    'metadata': 'bursty - ipa - cpu type: compute_cascadelake_r_ib',\n",
      "    'metaseries': 71,\n",
      "    'mode': 'exponential',\n",
      "    'model_name': ['nlp-li', 'nlp-trans', 'nlp-sum'],\n",
      "    'monitoring_duration': 2,\n",
      "    'nodes': [   {   'cpu_request': '1',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'dinalzein-xlm-roberta-base-finetuned-language-identification',\n",
      "                     'node_name': 'nlp-li',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'Helsinki-NLP-opus-mt-fr-en',\n",
      "                     'node_name': 'nlp-trans',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'},\n",
      "                 {   'cpu_request': '2',\n",
      "                     'data_type': 'text',\n",
      "                     'max_batch_size': '1',\n",
      "                     'max_batch_time': '1',\n",
      "                     'memory_request': '4Gi',\n",
      "                     'model_variants': 'sshleifer-distilbart-xsum-1-1',\n",
      "                     'node_name': 'nlp-sum',\n",
      "                     'num_interop_threads': '1',\n",
      "                     'num_threads': '1',\n",
      "                     'replicas': 1,\n",
      "                     'use_threading': 'True'}],\n",
      "    'normalize_accuracy': True,\n",
      "    'num_state_limit': 1,\n",
      "    'number_tasks': 3,\n",
      "    'only_measured_profiles': True,\n",
      "    'optimization_method': 'gurobi',\n",
      "    'pipeline_folder_name': 'nlp',\n",
      "    'pipeline_name': 'nlp',\n",
      "    'predictor_margin': 0,\n",
      "    'predictor_type': 'lstm',\n",
      "    'profiling_load': [20, 10, 10],\n",
      "    'profiling_series': [98, 99, 97],\n",
      "    'reference_latency': 'p99',\n",
      "    'reference_throughput': 'max',\n",
      "    'scaling_cap': 100,\n",
      "    'series': 81,\n",
      "    'simulation_mode': False,\n",
      "    'sla_factor': 5,\n",
      "    'task_name': ['nlp-li', 'nlp-trans', 'nlp-sum'],\n",
      "    'teleport_interval': 0,\n",
      "    'teleport_mode': False,\n",
      "    'threshold': 4,\n",
      "    'throughput_margin': -50,\n",
      "    'timeout': 1,\n",
      "    'warm_up': False,\n",
      "    'workload_config': [   {   'damping_factor': 8,\n",
      "                               'end': '1302360',\n",
      "                               'start': '1301160'}],\n",
      "    'workload_type': 'twitter'}\n"
     ]
    }
   ],
   "source": [
    "accuracy_methods = {}\n",
    "adaptation_intervals = {}\n",
    "simulation_modes = {}\n",
    "configs = {}\n",
    "for series, loader in loaders.items():\n",
    "    configs_exp = loader.load_configs()\n",
    "    print(f\"series: {series} config:\\n\")\n",
    "    config = configs_exp[\"0.yaml\"]\n",
    "    pp.pprint(config)\n",
    "    configs[series] = config\n",
    "    accuracy_methods[series] = config[\"accuracy_method\"]\n",
    "    adaptation_intervals[series] = config[\"adaptation_interval\"]\n",
    "    simulation_modes[series] = config[\"simulation_mode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the sent workload\n",
    "sent_loads = {}\n",
    "for series, config in configs.items():\n",
    "    workload_type = config[\"workload_type\"]\n",
    "    workload_config = config[\"workload_config\"][0]\n",
    "    start = workload_config[\"start\"]\n",
    "    end = workload_config[\"end\"]\n",
    "    damping_factor = workload_config[\"damping_factor\"]\n",
    "    sent_loads[series] = twitter_workload_generator(\n",
    "        days=f\"{start}-{end}\", damping_factor=damping_factor\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: False,\n",
       " 2: False,\n",
       " 3: False,\n",
       " 21: False,\n",
       " 22: False,\n",
       " 23: False,\n",
       " 41: False,\n",
       " 42: False,\n",
       " 43: False,\n",
       " 61: False,\n",
       " 62: False,\n",
       " 63: False,\n",
       " 81: False,\n",
       " 82: False,\n",
       " 83: False}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# key_config_df = loader.loader.key_config_mapper()\n",
    "# display(key_config_df)\n",
    "# key_config_df.columns\n",
    "results_all = []\n",
    "simulation_modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptation_logs = dict(\n",
    "    map(lambda l: (l[0], l[1].load_adaptation_log()), loaders.items())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_changes = {}\n",
    "for series in serieses:\n",
    "    series_changes[series] = loaders[series].series_changes(\n",
    "        adaptation_log=adaptation_logs[series]\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total core changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "replica_changes = {}\n",
    "for series, series_dict in series_changes.items():\n",
    "    # print(50 * \"-\" + f\" {series} \" + 50 * \"-\")\n",
    "    replica_changes[series] = {}\n",
    "    nodes = []\n",
    "    for node_name, metrics in series_changes[series][\"nodes\"].items():\n",
    "        replica_changes[series][node_name] = metrics[\"replicas\"]\n",
    "        nodes.append(node_name)\n",
    "    replica_changes[series][\"total\"] = [\n",
    "        sum(x) for x in zip(*replica_changes[series].values())\n",
    "    ]\n",
    "\n",
    "# -----------------------------\n",
    "core_changes = {}\n",
    "for series in serieses:\n",
    "    # print(50 * \"-\" + f\" {series} \" + 50 * \"-\")\n",
    "    core_changes[series] = {}\n",
    "    nodes = []\n",
    "    for node_name, metrics in series_changes[series][\"nodes\"].items():\n",
    "        core_changes[series][node_name] = metrics[\"cpu\"]\n",
    "        nodes.append(node_name)\n",
    "    core_changes[series][\"total\"] = [\n",
    "        sum(x) for x in zip(*core_changes[series].values())\n",
    "    ]\n",
    "\n",
    "# -----------------------------\n",
    "\n",
    "total_core_changes = {}\n",
    "for series in serieses:\n",
    "    # print(50 * \"-\" + f\" {series} \" + 50 * \"-\")\n",
    "    total_core_changes[series] = {}\n",
    "    for key in replica_changes[series].keys():\n",
    "        if key != \"total\":\n",
    "            total_core_changes[series][key] = [\n",
    "                x * y\n",
    "                for x, y in zip(replica_changes[series][key], core_changes[series][key])\n",
    "            ]\n",
    "    total = np.zeros(len(list(total_core_changes[series].values())[0]))\n",
    "    for key, series_value in total_core_changes[series].items():\n",
    "        total += np.array(series_value)\n",
    "    total_core_changes[series][\"total\"] = total.tolist()\n",
    "    # draw_temporal(total_core_changes[series])\n",
    "ylabel = \"Total Core\"\n",
    "xlabel = \"Pipelines\"\n",
    "legend = \"Predictor\"\n",
    "\n",
    "for exp, value in total_core_changes.items():\n",
    "    value[\"total\"] = (np.array(value[\"total\"]) / len(value[\"total\"])).tolist()\n",
    "total_core_changes_total = {\n",
    "    key: value[\"total\"] for key, value in total_core_changes.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'experiments.utils.drawing' from '/home/cc/ipa-private/experiments/utils/drawing.py'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(experiments.utils.drawing)\n",
    "\n",
    "# experiments.utils.drawing.draw_cumulative_with_grouping(\n",
    "#     dict_to_draw=total_core_changes_total,\n",
    "#     series_meta=series_meta,\n",
    "#     ylabel=ylabel,\n",
    "#     xlabel=xlabel,\n",
    "#     legend=legend,\n",
    "#     filename=f\"{FIGURES_PATH}/predictor-abelation-resources\",\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Latencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeout_per_second = {}\n",
    "per_second_results = {}\n",
    "for series in serieses:\n",
    "    if not simulation_modes[series]:\n",
    "        timeout_per_second[series], per_second_results[series] = loaders[\n",
    "            series\n",
    "        ].per_second_result_processing()\n",
    "    else:\n",
    "        timeout_per_second[series], per_second_results[series] = None, None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not all(simulation_modes.values()):\n",
    "    metric = \"p99\"  # [min, max, p99]\n",
    "    metrics_all = {}\n",
    "    for series in serieses:\n",
    "        # print(50 * \"-\" + f\" {series} \" + 50 * \"-\")\n",
    "        if not simulation_modes[series]:\n",
    "            metric_columns = list(\n",
    "                filter(lambda col: metric in col, per_second_results[series].columns)\n",
    "            )\n",
    "            metrics_all[series] = per_second_results[series][metric_columns]\n",
    "            # metrics_all[series][f\"{metric}_e2e\"] = metrics_all[series].sum(axis=1).to_list()\n",
    "            metrics_all[series] = metrics_all[series].to_dict(orient=\"list\")\n",
    "            # draw_temporal(metrics_all[series])\n",
    "    ylabel = \"Second\"\n",
    "    # draw_temporal(metrics_all, multiple_experiments=True, ylabel=ylabel)\n",
    "    # draw_cumulative(metrics_all, multiple_experiments=True, ylabel=ylabel)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## timeouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69 out of 14437\n",
      "368 out of 14437\n",
      "43 out of 14437\n",
      "132 out of 14437\n",
      "683 out of 14437\n",
      "131 out of 14437\n",
      "50 out of 14437\n",
      "139 out of 14437\n",
      "40 out of 14437\n",
      "803 out of 14437\n",
      "1647 out of 14437\n",
      "365 out of 14437\n",
      "257 out of 14437\n",
      "463 out of 14437\n",
      "87 out of 14437\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "legend = \"Predictor\"\n",
    "ylabel = \"% SLA Violations\"\n",
    "xlabel = \"Pipelines\"\n",
    "\n",
    "timeout_dics = {}\n",
    "for series in serieses:\n",
    "    # print(50 * \"-\" + f\" {series} \" + 50 * \"-\")\n",
    "    if not simulation_modes[series]:\n",
    "        timeout_dics[series] = (\n",
    "            np.array(timeout_per_second[series]) / sum(sent_loads[series]) * 100\n",
    "        ).tolist()\n",
    "        # draw_temporal(timeout_dics[series])\n",
    "        print(f\"{sum(timeout_per_second[series])} out of {sum(sent_loads[series])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cc/ipa-private/experiments/utils/drawing.py:560: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(group_names)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(experiments.utils.drawing)\n",
    "\n",
    "data = {\"Cost (cores)\": total_core_changes_total, \"SLA violations (%)\": timeout_dics}\n",
    "\n",
    "bbox_to_anchor = (0.83, 2.55)\n",
    "\n",
    "experiments.utils.drawing.draw_cumulative_with_grouping(\n",
    "    data,\n",
    "    series_meta=series_meta,\n",
    "    xlabel=xlabel,\n",
    "    filename=f\"{FIGURES_PATH}/predictor-abelation-sla\",\n",
    "    colors=[\"#2c7fb8\", \"#41b6c4\", \"#253494\"],\n",
    "    bbox_to_anchor=bbox_to_anchor,\n",
    "    bar_width=0.2,\n",
    "    ncol=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "central",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2465c4f56298bc06dbdad3e7519856d346ec0e9edf6ba2c905f0af711583810e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
