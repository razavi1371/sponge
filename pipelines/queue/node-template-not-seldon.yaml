apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    app: queue-{{ model_name }}-queue-{{ model_name }}-0-queue-{{ model_name }}
    app.kubernetes.io/managed-by: seldon-core
    fluentd: "true"
    seldon-app: queue-{{ model_name }}-queue-{{ model_name }}
    seldon-app-svc-queue: queue-{{ model_name }}-queue-{{ model_name }}-queue-{{ model_name }}
    seldon-deployment-id: queue-{{ model_name }}
    seldon.io/model: "true"
    sidecar.istio.io/inject: "true"
    version: queue-{{ model_name }}
  name: queue-{{ model_name }}-queue-{{ model_name }}-0-queue-{{ model_name }}
  namespace: default
spec:
  selector:
    matchLabels:
      seldon-app: queue-{{ model_name }}-queue-{{ model_name }}
      seldon-app-svc-queue: queue-{{ model_name }}-queue-{{ model_name }}-queue-{{ model_name }}
      seldon-deployment-id: queue-{{ model_name }}
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 0
    type: RollingUpdate
  template:
    metadata:
      annotations:
        prometheus.io/path: /prometheus
        prometheus.io/scrape: "true"
        seldon.io/no-engine: "true"
      creationTimestamp: null
      labels:
        app: queue-{{ model_name }}-queue-{{ model_name }}-0-queue-{{ model_name }}
        app.kubernetes.io/managed-by: seldon-core
        fluentd: "true"
        seldon-app: queue-{{ model_name }}-queue-{{ model_name }}
        seldon-app-svc-queue: queue-{{ model_name }}-queue-{{ model_name }}-queue-{{ model_name }}
        seldon-deployment-id: queue-{{ model_name }}
        seldon.io/model: "true"
        sidecar.istio.io/inject: "true"
        version: queue-{{ model_name }}
    spec:
      containers:
      - env:
        - name: MODEL_NAME
          value: {{ model_name }}
        - name: MLSERVER_MODEL_MAX_BATCH_SIZE
          value: '{{ max_batch_size }}'
        - name: MLSERVER_MODEL_MAX_BATCH_TIME
          value: '{{ max_batch_time }}'
        - name: MLSERVER_PARALLEL_WORKERS
          value: "0"
        - name: LAST_NODE
          value: "True"
        - name: DROP_LIMIT
          value: '{{drop_limit}}'
        - name: LOGS_ENABLED
          value: '{{ logs_enabled }}'
        - name: PREDICTIVE_UNIT_SERVICE_PORT
          value: "9000"
        - name: PREDICTIVE_UNIT_HTTP_SERVICE_PORT
          value: "9000"
        - name: MLSERVER_HTTP_PORT
          value: "9000"
        - name: PREDICTIVE_UNIT_GRPC_SERVICE_PORT
          value: "9500"
        - name: MLSERVER_GRPC_PORT
          value: "9500"
        - name: PREDICTIVE_UNIT_ID
          value: queue-{{ model_name }}
        - name: MLSERVER_MODEL_NAME
          value: queue-{{ model_name }}
        - name: PREDICTIVE_UNIT_IMAGE
          value: sdghafouri/dynainf:queue
        - name: PREDICTOR_ID
          value: queue-{{ model_name }}
        - name: PREDICTOR_LABELS
          value: '{"sidecar.istio.io/inject":"true","version":"queue"}'
        - name: SELDON_DEPLOYMENT_ID
          value: queue-{{ model_name }}
        - name: SELDON_EXECUTOR_ENABLED
          value: "true"
        - name: PREDICTIVE_UNIT_METRICS_SERVICE_PORT
          value: "6000"
        - name: PREDICTIVE_UNIT_METRICS_ENDPOINT
          value: /prometheus
        - name: MLSERVER_METRICS_PORT
          value: "6000"
        - name: MLSERVER_METRICS_ENDPOINT
          value: /prometheus
        image: sdghafouri/dynainf:queue
        imagePullPolicy: Always
        lifecycle:
          preStop:
            exec:
              command:
              - /bin/sh
              - -c
              - /bin/sleep {{ distrpution_time }}
        livenessProbe:
          failureThreshold: 3
          initialDelaySeconds: 60
          periodSeconds: 5
          successThreshold: 1
          tcpSocket:
            port: 9000
          timeoutSeconds: 1
        name: queue-{{ model_name }}
        ports:
        - containerPort: 6000
          name: metrics
          protocol: TCP
        - containerPort: 9000
          name: http
          protocol: TCP
        - containerPort: 9500
          name: grpc
          protocol: TCP
        readinessProbe:
          failureThreshold: 3
          periodSeconds: 1
          successThreshold: 1
          tcpSocket:
            port: 9000
          timeoutSeconds: 1
        resources:
          requests:
            cpu: '{{ cpu_request }}'
            memory: '{{ memory_request }}'
          limits:
            cpu: '{{ cpu_limit }}'
            memory: '{{ memory_limit }}'
        terminationMessagePath: /dev/termination-log
        terminationMessagePolicy: File
        volumeMounts:
        - mountPath: /etc/podinfo
          name: seldon-podinfo
      dnsPolicy: ClusterFirst
      restartPolicy: Always
      schedulerName: default-scheduler
      securityContext:
        runAsUser: 8888
      terminationGracePeriodSeconds: 20
      volumes:
      - downwardAPI:
          defaultMode: 420
          items:
          - fieldRef:
              apiVersion: v1
              fieldPath: metadata.annotations
            path: annotations
        name: seldon-podinfo
status:
  availableReplicas: 1
  readyReplicas: 1
  replicas: 1
  updatedReplicas: 1

---
apiVersion: v1
kind: Service
metadata:
  labels:
    app.kubernetes.io/managed-by: seldon-core
    seldon-app: queue-{{ model_name }}-queue-{{ model_name }}
    seldon-deployment-id: queue-{{ model_name }}
    seldon.io/model: "true"
  name: queue-{{ model_name }}-queue-{{ model_name }}
  namespace: default
spec:
  ports:
  - name: http
    nodePort: 32002
    port: 9000
    protocol: TCP
    targetPort: 9000
  - name: grpc
    port: 9500
    protocol: TCP
    targetPort: 9500
  selector:
    seldon-app: queue-{{ model_name }}-queue-{{ model_name }}
  sessionAffinity: None
  type: LoadBalancer
status:
  loadBalancer: {}
