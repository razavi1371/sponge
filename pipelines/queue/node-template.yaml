apiVersion: machinelearning.seldon.io/v1
kind: SeldonDeployment
metadata:
  name: queue-{{ model_name }}
spec:
  protocol: v2
  name: queue-{{ model_name }}
  annotations:
    proxy.istio.io/config: |
      terminationDrainDuration: {{ distrpution_time }}s
  predictors:
  - name: queue-{{ model_name }}
    annotations:
      seldon.io/no-engine: "true" 
    componentSpecs:
    - spec:
        terminationGracePeriodSeconds: {{ distrpution_time }}
        containers:
        - image: sdghafouri/queue:queue
          name: queue-{{ model_name }}
          imagePullPolicy: Always
          resources:
            requests:
              cpu: '{{ cpu_request }}'
              memory: '{{ memory_request }}'
            limits:
              cpu: '{{ cpu_limit }}'
              memory: '{{ memory_limit }}'
          env:
            - name: MODEL_NAME
              value: {{ model_name }}
            - name: LAST_NODE
              value: '{{ last_node }}'
            - name: MLSERVER_MODEL_MAX_BATCH_SIZE
              value: '{{ max_batch_size }}'
            - name: MLSERVER_MODEL_MAX_BATCH_TIME
              value: '{{ max_batch_time }}'
            - name: MLSERVER_PARALLEL_WORKERS
              value: "0"
            - name: DROP_LIMIT
              value: '{{drop_limit}}'
            - name: LOGS_ENABLED
              value: '{{ logs_enabled }}'
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 0
            periodSeconds: 1
            successThreshold: 1
            tcpSocket:
              port: 9000
            timeoutSeconds: 1
          lifecycle:
            preStop:
              exec:
                command:
                - /bin/sh
                - -c
                - /bin/sleep {{ distrpution_time }}
      replicas: 1
    graph:
      name: queue-{{ model_name }}
      type: MODEL
      children: []
    labels:
      sidecar.istio.io/inject: "true"
