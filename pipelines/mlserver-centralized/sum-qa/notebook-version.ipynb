{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.973744809627533}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "sentiment = pipeline(\"sentiment-analysis\")\n",
    "sentiment(\"mamooli weather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.5029847025871277}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summerize = pipeline(task=\"text-classification\", model=\"bert-base-uncased\")\n",
    "summerize(\n",
    "    \"If hearings or trials cannot take place because there are no barristers present to represent defendants, there won't be any trials in which criminals are sent to prison and those who are innocent are acquitted. Victims, like defendants, will be left in limbo, unsure when they will see justice. Tentative plans to broker a deal behind the scenes by bringing forward payments have failed - partly because there is simply no trust between the profession and ministers who wont meet them.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'en', 'score': 0.9999854564666748}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=\"dinalzein/xlm-roberta-base-finetuned-language-identification\",\n",
    ")\n",
    "translator(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'en', 'score': 0.9999854564666748}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=\"dinalzein/xlm-roberta-base-finetuned-language-identification\",\n",
    ")\n",
    "translator(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset librispeech_asr_demo (/home/cc/.cache/huggingface/datasets/hf-internal-testing___librispeech_asr_demo/clean-data_dir=%2F/2.1.0/d3bc4c2bc2078fcde3ad0f0f635862e4c0fef78ba94c4a34c4c250a097af240b)\n",
      "/home/cc/miniconda3/envs/central/lib/python3.9/site-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (200) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['</s> mister quilter is the apostle of the middle classes and we are glad to welcome his gospel</s>']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import Speech2TextProcessor, Speech2TextForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "\n",
    "model = Speech2TextForConditionalGeneration.from_pretrained(\n",
    "    \"facebook/s2t-small-librispeech-asr\"\n",
    ")\n",
    "processor = Speech2TextProcessor.from_pretrained(\"facebook/s2t-small-librispeech-asr\")\n",
    "\n",
    "\n",
    "ds = load_dataset(\n",
    "    \"hf-internal-testing/librispeech_asr_demo\",\n",
    "    \"clean\",\n",
    "    split=\"validation\",\n",
    "    data_dir=\"/\",\n",
    ")\n",
    "\n",
    "inputs = processor(\n",
    "    ds[0][\"audio\"][\"array\"],\n",
    "    sampling_rate=ds[0][\"audio\"][\"sampling_rate\"],\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "generated_ids = model.generate(\n",
    "    inputs[\"input_features\"], attention_mask=inputs[\"attention_mask\"]\n",
    ")\n",
    "\n",
    "transcription = processor.batch_decode(generated_ids)\n",
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' Hello'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "translator = pipeline(\n",
    "    task=\"summarization\",\n",
    "    model=\"sshleifer/distilbart-cnn-12-6\",\n",
    "    min_length=0,\n",
    "    max_length=4,\n",
    ")\n",
    "translator(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' Hello'}]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' Hello'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' who'}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translator(\"who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.15 ('jupyter-test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "59072ed32e7a3308a4a098da951e9f72b7536c5ea58a102a2f27175436f85f9a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
