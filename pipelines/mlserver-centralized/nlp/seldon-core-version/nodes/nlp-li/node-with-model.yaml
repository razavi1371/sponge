apiVersion: machinelearning.seldon.io/v1
kind: SeldonDeployment
metadata:
  name: nlp-li
spec:
  protocol: v2
  name: nlp-li
  annotations:
    proxy.istio.io/config: |
      terminationDrainDuration: 10s
  predictors:
  - name: nlp-li
    annotations:
      seldon.io/no-engine: "true"
    componentSpecs:
    - spec:
        # volumes:
        # - name: classifier-provision-location
        #   emptyDir: {}

        # initContainers:
        # - name: classifier-model-initializer
        #   image: seldonio/rclone-storage-initializer:1.16.0-dev
        #   imagePullPolicy: IfNotPresent
        #   args:
        #     - "s3://huggingface/text-classification/dinalzein-xlm-roberta-base-finetuned-language-identification"
        #     - "/mnt/models/dinalzein-xlm-roberta-base-finetuned-language-identification"

        #   volumeMounts:
        #   - mountPath: /mnt/models
        #     name: classifier-provision-location

        #   envFrom:
        #   - secretRef:
        #       name: seldon-rclone-secret

        terminationGracePeriodSeconds: 10
        containers:
        - image: sdghafouri/nlp-centralized-with-model:nlpli
          name: nlp-li
          imagePullPolicy: Always
          resources:
            requests:
              cpu: '2'
              memory: 4Gi
            limits:
              cpu: '2'
              memory: 4Gi
          # volumeMounts:
          # - mountPath: /mnt/models
          #   name: classifier-provision-location

          env:
            - name: MODEL_VARIANT
              value: dinalzein-xlm-roberta-base-finetuned-language-identification
            # - name: TRANSFORMERS_CACHE
            #   value: /opt/mlserver/.cache
            - name: TASK
              value: text-classification
            - name: MLSERVER_PARALLEL_WORKERS
              value: "1"
            - name: USE_THREADING
              value: "True"
            - name: NUM_INTEROP_THREADS
              value: "1"
            - name: NUM_THREADS
              value: "1"
            - name: LOGS_ENABLED
              value: 'Trues'
            - name: WITH_MODELS
              value: "True"
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 0
            periodSeconds: 1
            successThreshold: 1
            tcpSocket:
              port: 9000
            timeoutSeconds: 1
          lifecycle:
            preStop:
              exec:
                command:
                - /bin/sh
                - -c
                - /bin/sleep 10
      replicas: 1
    graph:
      name: nlp-li
      type: MODEL
      children: []
    labels:
      sidecar.istio.io/inject: "true"