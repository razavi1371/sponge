apiVersion: "serving.kserve.io/v1beta1"
kind: "InferenceService"
metadata:
  name: "resnet-classifier"
spec:
  predictor:
    volumes:
    - name: resnet-volume
      persistentVolumeClaim:
        claimName: torchhub-claim
        readOnly: true

    containers:
    - image: sdghafouri/video-pipelines-mlserver-bytes:resnet-human
      name: resnet-human
      imagePullPolicy: Always
      resources:
        requests:
          cpu: '1'
          memory: 4Gi
        limits:
          cpu: '1'
          memory: 4Gi
      volumeMounts:
      - mountPath: /opt/mlserver/.torch/hub/checkpoints
        name: resnet-volume
        subPath: resnet/resnet152
        readOnly: true
      env:
        - name: MODEL_VARIANT
          value: resnet152
        - name: TRANSFORMERS_CACHE
          value: /opt/mlserver/.cache
        - name: TORCH_HOME
          value: /opt/mlserver/.torch
        - name: MLSERVER_MODEL_MAX_BATCH_SIZE
          value: "1"
        - name: MLSERVER_MODEL_MAX_BATCH_TIME
          value: "1"
        - name: MLSERVER_PARALLEL_WORKERS
          value: "0"
        - name: USE_THREADING
          value: "True"
        - name: NUM_INTEROP_THREADS
          value: "1"
        - name: NUM_THREADS
          value: "1"
