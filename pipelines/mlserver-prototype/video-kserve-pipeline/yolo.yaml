
apiVersion: "serving.kserve.io/v1beta1"
kind: "InferenceService"
metadata:
  name: "yolo-object-detector"
spec:
  predictor:
    volumes:
    - name: yolov5-volume
      nfs:
        server: 192.5.86.160
        path: /fileshare/torchhub/yolo/yolov5m
    containers:
    - image: sdghafouri/video-pipelines-mlserver-bytes:yolov5
      name: yolo
      imagePullPolicy: Always
      resources:
        requests:
          cpu: '1'
          memory: 4Gi
        limits:
          cpu: '1'
          memory: 4Gi
      volumeMounts:
      - mountPath: /mnt/models/yolov5m
        name: yolov5-volume
      env:
        - name: MODEL_PATH
          value: /mnt/models/yolov5m
        - name: MODEL_VARIANT
          value: yolov5m
        - name: TRANSFORMERS_CACHE
          value: /opt/mlserver/.cache
        - name: TORCH_HOME
          value: /opt/mlserver/.torch
        - name: MLSERVER_MODEL_MAX_BATCH_SIZE
          value: "2"
        - name: MLSERVER_MODEL_MAX_BATCH_TIME
          value: "1"
        - name: MLSERVER_PARALLEL_WORKERS
          value: "0"
        - name: USE_THREADING
          value: "True"
        - name: NUM_INTEROP_THREADS
          value: "5"
        - name: NUM_THREADS
          value: "1"
