
apiVersion: machinelearning.seldon.io/v1
kind: SeldonDeployment
metadata:
  name: {{ name }}
spec:
  protocol: v2
  name: {{ name }}
  annotations:
    seldon.io/engine-separate-pod: "true"
  predictors:
  - componentSpecs:
    - spec:
        containers:
        - image: sdghafouri/audio-sent-pipelines-mlserver-bytes:audio
          name: audio
          imagePullPolicy: Always
            requests:
              cpu: '{{ cpu_request_1 }}'
              memory: '{{ memory_request }}'
            limits:
              cpu: '{{ cpu_limit_1 }}'
              memory: '{{ memory_limit }}'
          env:
            - name: MODEL_VARIANT
              value: {{ model_variant_1 }}
            - name: TRANSFORMERS_CACHE
              value: /opt/mlserver/.cache
            - name: TASK
              value: automatic-speech-recognition
            - name: MLSERVER_MODEL_MAX_BATCH_SIZE
              value: '{{ max_batch_size_1 }}'
            - name: MLSERVER_MODEL_MAX_BATCH_TIME
              value: '{{ max_batch_time_1 }}'
            - name: MLSERVER_PARALLEL_WORKERS
              value: "0"
            - name: USE_THREADING
              value: '{{use_threading_1}}'
            - name: NUM_INTEROP_THREADS
              value: '{{num_interop_threads_1}}'
            - name: NUM_THREADS
              value: '{{num_threads_1}}'
      replicas: {{ replicas_1 }}
    - spec:
        containers:
        - image: sdghafouri/audio-sent-pipelines-mlserver-bytes:nlpsent
          name: nlp-sent
          imagePullPolicy: Always
          resources:
            requests:
              cpu: '{{ cpu_request_2 }}'
              memory: '{{ memory_request }}'
            limits:
              cpu: '{{ cpu_limit_2 }}'
              memory: '{{ memory_limit }}'
          env:
            - name: MODEL_VARIANT
              value: {{ model_variant_2 }}
            - name: TRANSFORMERS_CACHE
              value: /opt/mlserver/.cache
            - name: TASK
              value: sentiment-analysis
            - name: MLSERVER_MODEL_MAX_BATCH_SIZE
              value: '{{ max_batch_size_2 }}'
            - name: MLSERVER_MODEL_MAX_BATCH_TIME
              value: '{{ max_batch_time_2 }}'
            - name: MLSERVER_PARALLEL_WORKERS
              value: "0"
            - name: USE_THREADING
              value: '{{use_threading_2}}'
            - name: NUM_INTEROP_THREADS
              value: '{{num_interop_threads_2}}'
            - name: NUM_THREADS
              value: '{{num_threads_2}}'
      replicas: {{ replicas }}
    graph:
      name: audio
      type: MODEL
      children:
      - name: nlp-sent
        type: MODEL
        children: []
    svcOrchSpec:
      resources:
        requests:
          cpu: '4'
          memory: 4Gi
        limits:
          cpu: '4'
          memory: 4Gi
    name: example
    labels:
      sidecar.istio.io/inject: "true"
    replicas: 1
