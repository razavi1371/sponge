apiVersion: machinelearning.seldon.io/v1
kind: SeldonDeployment
metadata:
  name: nlp-qa
spec:
  protocol: v2
  name: nlp-qa
  # annotations:
  #   seldon.io/engine-separate-pod: "true"
  annotations:
    proxy.istio.io/config: |
      terminationDrainDuration: 10s
  predictors:
  - name: nlp-qa
    annotations:
      seldon.io/no-engine: "true" 
    componentSpecs:

    - spec:
        # volumes:
        # - name: classifier-provision-location
        #   emptyDir: {}

        # initContainers:
        # - name: classifier-model-initializer
        #   image: seldonio/rclone-storage-initializer:1.16.0-dev
        #   imagePullPolicy: IfNotPresent
        #   args:
        #     - "s3://huggingface/question-answering/distilbert-base-cased-distilled-squad"
        #     - "/mnt/models/distilbert-base-cased-distilled-squad"

        #   volumeMounts:
        #   - mountPath: /mnt/models
        #     name: classifier-provision-location

        #   envFrom:
        #   - secretRef:
        #       name: seldon-rclone-secret

        terminationGracePeriodSeconds: 10
        containers:
        - image: sdghafouri/audio-qa-final-with-model:nlpqa
          name: nlp-qa 
          imagePullPolicy: Always
          resources:
            requests:
              cpu: '4'
              memory: 4Gi
            limits:
              cpu: '4'
              memory: 4Gi
          # volumeMounts:
          # - mountPath: /mnt/models
          #   name: classifier-provision-location

          env:
            - name: MODEL_VARIANT
              value: distilbert-base-cased-distilled-squad
            # - name: TRANSFORMERS_CACHE
            #   value: /opt/mlserver/.cache
            - name: TASK
              value: question-answering
            - name: CONTEXT
              value: default
            - name: MLSERVER_MODEL_MAX_BATCH_SIZE
              value: "1"
            - name: MLSERVER_MODEL_MAX_BATCH_TIME
              value: "1"
            - name: MLSERVER_PARALLEL_WORKERS
              value: "1"
            - name: USE_THREADING
              value: "True"
            - name: NUM_INTEROP_THREADS
              value: "4"
            - name: NUM_THREADS
              value: "4"
            - name: LOGS_ENABLED
              value: 'False'
            - name: WITH_MODELS
              value: "True"
          readinessProbe:
            failureThreshold: 3
            initialDelaySeconds: 0
            periodSeconds: 1
            successThreshold: 1
            tcpSocket:
              port: 9000
            timeoutSeconds: 1
          lifecycle:
            preStop:
              exec:
                command:
                - /bin/sh
                - -c
                - /bin/sleep 10
      replicas: 1
    graph:
      name: nlp-qa
      type: MODEL
      children: []
    labels:
      sidecar.istio.io/inject: "true"