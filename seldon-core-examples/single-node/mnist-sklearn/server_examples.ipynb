{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Model Servers with Seldon\n",
    "\n",
    "## Setup Seldon Core\n",
    "\n",
    "Use the setup notebook to [Setup Cluster](https://docs.seldon.io/projects/seldon-core/en/latest/examples/seldon_core_setup.html#Setup-Cluster) with [Ambassador Ingress](https://docs.seldon.io/projects/seldon-core/en/latest/examples/seldon_core_setup.html#Ambassador) and [Seldon Core](https://docs.seldon.io/projects/seldon-core/en/latest/examples/seldon_core_setup.html#Install-Seldon-Core). Instructions [also online](https://docs.seldon.io/projects/seldon-core/en/latest/examples/seldon_core_setup.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "namespace/seldon created\n",
      "Context \"microk8s\" modified.\n"
     ]
    }
   ],
   "source": [
    "!kubectl create namespace seldon\n",
    "!kubectl config set-context $(kubectl config current-context) --namespace=seldon\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serve SKLearn Iris Model\n",
    "\n",
    "In order to deploy SKLearn artifacts, we can leverage the [pre-packaged SKLearn inference server](https://docs.seldon.io/projects/seldon-core/en/latest/servers/sklearn.html).\n",
    "The exposed API can follow either:\n",
    "\n",
    "- The default Seldon protocol. \n",
    "- The [KFServing V2 protocol](https://docs.seldon.io/projects/seldon-core/en/latest/servers/sklearn.html##v2-kfserving-protocol-incubating).\n",
    "\n",
    "For details on each of these protocols, you can check the [documentation section on API protocols](https://docs.seldon.io/projects/seldon-core/en/latest/graph/protocols.html#v2-kfserving-protocol).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default Seldon protocol\n",
    "\n",
    "To deploy and start serving an SKLearn artifact using Seldon's default protocol, we can use a config like the one below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting servers/sklearnserver/samples/iris.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile servers/sklearnserver/samples/iris.yaml\n",
    "apiVersion: machinelearning.seldon.io/v1alpha2\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: sklearn-2\n",
    "spec:\n",
    "  predictors:\n",
    "  - graph:\n",
    "      name: classifier\n",
    "      implementation: SKLEARN_SERVER\n",
    "      modelUri: gs://seldon-models/v1.13.0-dev/sklearn/iris\n",
    "    name: default\n",
    "    replicas: 1\n",
    "    labels:\n",
    "      sidecar.istio.io/inject: \"true\"\n",
    "    svcOrchSpec: \n",
    "      env: \n",
    "      - name: SELDON_LOG_LEVEL\n",
    "        value: DEBUG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then apply it to deploy it to our Kubernetes cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/sklearn-2 created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f servers/sklearnserver/samples/iris.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment \"sklearn-default-0-classifier\" rollout to finish: 0 of 1 updated replicas are available...\n",
      "deployment \"sklearn-default-0-classifier\" successfully rolled out\n"
     ]
    }
   ],
   "source": [
    "!kubectl rollout status deploy/$(kubectl get deploy -l seldon-deployment-id=sklearn -o jsonpath='{.items[0].metadata.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once it's deployed we can send our sklearn model requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REST Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'names': ['t:0', 't:1', 't:2'], 'ndarray': [[9.912315378486697e-07, 0.0007015931307746079, 0.9992974156376876]]}, 'meta': {'requestPath': {'classifier': 'seldonio/sklearnserver:1.13.1'}}}\n"
     ]
    }
   ],
   "source": [
    "X=!curl -s -d '{\"data\": {\"ndarray\":[[1.0, 2.0, 5.0, 6.0]]}}' \\\n",
    "   -X POST http://localhost:32000/seldon/seldon/sklearn/api/v1.0/predictions \\\n",
    "   -H \"Content-Type: application/json\"\n",
    "d=json.loads(X[0])\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seldon_core.seldon_client import SeldonClient\n",
    "\n",
    "sc = SeldonClient(\n",
    "    gateway_endpoint='localhost:32000', deployment_name=\"sklearn\", namespace=\"seldon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success:True message:\n",
      "Request:\n",
      "meta {\n",
      "}\n",
      "data {\n",
      "  tensor {\n",
      "    shape: 1\n",
      "    shape: 4\n",
      "    values: 0.6891268964215331\n",
      "    values: 0.6377761021329467\n",
      "    values: 0.006314612920745977\n",
      "    values: 0.8182397221572331\n",
      "  }\n",
      "}\n",
      "\n",
      "Response:\n",
      "{'data': {'names': ['t:0', 't:1', 't:2'], 'tensor': {'shape': [1, 3], 'values': [0.5503487905646082, 0.26382901518247037, 0.18582219425292154]}}, 'meta': {'requestPath': {'classifier': 'seldonio/sklearnserver:1.13.1'}}}\n"
     ]
    }
   ],
   "source": [
    "r = sc.predict(gateway=\"istio\", transport=\"rest\", shape=(1, 4))\n",
    "print(r)\n",
    "assert r.success == True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gRPC Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success:True message:\n",
      "Request:\n",
      "{'meta': {}, 'data': {'tensor': {'shape': [1, 4], 'values': [0.03386187064172752, 0.21334542903801457, 0.08818716896549395, 0.16749386671434563]}}}\n",
      "Response:\n",
      "{'meta': {'requestPath': {'classifier': 'seldonio/sklearnserver:1.13.1'}}, 'data': {'names': ['t:0', 't:1', 't:2'], 'tensor': {'shape': [1, 3], 'values': [0.37642540105025013, 0.4348983334245379, 0.18867626552521202]}}}\n"
     ]
    }
   ],
   "source": [
    "r = sc.predict(gateway=\"ambassador\", transport=\"grpc\", shape=(1, 4))\n",
    "print(r)\n",
    "assert r.success == True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/cc/infernece-pipeline-joint-optimization/seldon-core-examples/single-node/mnist-sklearn/server_examples.ipynb Cell 17'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bchameleon/home/cc/infernece-pipeline-joint-optimization/seldon-core-examples/single-node/mnist-sklearn/server_examples.ipynb#ch0000016vscode-remote?line=0'>1</a>\u001b[0m X\u001b[39m=\u001b[39mget_ipython()\u001b[39m.\u001b[39mgetoutput(\u001b[39m'\u001b[39m\u001b[39mcd ../executor/proto && grpcurl -d \u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m{\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m{\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mndarray\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m:[[1.0,2.0,5.0,6.0]]}}\u001b[39m\u001b[39m\\'\u001b[39;00m\u001b[39m           -rpc-header seldon:sklearn -rpc-header namespace:seldon           -plaintext           -proto ./prediction.proto  0.0.0.0:8003 seldon.protos.Seldon/Predict\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bchameleon/home/cc/infernece-pipeline-joint-optimization/seldon-core-examples/single-node/mnist-sklearn/server_examples.ipynb#ch0000016vscode-remote?line=1'>2</a>\u001b[0m d\u001b[39m=\u001b[39mjson\u001b[39m.\u001b[39;49mloads(\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(X))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bchameleon/home/cc/infernece-pipeline-joint-optimization/seldon-core-examples/single-node/mnist-sklearn/server_examples.ipynb#ch0000016vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(d)\n",
      "File \u001b[0;32m~/miniconda3/envs/central/lib/python3.8/json/__init__.py:357\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    <a href='file:///home/cc/miniconda3/envs/central/lib/python3.8/json/__init__.py?line=351'>352</a>\u001b[0m     \u001b[39mdel\u001b[39;00m kw[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    <a href='file:///home/cc/miniconda3/envs/central/lib/python3.8/json/__init__.py?line=353'>354</a>\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/cc/miniconda3/envs/central/lib/python3.8/json/__init__.py?line=354'>355</a>\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/cc/miniconda3/envs/central/lib/python3.8/json/__init__.py?line=355'>356</a>\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> <a href='file:///home/cc/miniconda3/envs/central/lib/python3.8/json/__init__.py?line=356'>357</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[1;32m    <a href='file:///home/cc/miniconda3/envs/central/lib/python3.8/json/__init__.py?line=357'>358</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/cc/miniconda3/envs/central/lib/python3.8/json/__init__.py?line=358'>359</a>\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/miniconda3/envs/central/lib/python3.8/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    <a href='file:///home/cc/miniconda3/envs/central/lib/python3.8/json/decoder.py?line=331'>332</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, s, _w\u001b[39m=\u001b[39mWHITESPACE\u001b[39m.\u001b[39mmatch):\n\u001b[1;32m    <a href='file:///home/cc/miniconda3/envs/central/lib/python3.8/json/decoder.py?line=332'>333</a>\u001b[0m     \u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/cc/miniconda3/envs/central/lib/python3.8/json/decoder.py?line=333'>334</a>\u001b[0m \u001b[39m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/cc/miniconda3/envs/central/lib/python3.8/json/decoder.py?line=334'>335</a>\u001b[0m \n\u001b[1;32m    <a href='file:///home/cc/miniconda3/envs/central/lib/python3.8/json/decoder.py?line=335'>336</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/cc/miniconda3/envs/central/lib/python3.8/json/decoder.py?line=336'>337</a>\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[1;32m    <a href='file:///home/cc/miniconda3/envs/central/lib/python3.8/json/decoder.py?line=337'>338</a>\u001b[0m     end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[1;32m    <a href='file:///home/cc/miniconda3/envs/central/lib/python3.8/json/decoder.py?line=338'>339</a>\u001b[0m     \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/miniconda3/envs/central/lib/python3.8/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    <a href='file:///home/cc/miniconda3/envs/central/lib/python3.8/json/decoder.py?line=352'>353</a>\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    <a href='file:///home/cc/miniconda3/envs/central/lib/python3.8/json/decoder.py?line=353'>354</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> <a href='file:///home/cc/miniconda3/envs/central/lib/python3.8/json/decoder.py?line=354'>355</a>\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    <a href='file:///home/cc/miniconda3/envs/central/lib/python3.8/json/decoder.py?line=355'>356</a>\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "X=!cd ../executor/proto && grpcurl -d '{\"data\":{\"ndarray\":[[1.0,2.0,5.0,6.0]]}}' \\\n",
    "         -rpc-header seldon:sklearn -rpc-header namespace:seldon \\\n",
    "         -plaintext \\\n",
    "         -proto ./prediction.proto  0.0.0.0:8003 seldon.protos.Seldon/Predict\n",
    "d=json.loads(\"\".join(X))\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And delete the model we deployed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io \"sklearn\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f servers/sklearnserver/samples/iris.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFServing V2 protocol\n",
    "\n",
    "We can deploy a SKLearn artifact, exposing an API compatible with [KFServing's V2 Protocol](https://docs.seldon.io/projects/seldon-core/en/latest/servers/sklearn.html##v2-kfserving-protocol-incubating) by specifying the `protocol` of our `SeldonDeployment` as `kfserving`.\n",
    "For example, we can consider the config below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting servers/iris-sklearn-v2.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile servers/iris-sklearn-v2.yaml\n",
    "apiVersion: machinelearning.seldon.io/v1\n",
    "kind: SeldonDeployment\n",
    "metadata:\n",
    "  name: sklearn\n",
    "spec:\n",
    "  name: iris\n",
    "  protocol: kfserving\n",
    "  predictors:\n",
    "  - graph:\n",
    "      children: []\n",
    "      implementation: SKLEARN_SERVER\n",
    "      modelUri: gs://seldon-models/sklearn/iris-0.23.2/lr_model\n",
    "      name: classifier\n",
    "    name: default\n",
    "    replicas: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then apply it to deploy our model to our Kubernetes cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io/sklearn configured\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f servers/iris-sklearn-v2.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for deployment \"sklearn-default-0-classifier\" rollout to finish: 1 old replicas are pending termination...\n",
      "Waiting for deployment \"sklearn-default-0-classifier\" rollout to finish: 1 old replicas are pending termination...\n",
      "deployment \"sklearn-default-0-classifier\" successfully rolled out\n"
     ]
    }
   ],
   "source": [
    "!kubectl rollout status deploy/$(kubectl get deploy -l seldon-deployment-id=sklearn -o jsonpath='{.items[0].metadata.name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once it's deployed, we can send inference requests to our model.\n",
    "Note that, since it's using the KFServing's V2 Protocol, these requests will be different to the ones using the default Seldon Protocol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"model_name\": \"classifier\",\n",
      "  \"model_version\": \"v1\",\n",
      "  \"id\": \"52096d6f-72e7-462d-95b2-9626e1b65f27\",\n",
      "  \"parameters\": null,\n",
      "  \"outputs\": [\n",
      "    {\n",
      "      \"name\": \"predict\",\n",
      "      \"shape\": [\n",
      "        1\n",
      "      ],\n",
      "      \"datatype\": \"INT64\",\n",
      "      \"parameters\": null,\n",
      "      \"data\": [\n",
      "        2\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import requests\n",
    "\n",
    "inference_request = {\n",
    "    \"inputs\": [\n",
    "        {\"name\": \"predict\", \"shape\": [1, 4], \"datatype\": \"FP32\", \"data\": [[1, 2, 3, 4]]}\n",
    "    ]\n",
    "}\n",
    "\n",
    "endpoint = \"http://localhost:8003/seldon/seldon/sklearn/v2/models/infer\"\n",
    "response = requests.post(endpoint, json=inference_request)\n",
    "\n",
    "print(json.dumps(response.json(), indent=2))\n",
    "assert response.ok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can delete the model we deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seldondeployment.machinelearning.seldon.io \"sklearn\" deleted\n"
     ]
    }
   ],
   "source": [
    "!kubectl delete -f servers/iris-sklearn-v2.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2465c4f56298bc06dbdad3e7519856d346ec0e9edf6ba2c905f0af711583810e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('central')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
