# ----------- pipeline configs -------------
# pipeline informat
pipeline_folder_name: video
pipeline_name: video
timeout: 1
pipeline_folder_name: video
mode: exponential
nodes:
  - node_name: yolo
    data_type: image
    model_variants: yolov5n
    max_batch_size: '1'
    max_batch_time: '1'
    cpu_request: '2'
    memory_request: 4Gi
    replicas: 5
    use_threading: 'True'
    num_interop_threads: '2'
    num_threads: '2'

# ----------- experiment configs -------------

benchmark_duration: 1
adaptation_interval: 1
workload_type: static
workload_config:
  loads_to_test: 40
  load_duration: 120
# workload_type: twitter
# workload_config:
#   - start: '1301160'
#     end: '1302360'
#     # end: '1863200'
#     # end: '1862200'
#     # end: '1861960'
#     # end: '1862500'
#     # end: '1863700'
#     # end: '1865100'
#     damping_factor: 8 # [int | null]

# ----------- optimizer configs -------------

metaseries: 5
series: 2
metadata: 'check on lower load=40, multiplier=0.9, duration=10min'
number_tasks: 1
profiling_series:
  - 72
model_name:
  - yolo
task_name: 
  - crop
initial_active_model:
  - yolov5n
initial_cpu_allocation:
  - 1
initial_replica:
  - 1
initial_batch:
  - 1
alpha: 2
scaling_cap: 16 # maximum possible scaling per nodes
batching_cap: 16 # maximum possible batching per nodes
cpu_cap: 16 # maximum possible cpu allocation per nodes
num_state_limit: 1000 # number of states
threshold: 4 # RPS threshold for finding the base allocation
optimization_method: fa2 # options: [dynainf | fa2]
allocation_mode: base # options: [fix | base | variable]
sla_factor: 5
normalize_accuracy: true
only_measured_profiles: true
profiling_load: 128
baseline_mode: null # [switch | scale | null]
accuracy_method: sum # [average | sum | multiply]
lowest_model_accuracy: 0

# ----------- load predictor configs -------------

predictor_type: 'reactive' # [reactive | avg | arima | lstm | max]
monitoring_duration: 2 # in minutes
backup_predictor_type: 'max' # [reactive | avg | lstm | max]
backup_predictor_duration: 2 # in minutes


# ----------- queueing-option -------------

central_queue: true

# ----------- distruption time -------------

distrpution_time: 30

# ----------- distruption time -------------
# debug mode with complete lgos of containers
debug_mode:  false

# ----------- simulation mode -------------
simulation_mode: false

# ----------- percent added to the predictor load -------------
predictor_margin: 0

# ----------- drop interval -------------
drop_limit: 100

# ----------- do a 10 second warm up before starting the experiment -------------
warm_up: false

# ----------- teleport mode (only available in real-world experiments) -------------
teleport_mode: false 
teleport_interval: 0

# ----------- reference latency and throughput -------------
reference_latency: 'p99' # p99 | avg
reference_throughput: 'max' # max | p99 | avg
latency_margin: 0
throughput_margin: 0

# ----------- enable in container logging -------------
logs_enabled: true

# ----------- whether to read models from storage or not - should be defined per node -------------
only_pod: false

sla: 1000

# minikube ip
minikube_ip: "192.168.49.2"